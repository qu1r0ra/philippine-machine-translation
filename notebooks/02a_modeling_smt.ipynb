{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd9a482a",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3191f06e",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3195b8-9381-4a27-97dd-2950ac4042b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99cc3a57-8d39-428f-a7c8-0e559576c2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONFIG] Directories ensured and random seed set.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from itertools import islice\n",
    "from pathlib import Path\n",
    "\n",
    "import dill as pickle\n",
    "import pandas as pd\n",
    "from nltk.translate import AlignedSent\n",
    "from nltk.translate.ibm1 import IBMModel1\n",
    "from nltk.translate.ibm2 import IBMModel2\n",
    "from nltk.translate.ibm3 import IBMModel3\n",
    "from nltk.translate.ibm4 import IBMModel4\n",
    "from nltk.translate.ibm5 import IBMModel5\n",
    "\n",
    "from src.config import MODELS_DIR, PROCESSED_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467d761d-0249-4cf8-b484-6e358db9a610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\qu1r0ra\\\\Documents\\\\GitHub\\\\philippine-machine-translation'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Switch to root as working directory\n",
    "if Path.cwd().name == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76895806-583f-4e45-b6cb-f03bac286c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           language1  \\\n",
      "0                          Si Adan, si Set, si Enos,   \n",
      "1                  si Kenan, si Mahalalel, si Jared,   \n",
      "2                    si Enoc, si Metusela, si Lamec,   \n",
      "3                si Noe, si Sem, si Ham ug si Jafet.   \n",
      "4  Ang mga anak nga lalaki ni Jafet: si Gomer, si...   \n",
      "\n",
      "                                           language2  \\\n",
      "0                                   Adán, Set, Enós,   \n",
      "1                         Cainán, Mahalaleel, Jared,   \n",
      "2                            Enoc, Matusalén, Lamec,   \n",
      "3                             Noé, Sem, Cam y Jafet.   \n",
      "4  Los hijos de Jafet: Gomer, Magog, Madai, Javán...   \n",
      "\n",
      "                                          src_tokens  \\\n",
      "0          ['si', 'adan', 'si', 'set', 'si', 'enos']   \n",
      "1  ['si', 'kenan', 'si', 'mahalalel', 'si', 'jared']   \n",
      "2    ['si', 'enoc', 'si', 'metusela', 'si', 'lamec']   \n",
      "3  ['si', 'noe', 'si', 'sem', 'si', 'ham', 'ug', ...   \n",
      "4  ['ang', 'mga', 'anak', 'nga', 'lalaki', 'ni', ...   \n",
      "\n",
      "                                          tgt_tokens  \n",
      "0                            ['adán', 'set', 'enós']  \n",
      "1                  ['cainán', 'mahalaleel', 'jared']  \n",
      "2                     ['enoc', 'matusalén', 'lamec']  \n",
      "3                ['noé', 'sem', 'cam', 'y', 'jafet']  \n",
      "4  ['los', 'hijos', 'de', 'jafet', 'gomer', 'mago...  \n",
      "\n",
      "Columns: ['language1', 'language2', 'src_tokens', 'tgt_tokens']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PROCESSED_DIR / \"preprocessed.csv\")\n",
    "\n",
    "print(df.head())\n",
    "print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ed18ea-464e-440e-aa8c-6e19a71c2bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sa': 69, 'ug': 69, 'ang': 69, 'de': 36, 'nga': 69}\n"
     ]
    }
   ],
   "source": [
    "word2class_path = PROCESSED_DIR / \"word_classes.json\"\n",
    "\n",
    "with open(word2class_path) as f:\n",
    "    word2class = json.load(f)\n",
    "\n",
    "print(dict(islice(word2class.items(), 5)))  # print 5 key-value pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817ab155-ad6e-4716-ba1c-1a17bf3bd2b6",
   "metadata": {},
   "source": [
    "Next, let us create aligned sentences to be passed into the IBM models. For this, we need NLTK's `AlignedSent` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4edddb2-abcd-4f22-b855-70e1e6a030b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 31,105 aligned sentence pairs.\n"
     ]
    }
   ],
   "source": [
    "aligned_sents = [\n",
    "    AlignedSent(tgt_tokens.split(), src_tokens.split())\n",
    "    for src_tokens, tgt_tokens in zip(df[\"src_tokens\"], df[\"tgt_tokens\"], strict=True)\n",
    "]\n",
    "\n",
    "print(f\"Created {len(aligned_sents):,} aligned sentence pairs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04803629-fecc-4e7c-bddd-c0d42ca466ff",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeefb71f-d0a3-4e15-8bc8-2d84e6cf5e44",
   "metadata": {},
   "source": [
    "#### IBM Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a354e2f8-64c3-4497-a7ed-d7413fd2c2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[IBM1] Training complete.\n",
      "\n",
      "IBM Model 1 saved to C:\\Users\\qu1r0ra\\Documents\\GitHub\\philippine-machine-translation\\data\\models\\ibm1_model.pkl\n",
      "CPU times: total: 2min 8s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ibm1 = IBMModel1(aligned_sents, iterations=5)\n",
    "print(\"\\n[IBM1] Training complete.\")\n",
    "\n",
    "ibm1_path = MODELS_DIR / \"ibm1_model.pkl\"\n",
    "with open(ibm1_path, \"wb\") as f:\n",
    "    pickle.dump(ibm1, f)\n",
    "\n",
    "print(f\"\\nIBM Model 1 saved to {ibm1_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45261243-f5ee-4bd7-aee1-ad0036e08bda",
   "metadata": {},
   "source": [
    "#### IBM Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bf780bd-6b0d-4050-bf28-f8d3a34e30c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[IBM2] Training complete.\n",
      "\n",
      "IBM Model 2 saved to C:\\Users\\qu1r0ra\\Documents\\GitHub\\philippine-machine-translation\\data\\models\\ibm2_model.pkl\n",
      "CPU times: total: 8min 51s\n",
      "Wall time: 8min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ibm2 = IBMModel2(aligned_sents, iterations=5)\n",
    "print(\"\\n[IBM2] Training complete.\")\n",
    "\n",
    "ibm2_path = MODELS_DIR / \"ibm2_model.pkl\"\n",
    "with open(ibm2_path, \"wb\") as f:\n",
    "    pickle.dump(ibm2, f)\n",
    "\n",
    "print(f\"\\nIBM Model 2 saved to {ibm2_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323cbfff-5a81-420d-b4fe-df94638561b3",
   "metadata": {},
   "source": [
    "#### IBM Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856bdac8-448b-4dad-9077-4e1facf43f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ibm3 = IBMModel3(aligned_sents, iterations=1)\n",
    "print(\"\\n[IBM3] Training complete.\")\n",
    "\n",
    "ibm3_path = MODELS_DIR / \"ibm3_model.pkl\"\n",
    "with open(ibm3_path, \"wb\") as f:\n",
    "    pickle.dump(ibm3, f)\n",
    "\n",
    "print(f\"\\nIBM Model 3 saved to {ibm3_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd69345-1b2f-4f24-aac0-ede8db58db0c",
   "metadata": {},
   "source": [
    "#### IBM Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe2d4ad-b637-4abe-9fe8-d77d9755e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ibm4 = IBMModel4(\n",
    "    aligned_sents,\n",
    "    iterations=3,\n",
    "    source_word_classes=word2class,\n",
    "    target_word_classes=word2class,\n",
    ")\n",
    "print(\"\\n[IBM4] Training complete.\")\n",
    "\n",
    "ibm4_path = MODELS_DIR / \"ibm4_model.pkl\"\n",
    "with open(ibm4_path, \"wb\") as f:\n",
    "    pickle.dump(ibm4, f)\n",
    "\n",
    "print(f\"\\nIBM Model 4 saved to {ibm4_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5505e-996a-460d-9791-f92519032dfd",
   "metadata": {},
   "source": [
    "#### IBM Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52483a32-3db6-4dc6-804e-40ed9c0ab260",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ibm5 = IBMModel5(\n",
    "    aligned_sents,\n",
    "    iterations=3,\n",
    "    source_word_classes=word2class,\n",
    "    target_word_classes=word2class,\n",
    ")\n",
    "print(\"\\n[IBM5] Training complete.\")\n",
    "\n",
    "ibm5_path = MODELS_DIR / \"ibm4_model.pkl\"\n",
    "with open(ibm5_path, \"wb\") as f:\n",
    "    pickle.dump(ibm5, f)\n",
    "\n",
    "print(f\"\\nIBM Model 5 saved to {ibm5_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "philippine-machine-translation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
