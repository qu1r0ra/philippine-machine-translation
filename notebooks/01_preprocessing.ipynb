{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3bf7e06",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14835614-0fac-4779-be76-3015be520f12",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "950d4a10-25f1-44cc-8a20-80bd36fc07a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f1c05d9-76ce-4882-88bf-86032bf4e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import nltk\n",
    "import multiprocessing\n",
    "\n",
    "import pandas as pd\n",
    "from src.config import RAW_DIR, PROCESSED_DIR\n",
    "from src.preprocessing import preprocess_corpus, build_word_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d30b8cf-de88-4cf2-b85e-ea6deb2f7b6b",
   "metadata": {},
   "source": [
    "First, let us download the `NLTK PUNKT` tokenizer. We will need this for preprocessing our corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e20f39f2-b263-41c9-b398-493dc366b63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\qu1r0ra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\qu1r0ra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0929edad-4d43-49cf-b892-d1ed98c3f479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\qu1r0ra\\\\Documents\\\\GitHub\\\\philippine-machine-translation'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Switch to root as working directory\n",
    "if Path.cwd().name == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeb50df",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd134e14-7704-478f-8c38-cdc65055621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 CSV files.\n",
      "Loaded: cebuano_spanish.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usfm</th>\n",
       "      <th>book</th>\n",
       "      <th>verse</th>\n",
       "      <th>chapter</th>\n",
       "      <th>language1</th>\n",
       "      <th>language2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1CH.1.1</td>\n",
       "      <td>1CH</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Si Adan, si Set, si Enos,</td>\n",
       "      <td>Adán, Set, Enós,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1CH.1.2</td>\n",
       "      <td>1CH</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>si Kenan, si Mahalalel, si Jared,</td>\n",
       "      <td>Cainán, Mahalaleel, Jared,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1CH.1.3</td>\n",
       "      <td>1CH</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>si Enoc, si Metusela, si Lamec,</td>\n",
       "      <td>Enoc, Matusalén, Lamec,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1CH.1.4</td>\n",
       "      <td>1CH</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>si Noe, si Sem, si Ham ug si Jafet.</td>\n",
       "      <td>Noé, Sem, Cam y Jafet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1CH.1.5</td>\n",
       "      <td>1CH</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Ang mga anak nga lalaki ni Jafet: si Gomer, si...</td>\n",
       "      <td>Los hijos de Jafet: Gomer, Magog, Madai, Javán...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      usfm book  verse  chapter  \\\n",
       "0  1CH.1.1  1CH      1        1   \n",
       "1  1CH.1.2  1CH      2        1   \n",
       "2  1CH.1.3  1CH      3        1   \n",
       "3  1CH.1.4  1CH      4        1   \n",
       "4  1CH.1.5  1CH      5        1   \n",
       "\n",
       "                                           language1  \\\n",
       "0                          Si Adan, si Set, si Enos,   \n",
       "1                  si Kenan, si Mahalalel, si Jared,   \n",
       "2                    si Enoc, si Metusela, si Lamec,   \n",
       "3                si Noe, si Sem, si Ham ug si Jafet.   \n",
       "4  Ang mga anak nga lalaki ni Jafet: si Gomer, si...   \n",
       "\n",
       "                                           language2  \n",
       "0                                   Adán, Set, Enós,  \n",
       "1                         Cainán, Mahalaleel, Jared,  \n",
       "2                            Enoc, Matusalén, Lamec,  \n",
       "3                             Noé, Sem, Cam y Jafet.  \n",
       "4  Los hijos de Jafet: Gomer, Magog, Madai, Javán...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = list(RAW_DIR.glob(\"**/*.csv\"))\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(\"No CSV files found in RAW_DIR.\")\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files.\")\n",
    "\n",
    "df = pd.read_csv(csv_files[0])\n",
    "print(f\"Loaded: {csv_files[0].name}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ead750-48a1-4a90-95f5-d8f60826e297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Preprocessing] Cleaning and tokenizing columns: language1, language2\n",
      "[Preprocessing] 31,105 valid sentence pairs remaining after cleaning.\n",
      "[Preprocessing] Done.\n"
     ]
    }
   ],
   "source": [
    "df_preprocessed = preprocess_corpus(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d864117-80a2-4d4a-86c7-ecbe7595c3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to C:\\Users\\qu1r0ra\\Documents\\GitHub\\philippine-machine-translation\\data\\processed\\preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "processed_path = PROCESSED_DIR / \"preprocessed.csv\"\n",
    "df_preprocessed.to_csv(processed_path, index=False)\n",
    "print(f\"Preprocessed data saved to {processed_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac76d091-0f83-4ee1-a38b-1ee73483adad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language1</th>\n",
       "      <th>language2</th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>tgt_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Si Adan, si Set, si Enos,</td>\n",
       "      <td>Adán, Set, Enós,</td>\n",
       "      <td>[si, adan, si, set, si, enos]</td>\n",
       "      <td>[adán, set, enós]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>si Kenan, si Mahalalel, si Jared,</td>\n",
       "      <td>Cainán, Mahalaleel, Jared,</td>\n",
       "      <td>[si, kenan, si, mahalalel, si, jared]</td>\n",
       "      <td>[cainán, mahalaleel, jared]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>si Enoc, si Metusela, si Lamec,</td>\n",
       "      <td>Enoc, Matusalén, Lamec,</td>\n",
       "      <td>[si, enoc, si, metusela, si, lamec]</td>\n",
       "      <td>[enoc, matusalén, lamec]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>si Noe, si Sem, si Ham ug si Jafet.</td>\n",
       "      <td>Noé, Sem, Cam y Jafet.</td>\n",
       "      <td>[si, noe, si, sem, si, ham, ug, si, jafet]</td>\n",
       "      <td>[noé, sem, cam, y, jafet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ang mga anak nga lalaki ni Jafet: si Gomer, si...</td>\n",
       "      <td>Los hijos de Jafet: Gomer, Magog, Madai, Javán...</td>\n",
       "      <td>[ang, mga, anak, nga, lalaki, ni, jafet, si, g...</td>\n",
       "      <td>[los, hijos, de, jafet, gomer, magog, madai, j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           language1  \\\n",
       "0                          Si Adan, si Set, si Enos,   \n",
       "1                  si Kenan, si Mahalalel, si Jared,   \n",
       "2                    si Enoc, si Metusela, si Lamec,   \n",
       "3                si Noe, si Sem, si Ham ug si Jafet.   \n",
       "4  Ang mga anak nga lalaki ni Jafet: si Gomer, si...   \n",
       "\n",
       "                                           language2  \\\n",
       "0                                   Adán, Set, Enós,   \n",
       "1                         Cainán, Mahalaleel, Jared,   \n",
       "2                            Enoc, Matusalén, Lamec,   \n",
       "3                             Noé, Sem, Cam y Jafet.   \n",
       "4  Los hijos de Jafet: Gomer, Magog, Madai, Javán...   \n",
       "\n",
       "                                          src_tokens  \\\n",
       "0                      [si, adan, si, set, si, enos]   \n",
       "1              [si, kenan, si, mahalalel, si, jared]   \n",
       "2                [si, enoc, si, metusela, si, lamec]   \n",
       "3         [si, noe, si, sem, si, ham, ug, si, jafet]   \n",
       "4  [ang, mga, anak, nga, lalaki, ni, jafet, si, g...   \n",
       "\n",
       "                                          tgt_tokens  \n",
       "0                                  [adán, set, enós]  \n",
       "1                        [cainán, mahalaleel, jared]  \n",
       "2                           [enoc, matusalén, lamec]  \n",
       "3                          [noé, sem, cam, y, jafet]  \n",
       "4  [los, hijos, de, jafet, gomer, magog, madai, j...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60be9f6-3407-47ae-ab95-509440e261c8",
   "metadata": {},
   "source": [
    "Let us build word classes using `FastText`, a word embedding model preferred for morphologically rich languages like Filipino."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a6d62-6476-4708-8ea1-7d0ea208a52d",
   "metadata": {},
   "source": [
    "First, we need to determine how many logical cores our computer has so we can speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e29242b0-ac71-4f84-82bd-705aa0ed4aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ea17d-7cd1-4099-8621-00f7231eb21e",
   "metadata": {},
   "source": [
    "Next, set the variable below to the value you got above (i.e., the number of logical cores your computer has) or to the number of cores you want to use (why not just use all?) and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7476c5d-5863-4940-87d9-39194360a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4a9c9b9-ba0a-48f2-ba57-575174ea19c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[FastText] Training on 62,210 sentences...\n",
      "[Clustering] Running KMeans on 19,612 word vectors (100 dims) ...\n",
      "[Clustering] Done — created 100 clusters.\n",
      "[Save] Word classes saved to C:\\Users\\qu1r0ra\\Documents\\GitHub\\philippine-machine-translation\\data\\processed\\word_classes.json\n",
      "CPU times: total: 4min 47s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word2class = build_word_classes(df_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d266ef8b-5079-4c84-9548-88a3662654b3",
   "metadata": {},
   "source": [
    "Let us inspect a few word-to-class mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6e3da2e-ad5e-49ad-b8ac-d849924de649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sa', 'c48'),\n",
       " ('ug', 'c48'),\n",
       " ('ang', 'c48'),\n",
       " ('de', 'c0'),\n",
       " ('nga', 'c48'),\n",
       " ('y', 'c80'),\n",
       " ('mga', 'c48'),\n",
       " ('a', 'c78'),\n",
       " ('que', 'c19'),\n",
       " ('la', 'c77'),\n",
       " ('el', 'c40'),\n",
       " ('los', 'c43'),\n",
       " ('en', 'c0'),\n",
       " ('si', 'c72'),\n",
       " ('iyang', 'c1'),\n",
       " ('ka', 'c41'),\n",
       " ('dios', 'c20'),\n",
       " ('ni', 'c88'),\n",
       " ('siya', 'c60'),\n",
       " ('no', 'c36')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word2class.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd1caf9-1224-445b-a56e-09bbcffd52dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61a9bed3-500f-4d8e-aa75-2abb40560833",
   "metadata": {},
   "source": [
    "With preprocessing finished, we can proceed with **modeling**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
