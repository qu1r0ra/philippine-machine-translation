{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qu1r0ra/philippine-machine-translation/blob/chore%2Fpolish-files/notebooks/02b_modeling_nmt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSZvC47w-PYi"
      },
      "source": [
        "# Modeling in Neural Machine Translation (NMT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQMiV4Pd-cHg"
      },
      "source": [
        "## Notes\n",
        "\n",
        "The author who trained the Transformer model did not have sufficient computational resources to train locally, so he decided to train it via Google Colab.\n",
        "\n",
        "Unfortunately, the free plan in Colab also did not suffice for training as the free GPUs have rate limits, so the author also decided to purchase compute units to access said GPUs. You may also need Colab compute units to replicate the results of this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWsIoY2d_2en"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ldrf4Rv_9pG"
      },
      "source": [
        "First, let us uninstall Colab's preinstalled `torch`, `torchvision`, and `torchaudio` packages.\n",
        "\n",
        "We need to downgrade them as the `OpenNMT-py` version that the authors used for training requires older versions.\n",
        "\n",
        "**NOTE:** You only need to run this the first time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8dE0Okm9lpK",
        "outputId": "d00d4128-b6e1-4135-ef73-295eb6609fb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.8.0+cu126\n",
            "Uninstalling torch-2.8.0+cu126:\n",
            "  Successfully uninstalled torch-2.8.0+cu126\n",
            "Found existing installation: torchvision 0.23.0+cu126\n",
            "Uninstalling torchvision-0.23.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.23.0+cu126\n",
            "Found existing installation: torchaudio 2.8.0+cu126\n",
            "Uninstalling torchaudio-2.8.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.8.0+cu126\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall torch torchvision torchaudio -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Nd3mFAGAZk9"
      },
      "source": [
        "Next, let us install `condacolab` so we can install the older package versions via `conda`.\n",
        "\n",
        "The authors tried using `pip` to install the older versions but they were somehow unlisted and thus could not be installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1019quAmAWik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4506c2-b755-46e4-d7ea-8af1fee81130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:08\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDMMVD5-BOby"
      },
      "source": [
        "Now we can install the older versions required by our `OpenNMT-py` version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTWpZFvyBK55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c7047d-4ff8-43a5-b48d-4fd03721579b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - pytorch\n",
            " - nvidia\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - pytorch-cuda=11.8\n",
            "    - pytorch==2.1.1\n",
            "    - torchaudio==2.1.1\n",
            "    - torchvision==0.16.1\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-4.5          |       5_kmp_llvm           8 KB  conda-forge\n",
            "    aom-3.5.0                  |       h27087fc_0         2.7 MB  conda-forge\n",
            "    blas-2.116                 |              mkl          13 KB  conda-forge\n",
            "    blas-devel-3.9.0           |   16_linux64_mkl          12 KB  conda-forge\n",
            "    ca-certificates-2025.10.5  |       hbd8a1cb_0         152 KB  conda-forge\n",
            "    certifi-2025.10.5          |     pyhd8ed1ab_0         156 KB  conda-forge\n",
            "    conda-24.11.3              |  py311h38be061_0         1.1 MB  conda-forge\n",
            "    cpython-3.11.14            |  py311hd8ed1ab_2          46 KB  conda-forge\n",
            "    cuda-cudart-11.8.89        |                0         197 KB  nvidia\n",
            "    cuda-cupti-11.8.87         |                0        25.3 MB  nvidia\n",
            "    cuda-libraries-11.8.0      |                0           1 KB  nvidia\n",
            "    cuda-nvrtc-11.8.89         |                0        19.1 MB  nvidia\n",
            "    cuda-nvtx-11.8.86          |                0          57 KB  nvidia\n",
            "    cuda-runtime-11.8.0        |                0           1 KB  nvidia\n",
            "    cuda-version-12.9          |                3          17 KB  nvidia\n",
            "    ffmpeg-5.1.2               | gpl_h8dda1f0_106         9.2 MB  conda-forge\n",
            "    filelock-3.20.0            |     pyhd8ed1ab_0          18 KB  conda-forge\n",
            "    font-ttf-dejavu-sans-mono-2.37|       hab24e00_0         388 KB  conda-forge\n",
            "    font-ttf-inconsolata-3.000 |       h77eed37_0          94 KB  conda-forge\n",
            "    font-ttf-source-code-pro-2.038|       h77eed37_0         684 KB  conda-forge\n",
            "    font-ttf-ubuntu-0.83       |       h77eed37_3         1.5 MB  conda-forge\n",
            "    fontconfig-2.15.0          |       h7e30c49_1         259 KB  conda-forge\n",
            "    fonts-conda-ecosystem-1    |                0           4 KB  conda-forge\n",
            "    fonts-conda-forge-1        |       hc364b38_1           4 KB  conda-forge\n",
            "    freetype-2.14.1            |       ha770c72_0         169 KB  conda-forge\n",
            "    gmp-6.3.0                  |       hac33072_2         449 KB  conda-forge\n",
            "    gmpy2-2.2.1                |  py311h92a432a_1         199 KB  conda-forge\n",
            "    gnutls-3.7.9               |       hb077bed_0         1.9 MB  conda-forge\n",
            "    jinja2-3.1.6               |     pyhd8ed1ab_0         110 KB  conda-forge\n",
            "    jpeg-9e                    |       h166bdaf_2         269 KB  conda-forge\n",
            "    lame-3.100                 |    h166bdaf_1003         496 KB  conda-forge\n",
            "    lcms2-2.15                 |       hfd0df8a_0         235 KB  conda-forge\n",
            "    lerc-4.0.0                 |       h0aef613_1         258 KB  conda-forge\n",
            "    libblas-3.9.0              |   16_linux64_mkl          13 KB  conda-forge\n",
            "    libcblas-3.9.0             |   16_linux64_mkl          12 KB  conda-forge\n",
            "    libcublas-11.11.3.6        |                0       364.0 MB  nvidia\n",
            "    libcufft-10.9.0.58         |                0       142.8 MB  nvidia\n",
            "    libcufile-1.14.1.1         |                4         946 KB  nvidia\n",
            "    libcurand-10.3.10.19       |                0        44.0 MB  nvidia\n",
            "    libcusolver-11.4.1.48      |                0        96.5 MB  nvidia\n",
            "    libcusparse-11.7.5.86      |                0       176.3 MB  nvidia\n",
            "    libdeflate-1.17            |       h0b41bf4_0          63 KB  conda-forge\n",
            "    libdrm-2.4.125             |       hb03c661_1         304 KB  conda-forge\n",
            "    libfreetype-2.14.1         |       ha770c72_0           7 KB  conda-forge\n",
            "    libfreetype6-2.14.1        |       h73754d4_0         378 KB  conda-forge\n",
            "    libgfortran-14.2.0         |       h69a702a_2          52 KB  conda-forge\n",
            "    libgfortran-ng-14.2.0      |       h69a702a_2          53 KB  conda-forge\n",
            "    libgfortran5-14.2.0        |       hf1ad2bd_2         1.4 MB  conda-forge\n",
            "    libhwloc-2.11.2            |default_h0d58e46_1001         2.3 MB  conda-forge\n",
            "    libidn2-2.3.8              |       hfac485b_1         136 KB  conda-forge\n",
            "    libjpeg-turbo-2.0.0        |       h9bf148f_0         950 KB  pytorch\n",
            "    liblapack-3.9.0            |   16_linux64_mkl          12 KB  conda-forge\n",
            "    liblapacke-3.9.0           |   16_linux64_mkl          12 KB  conda-forge\n",
            "    liblzma-devel-5.6.3        |       hb9d3cd8_1         368 KB  conda-forge\n",
            "    libnpp-11.8.0.86           |                0       147.8 MB  nvidia\n",
            "    libnvjpeg-11.9.0.86        |                0         2.4 MB  nvidia\n",
            "    libopus-1.5.2              |       hd0c01bc_0         305 KB  conda-forge\n",
            "    libpciaccess-0.18          |       hb9d3cd8_0          28 KB  conda-forge\n",
            "    libpng-1.6.50              |       h421ea60_1         310 KB  conda-forge\n",
            "    libtasn1-4.20.0            |       hb03c661_1         115 KB  conda-forge\n",
            "    libtiff-4.5.0              |       h6adf6a1_2         397 KB  conda-forge\n",
            "    libunistring-0.9.10        |       h7f98852_0         1.4 MB  conda-forge\n",
            "    libva-2.18.0               |       h0b41bf4_0         182 KB  conda-forge\n",
            "    libvpx-1.11.0              |       h9c3ff4c_3         1.1 MB  conda-forge\n",
            "    libwebp-base-1.6.0         |       hd42ef1d_0         419 KB  conda-forge\n",
            "    libxcb-1.13                |    h7f98852_1004         391 KB  conda-forge\n",
            "    llvm-openmp-15.0.7         |       h0cdce71_0         3.1 MB  conda-forge\n",
            "    markupsafe-3.0.3           |  py311h3778330_0          25 KB  conda-forge\n",
            "    mkl-2022.1.0               |     h84fe81f_915       199.6 MB  conda-forge\n",
            "    mkl-devel-2022.1.0         |     ha770c72_916          25 KB  conda-forge\n",
            "    mkl-include-2022.1.0       |     h84fe81f_915         745 KB  conda-forge\n",
            "    mpc-1.3.1                  |       h24ddda3_1         114 KB  conda-forge\n",
            "    mpfr-4.2.1                 |       h90cbb55_3         620 KB  conda-forge\n",
            "    mpmath-1.3.0               |     pyhd8ed1ab_1         429 KB  conda-forge\n",
            "    nettle-3.9.1               |       h7ab15ed_0         988 KB  conda-forge\n",
            "    networkx-3.5               |     pyhe01879c_0         1.5 MB  conda-forge\n",
            "    numpy-2.3.4                |  py311h2e04523_0         9.0 MB  conda-forge\n",
            "    openh264-2.3.1             |       hcb278e6_2         702 KB  conda-forge\n",
            "    openjpeg-2.5.0             |       hfec8fc6_2         344 KB  conda-forge\n",
            "    openssl-3.5.4              |       h26f9b46_0         3.0 MB  conda-forge\n",
            "    p11-kit-0.24.1             |       hc5aa10d_0         4.5 MB  conda-forge\n",
            "    pillow-9.4.0               |  py311h50def17_1        44.6 MB  conda-forge\n",
            "    pthread-stubs-0.4          |    hb9d3cd8_1002           8 KB  conda-forge\n",
            "    pytorch-2.1.1              |py3.11_cuda11.8_cudnn8.7.0_0        1.46 GB  pytorch\n",
            "    pytorch-cuda-11.8          |       h7e8668a_6           7 KB  pytorch\n",
            "    pytorch-mutex-1.0          |             cuda           3 KB  pytorch\n",
            "    pyyaml-6.0.3               |  py311h3778330_0         207 KB  conda-forge\n",
            "    svt-av1-1.4.1              |       hcb278e6_0         2.4 MB  conda-forge\n",
            "    sympy-1.14.0               |   pyh2585a3b_105         4.4 MB  conda-forge\n",
            "    tbb-2021.13.0              |       hceb3a55_1         172 KB  conda-forge\n",
            "    torchaudio-2.1.1           |      py311_cu118         6.2 MB  pytorch\n",
            "    torchtriton-2.1.0          |            py311        91.0 MB  pytorch\n",
            "    torchvision-0.16.1         |      py311_cu118         8.3 MB  pytorch\n",
            "    typing_extensions-4.15.0   |     pyhcf101f3_0          50 KB  conda-forge\n",
            "    x264-1!164.3095            |       h166bdaf_2         877 KB  conda-forge\n",
            "    x265-3.5                   |       h924138e_3         3.2 MB  conda-forge\n",
            "    xorg-fixesproto-5.0        |    hb9d3cd8_1003          11 KB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    hb9d3cd8_1003          30 KB  conda-forge\n",
            "    xorg-libx11-1.8.4          |       h0b41bf4_0         810 KB  conda-forge\n",
            "    xorg-libxau-1.0.12         |       hb9d3cd8_0          14 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.5        |       hb9d3cd8_0          19 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h0b41bf4_2          49 KB  conda-forge\n",
            "    xorg-libxfixes-5.0.3       |    h7f98852_1004          18 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    hb9d3cd8_1004          30 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    hb9d3cd8_1008          72 KB  conda-forge\n",
            "    xz-5.6.3                   |       hbcc6ac9_1          23 KB  conda-forge\n",
            "    xz-gpl-tools-5.6.3         |       hbcc6ac9_1          33 KB  conda-forge\n",
            "    xz-tools-5.6.3             |       hb9d3cd8_1          88 KB  conda-forge\n",
            "    yaml-0.2.5                 |       h280c20c_3          83 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        2.86 GB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  aom                conda-forge/linux-64::aom-3.5.0-h27087fc_0 \n",
            "  blas               conda-forge/linux-64::blas-2.116-mkl \n",
            "  blas-devel         conda-forge/linux-64::blas-devel-3.9.0-16_linux64_mkl \n",
            "  cpython            conda-forge/noarch::cpython-3.11.14-py311hd8ed1ab_2 \n",
            "  cuda-cudart        nvidia/linux-64::cuda-cudart-11.8.89-0 \n",
            "  cuda-cupti         nvidia/linux-64::cuda-cupti-11.8.87-0 \n",
            "  cuda-libraries     nvidia/linux-64::cuda-libraries-11.8.0-0 \n",
            "  cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-11.8.89-0 \n",
            "  cuda-nvtx          nvidia/linux-64::cuda-nvtx-11.8.86-0 \n",
            "  cuda-runtime       nvidia/linux-64::cuda-runtime-11.8.0-0 \n",
            "  cuda-version       nvidia/noarch::cuda-version-12.9-3 \n",
            "  ffmpeg             conda-forge/linux-64::ffmpeg-5.1.2-gpl_h8dda1f0_106 \n",
            "  filelock           conda-forge/noarch::filelock-3.20.0-pyhd8ed1ab_0 \n",
            "  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0 \n",
            "  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0 \n",
            "  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0 \n",
            "  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-h77eed37_3 \n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.15.0-h7e30c49_1 \n",
            "  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0 \n",
            "  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-hc364b38_1 \n",
            "  freetype           conda-forge/linux-64::freetype-2.14.1-ha770c72_0 \n",
            "  gmp                conda-forge/linux-64::gmp-6.3.0-hac33072_2 \n",
            "  gmpy2              conda-forge/linux-64::gmpy2-2.2.1-py311h92a432a_1 \n",
            "  gnutls             conda-forge/linux-64::gnutls-3.7.9-hb077bed_0 \n",
            "  jinja2             conda-forge/noarch::jinja2-3.1.6-pyhd8ed1ab_0 \n",
            "  jpeg               conda-forge/linux-64::jpeg-9e-h166bdaf_2 \n",
            "  lame               conda-forge/linux-64::lame-3.100-h166bdaf_1003 \n",
            "  lcms2              conda-forge/linux-64::lcms2-2.15-hfd0df8a_0 \n",
            "  lerc               conda-forge/linux-64::lerc-4.0.0-h0aef613_1 \n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-16_linux64_mkl \n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-16_linux64_mkl \n",
            "  libcublas          nvidia/linux-64::libcublas-11.11.3.6-0 \n",
            "  libcufft           nvidia/linux-64::libcufft-10.9.0.58-0 \n",
            "  libcufile          nvidia/linux-64::libcufile-1.14.1.1-4 \n",
            "  libcurand          nvidia/linux-64::libcurand-10.3.10.19-0 \n",
            "  libcusolver        nvidia/linux-64::libcusolver-11.4.1.48-0 \n",
            "  libcusparse        nvidia/linux-64::libcusparse-11.7.5.86-0 \n",
            "  libdeflate         conda-forge/linux-64::libdeflate-1.17-h0b41bf4_0 \n",
            "  libdrm             conda-forge/linux-64::libdrm-2.4.125-hb03c661_1 \n",
            "  libfreetype        conda-forge/linux-64::libfreetype-2.14.1-ha770c72_0 \n",
            "  libfreetype6       conda-forge/linux-64::libfreetype6-2.14.1-h73754d4_0 \n",
            "  libgfortran        conda-forge/linux-64::libgfortran-14.2.0-h69a702a_2 \n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-14.2.0-h69a702a_2 \n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-14.2.0-hf1ad2bd_2 \n",
            "  libhwloc           conda-forge/linux-64::libhwloc-2.11.2-default_h0d58e46_1001 \n",
            "  libidn2            conda-forge/linux-64::libidn2-2.3.8-hfac485b_1 \n",
            "  libjpeg-turbo      pytorch/linux-64::libjpeg-turbo-2.0.0-h9bf148f_0 \n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-16_linux64_mkl \n",
            "  liblapacke         conda-forge/linux-64::liblapacke-3.9.0-16_linux64_mkl \n",
            "  liblzma-devel      conda-forge/linux-64::liblzma-devel-5.6.3-hb9d3cd8_1 \n",
            "  libnpp             nvidia/linux-64::libnpp-11.8.0.86-0 \n",
            "  libnvjpeg          nvidia/linux-64::libnvjpeg-11.9.0.86-0 \n",
            "  libopus            conda-forge/linux-64::libopus-1.5.2-hd0c01bc_0 \n",
            "  libpciaccess       conda-forge/linux-64::libpciaccess-0.18-hb9d3cd8_0 \n",
            "  libpng             conda-forge/linux-64::libpng-1.6.50-h421ea60_1 \n",
            "  libtasn1           conda-forge/linux-64::libtasn1-4.20.0-hb03c661_1 \n",
            "  libtiff            conda-forge/linux-64::libtiff-4.5.0-h6adf6a1_2 \n",
            "  libunistring       conda-forge/linux-64::libunistring-0.9.10-h7f98852_0 \n",
            "  libva              conda-forge/linux-64::libva-2.18.0-h0b41bf4_0 \n",
            "  libvpx             conda-forge/linux-64::libvpx-1.11.0-h9c3ff4c_3 \n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.6.0-hd42ef1d_0 \n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h7f98852_1004 \n",
            "  llvm-openmp        conda-forge/linux-64::llvm-openmp-15.0.7-h0cdce71_0 \n",
            "  markupsafe         conda-forge/linux-64::markupsafe-3.0.3-py311h3778330_0 \n",
            "  mkl                conda-forge/linux-64::mkl-2022.1.0-h84fe81f_915 \n",
            "  mkl-devel          conda-forge/linux-64::mkl-devel-2022.1.0-ha770c72_916 \n",
            "  mkl-include        conda-forge/linux-64::mkl-include-2022.1.0-h84fe81f_915 \n",
            "  mpc                conda-forge/linux-64::mpc-1.3.1-h24ddda3_1 \n",
            "  mpfr               conda-forge/linux-64::mpfr-4.2.1-h90cbb55_3 \n",
            "  mpmath             conda-forge/noarch::mpmath-1.3.0-pyhd8ed1ab_1 \n",
            "  nettle             conda-forge/linux-64::nettle-3.9.1-h7ab15ed_0 \n",
            "  networkx           conda-forge/noarch::networkx-3.5-pyhe01879c_0 \n",
            "  numpy              conda-forge/linux-64::numpy-2.3.4-py311h2e04523_0 \n",
            "  openh264           conda-forge/linux-64::openh264-2.3.1-hcb278e6_2 \n",
            "  openjpeg           conda-forge/linux-64::openjpeg-2.5.0-hfec8fc6_2 \n",
            "  p11-kit            conda-forge/linux-64::p11-kit-0.24.1-hc5aa10d_0 \n",
            "  pillow             conda-forge/linux-64::pillow-9.4.0-py311h50def17_1 \n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-hb9d3cd8_1002 \n",
            "  pytorch            pytorch/linux-64::pytorch-2.1.1-py3.11_cuda11.8_cudnn8.7.0_0 \n",
            "  pytorch-cuda       pytorch/linux-64::pytorch-cuda-11.8-h7e8668a_6 \n",
            "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cuda \n",
            "  pyyaml             conda-forge/linux-64::pyyaml-6.0.3-py311h3778330_0 \n",
            "  svt-av1            conda-forge/linux-64::svt-av1-1.4.1-hcb278e6_0 \n",
            "  sympy              conda-forge/noarch::sympy-1.14.0-pyh2585a3b_105 \n",
            "  tbb                conda-forge/linux-64::tbb-2021.13.0-hceb3a55_1 \n",
            "  torchaudio         pytorch/linux-64::torchaudio-2.1.1-py311_cu118 \n",
            "  torchtriton        pytorch/linux-64::torchtriton-2.1.0-py311 \n",
            "  torchvision        pytorch/linux-64::torchvision-0.16.1-py311_cu118 \n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-4.15.0-pyhcf101f3_0 \n",
            "  x264               conda-forge/linux-64::x264-1!164.3095-h166bdaf_2 \n",
            "  x265               conda-forge/linux-64::x265-3.5-h924138e_3 \n",
            "  xorg-fixesproto    conda-forge/linux-64::xorg-fixesproto-5.0-hb9d3cd8_1003 \n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-hb9d3cd8_1003 \n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.8.4-h0b41bf4_0 \n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.12-hb9d3cd8_0 \n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.5-hb9d3cd8_0 \n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h0b41bf4_2 \n",
            "  xorg-libxfixes     conda-forge/linux-64::xorg-libxfixes-5.0.3-h7f98852_1004 \n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-hb9d3cd8_1004 \n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-hb9d3cd8_1008 \n",
            "  xz                 conda-forge/linux-64::xz-5.6.3-hbcc6ac9_1 \n",
            "  xz-gpl-tools       conda-forge/linux-64::xz-gpl-tools-5.6.3-hbcc6ac9_1 \n",
            "  xz-tools           conda-forge/linux-64::xz-tools-5.6.3-hb9d3cd8_1 \n",
            "  yaml               conda-forge/linux-64::yaml-0.2.5-h280c20c_3 \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates~ --> conda-forge/noarch::ca-certificates-2025.10.5-hbd8a1cb_0 \n",
            "  certifi                           2024.12.14-pyhd8ed1ab_0 --> 2025.10.5-pyhd8ed1ab_0 \n",
            "  conda                             24.11.2-py311h38be061_1 --> 24.11.3-py311h38be061_0 \n",
            "  openssl                                  3.4.0-h7b32b05_1 --> 3.5.4-h26f9b46_0 \n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-2_gnu --> 4.5-5_kmp_llvm \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "pytorch-2.1.1        | 1.46 GB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.6 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-5.1.2         | 9.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.3.4          | 9.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.16.1   | 8.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchaudio-2.1.1     | 6.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "p11-kit-0.24.1       | 4.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.14.0         | 4.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "x265-3.5             | 3.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   0% 0.0006478866996500437/1 [00:00<02:35, 155.31s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   1% 0.006568404427999548/1 [00:00<00:15, 15.29s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :   0% 0.0035221477228253/1 [00:00<00:28, 28.46s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :   0% 0.004076241637105923/1 [00:00<00:24, 24.58s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   0% 0.0033857304949453894/1 [00:00<00:53, 53.42s/it] \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   2% 0.017687468132913817/1 [00:00<00:10, 10.86s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :   3% 0.02661178279468004/1 [00:00<00:06,  6.67s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :   3% 0.028799533305639672/1 [00:00<00:06,  6.19s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   1% 0.0063639193562399455/1 [00:00<00:41, 42.09s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   3% 0.02945049305625941/1 [00:00<00:09,  9.65s/it] \u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :   5% 0.04586619034612501/1 [00:00<00:05,  5.91s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :   5% 0.051218862309722245/1 [00:00<00:04,  5.27s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   1% 0.009206261006317556/1 [00:00<00:38, 39.18s/it] \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   4% 0.03983973404695151/1 [00:00<00:09,  9.71s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :   7% 0.06715561658186904/1 [00:00<00:05,  5.37s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :   7% 0.07408126105696851/1 [00:00<00:04,  4.88s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  10% 0.09862382024176923/1 [00:00<00:03,  3.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   5% 0.05057242102080698/1 [00:00<00:09,  9.58s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :   9% 0.08617521428512566/1 [00:00<00:04,  5.34s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  10% 0.09525999478019276/1 [00:00<00:04,  4.82s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   1% 0.011766458448483052/1 [00:00<00:39, 39.90s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   6% 0.0633657838936427/1 [00:00<00:08,  8.91s/it] \u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  11% 0.10558616173536287/1 [00:00<00:04,  5.28s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   1% 0.014567000956647756/1 [00:00<00:37, 38.43s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  16% 0.15760784135099454/1 [00:00<00:03,  3.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  14% 0.13664270879168114/1 [00:00<00:04,  4.95s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  12% 0.12452748948922338/1 [00:00<00:04,  5.53s/it]\u001b[A\u001b[A\n",
            "pytorch-2.1.1        | 1.46 GB   | :   2% 0.017179447326204383/1 [00:00<00:39, 40.16s/it]\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  18% 0.18498572928520488/1 [00:00<00:03,  3.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  16% 0.15720114487447623/1 [00:00<00:04,  4.93s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   2% 0.02000088940532554/1 [00:00<00:37, 38.60s/it] \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :   9% 0.08538925756399413/1 [00:00<00:08,  9.51s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  21% 0.21225791108839506/1 [00:00<00:02,  3.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  18% 0.17758235306000586/1 [00:00<00:04,  4.93s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   2% 0.022602885989403944/1 [00:00<00:38, 38.89s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  10% 0.09595022154626791/1 [00:00<00:08,  9.73s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  24% 0.23910726836750482/1 [00:00<00:03,  3.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  20% 0.19787494729690272/1 [00:01<00:03,  4.96s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   3% 0.025183983002525893/1 [00:01<00:38, 39.61s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  11% 0.10775617721750892/1 [00:01<00:08,  9.33s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  27% 0.2658509195155944/1 [00:01<00:02,  3.89s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  22% 0.21931952286602518/1 [00:01<00:03,  4.87s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   3% 0.027723280873734935/1 [00:01<00:38, 39.92s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  12% 0.11853179493925982/1 [00:01<00:08,  9.50s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  29% 0.2917489216155231/1 [00:01<00:02,  4.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  24% 0.23996657289745302/1 [00:01<00:03,  4.87s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   3% 0.030241679173987523/1 [00:01<00:38, 40.10s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  13% 0.1290927589215336/1 [00:01<00:08,  9.75s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  32% 0.31880969115667307/1 [00:01<00:02,  3.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  26% 0.26212006005563737/1 [00:01<00:03,  4.77s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   3% 0.03273917790328366/1 [00:01<00:39, 40.45s/it] \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  14% 0.13939613841643486/1 [00:01<00:08,  9.95s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  34% 0.34449628099456153/1 [00:01<00:02,  3.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  28% 0.28427354721382175/1 [00:01<00:03,  4.69s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   4% 0.03540387320023142/1 [00:01<00:38, 39.57s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  15% 0.149484864171859/1 [00:01<00:08, 10.00s/it]  \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  37% 0.37071140148755055/1 [00:01<00:02,  3.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  31% 0.30562950883431145/1 [00:01<00:03,  4.76s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   4% 0.03795362085691869/1 [00:01<00:38, 39.53s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  16% 0.15978824366676025/1 [00:01<00:08,  9.93s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  40% 0.3962922851944189/1 [00:01<00:02,  3.97s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  33% 0.32858052153019046/1 [00:01<00:03,  4.64s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   4% 0.040660115295779356/1 [00:01<00:37, 38.74s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  17% 0.1712507533548379/1 [00:01<00:07,  9.55s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  42% 0.4235644669976091/1 [00:01<00:02,  3.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  35% 0.35108846448290576/1 [00:01<00:02,  4.58s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   4% 0.043293461236292435/1 [00:01<00:36, 38.58s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  18% 0.18378653174030107/1 [00:01<00:07,  9.03s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  46% 0.45855319636526787/1 [00:01<00:01,  3.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  37% 0.37368502138425386/1 [00:01<00:02,  4.53s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   5% 0.04607310417350069/1 [00:01<00:36, 37.78s/it] \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  20% 0.19589300264681006/1 [00:01<00:07,  8.80s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  49% 0.49216774602966507/1 [00:01<00:01,  3.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  40% 0.39840831305278757/1 [00:01<00:02,  4.38s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   5% 0.04872734968497022/1 [00:01<00:37, 39.11s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  21% 0.20731258158699228/1 [00:01<00:07,  9.37s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  52% 0.5222939933703984/1 [00:01<00:01,  3.59s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | :  42% 0.42242269313225944/1 [00:02<00:02,  4.31s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   5% 0.05129799691261394/1 [00:02<00:37, 39.16s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  22% 0.21808819930874315/1 [00:02<00:07,  9.72s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  55% 0.5505175303527697/1 [00:02<00:01,  3.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   5% 0.0541194389917351/1 [00:02<00:35, 37.99s/it] \n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  41% 0.41169993382357944/1 [00:02<00:02,  5.07s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  23% 0.2289496785262849/1 [00:02<00:07,  9.58s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  58% 0.5790581857282013/1 [00:02<00:01,  3.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   6% 0.05699312999824739/1 [00:02<00:34, 37.02s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  43% 0.43251974036294677/1 [00:02<00:02,  4.99s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  24% 0.24105614943279388/1 [00:02<00:06,  9.16s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  61% 0.6064360736624116/1 [00:02<00:01,  3.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   6% 0.05969962443710806/1 [00:02<00:35, 37.72s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  45% 0.45271338730714517/1 [00:02<00:02,  5.02s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  25% 0.2531196895914074/1 [00:02<00:06,  8.89s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  63% 0.6336025493345817/1 [00:02<00:01,  3.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   6% 0.06236431973405582/1 [00:02<00:36, 38.70s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  47% 0.47275049435255134/1 [00:02<00:02,  5.10s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  26% 0.2644534070357988/1 [00:02<00:06,  9.17s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  66% 0.6644687395924559/1 [00:02<00:01,  3.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   7% 0.06561420301778426/1 [00:02<00:33, 36.01s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  50% 0.4974837983617245/1 [00:02<00:02,  4.74s/it] \u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  28% 0.27600177821966726/1 [00:02<00:06,  9.03s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  69% 0.6927979827058472/1 [00:02<00:01,  3.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   7% 0.06840429574047074/1 [00:02<00:33, 36.18s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  52% 0.5186949546480725/1 [00:02<00:02,  4.82s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  29% 0.28716377267247695/1 [00:02<00:06,  9.31s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  72% 0.7208101074261783/1 [00:02<00:01,  3.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   7% 0.071183938677679/1 [00:02<00:34, 36.69s/it]  \n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  54% 0.5395930311368359/1 [00:02<00:02,  4.92s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  30% 0.298154044133705/1 [00:02<00:06,  9.26s/it]  \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  75% 0.7505135302428312/1 [00:02<00:00,  3.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   7% 0.07410987861158241/1 [00:02<00:33, 35.97s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  56% 0.5618999667147294/1 [00:02<00:02,  4.79s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  31% 0.30910138484703753/1 [00:02<00:06,  9.23s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  78% 0.7787370672252024/1 [00:02<00:00,  3.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   8% 0.0772970631824415/1 [00:02<00:31, 34.51s/it] \n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  59% 0.586868080572091/1 [00:02<00:01,  4.53s/it] \u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  32% 0.3202633792998472/1 [00:03<00:06,  9.15s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  81% 0.8067491919455335/1 [00:03<00:00,  3.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   8% 0.0802125533308667/1 [00:03<00:31, 34.46s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  61% 0.6090184762511923/1 [00:03<00:01,  4.67s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  33% 0.3317688197358203/1 [00:03<00:06,  9.02s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  84% 0.8358183779760656/1 [00:03<00:00,  3.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   8% 0.08318029240668302/1 [00:03<00:31, 34.25s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  63% 0.6305427123351247/1 [00:03<00:01,  4.69s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  34% 0.34288788344073456/1 [00:03<00:05,  9.11s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  86% 0.864041914958437/1 [00:03<00:00,  3.60s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   9% 0.08610623234058645/1 [00:03<00:32, 35.78s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  65% 0.651988678469661/1 [00:03<00:01,  4.85s/it] \u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  35% 0.3544791853724985/1 [00:03<00:05,  8.97s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  89% 0.893005394857949/1 [00:03<00:00,  3.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   9% 0.08891722463422938/1 [00:03<00:32, 35.90s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  67% 0.6727302150596323/1 [00:03<00:01,  4.92s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  37% 0.3660704873042624/1 [00:03<00:05,  8.87s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  92% 0.9212289318403203/1 [00:03<00:00,  3.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   9% 0.09183271478265458/1 [00:03<00:32, 35.44s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  69% 0.6945675309411491/1 [00:03<00:01,  4.82s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  38% 0.3782628197065622/1 [00:03<00:05,  8.67s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  95% 0.9504038240018726/1 [00:03<00:00,  3.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :   9% 0.09466460664725396/1 [00:03<00:32, 35.42s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  72% 0.7171875463166271/1 [00:03<00:01,  4.70s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  39% 0.3898111908904307/1 [00:03<00:05,  8.92s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | :  98% 0.9790501855083243/1 [00:03<00:00,  3.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  10% 0.0976323457230703/1 [00:03<00:31, 34.93s/it] \n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  74% 0.7385552425017673/1 [00:03<00:01,  4.84s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  40% 0.4010590468390312/1 [00:03<00:05,  8.91s/it]\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  10% 0.10070458265366888/1 [00:03<00:30, 34.19s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  76% 0.7644625957518822/1 [00:03<00:01,  4.51s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  41% 0.4147968861655662/1 [00:03<00:04,  8.36s/it]\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  10% 0.10396491572287556/1 [00:03<00:29, 33.07s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  79% 0.7903699490019972/1 [00:03<00:00,  4.30s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  43% 0.4279766257694608/1 [00:03<00:04,  8.12s/it]\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  11% 0.10766413978216774/1 [00:03<00:27, 31.01s/it]\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  82% 0.8159642224545277/1 [00:04<00:00,  4.18s/it]\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  44% 0.4412422268691461/1 [00:04<00:04,  7.95s/it]\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  11% 0.11098717156424377/1 [00:04<00:27, 30.76s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  45% 0.4548942046998903/1 [00:04<00:04,  7.75s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  84% 0.8399930969191359/1 [00:04<00:00,  4.24s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  11% 0.11424750463345044/1 [00:04<00:28, 32.16s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  47% 0.4681598057995756/1 [00:04<00:04,  7.70s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  87% 0.8659004501692509/1 [00:04<00:00,  4.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  12% 0.11781088148152569/1 [00:04<00:27, 30.86s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  48% 0.4818976451261106/1 [00:04<00:03,  7.58s/it]\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | :  89% 0.8923556930651387/1 [00:04<00:00,  4.02s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  12% 0.12164595275203481/1 [00:04<00:25, 29.29s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  50% 0.4980825370826847/1 [00:04<00:03,  7.10s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  13% 0.1264946532139319/1 [00:04<00:22, 26.06s/it] \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  52% 0.5177877503666833/1 [00:04<00:03,  6.35s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  13% 0.1307477159035701/1 [00:04<00:21, 25.25s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  54% 0.5353034955080155/1 [00:04<00:02,  6.14s/it]\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  14% 0.13562776572190188/1 [00:04<00:20, 23.63s/it]\n",
            "pytorch-2.1.1        | 1.46 GB   | :  14% 0.14188718722335955/1 [00:04<00:17, 20.68s/it]\n",
            "pytorch-2.1.1        | 1.46 GB   | :  15% 0.1482929057215124/1 [00:04<00:16, 18.86s/it] \n",
            "pytorch-2.1.1        | 1.46 GB   | :  15% 0.15393578987975473/1 [00:05<00:15, 18.51s/it]\n",
            "pytorch-2.1.1        | 1.46 GB   | :  16% 0.1603415083779076/1 [00:05<00:14, 17.54s/it] \n",
            "pytorch-2.1.1        | 1.46 GB   | :  17% 0.1660575410344975/1 [00:05<00:14, 17.61s/it]\n",
            "pytorch-2.1.1        | 1.46 GB   | :  17% 0.1718258226184785/1 [00:05<00:14, 17.54s/it]\n",
            "pytorch-2.1.1        | 1.46 GB   | :  18% 0.17778220034106762/1 [00:05<00:14, 17.31s/it]\n",
            "pytorch-2.1.1        | 1.46 GB   | :  18% 0.1838012767765261/1 [00:05<00:13, 17.10s/it] \n",
            "pytorch-2.1.1        | 1.46 GB   | :  19% 0.18970540557172408/1 [00:05<00:13, 17.06s/it]\n",
            "pytorch-2.1.1        | 1.46 GB   | :  20% 0.19573493179266077/1 [00:05<00:13, 16.92s/it]\n",
            "pytorch-2.1.1        | 1.46 GB   | :  20% 0.20203615243603137/1 [00:05<00:13, 16.59s/it]\n",
            "pytorch-2.1.1        | 1.46 GB   | :  21% 0.2083896220067931/1 [00:05<00:12, 16.34s/it] \n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | : 100% 1.0/1 [00:05<00:00,  3.59s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  86% 0.8568547972447254/1 [00:05<00:00,  4.22s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  21% 0.2145131962970338/1 [00:06<00:14, 19.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :   4% 0.040811766576002/1 [00:06<01:40, 104.78s/it]          \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  88% 0.8806384315787891/1 [00:06<00:00,  4.99s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  22% 0.2199888838876245/1 [00:06<00:17, 21.85s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  90% 0.9016315672996503/1 [00:06<00:00,  5.35s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  22% 0.22484803413499985/1 [00:06<00:18, 23.38s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  16% 0.1587610544283617/1 [00:06<00:14, 17.00s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  92% 0.9211221268441719/1 [00:06<00:00,  5.81s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  23% 0.229330992105159/1 [00:06<00:18, 24.16s/it]  \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  94% 0.9389813179686675/1 [00:06<00:00,  5.88s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  23% 0.23360495436575365/1 [00:06<00:19, 25.11s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  96% 0.9564112016142087/1 [00:06<00:00,  6.03s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  24% 0.237680370702262/1 [00:06<00:19, 25.36s/it]  \n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  97% 0.9732829855371095/1 [00:06<00:00,  6.15s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  24% 0.24168263854042274/1 [00:06<00:19, 26.20s/it]\n",
            "libcublas-11.11.3.6  | 364.0 MB  | :  99% 0.989725461981056/1 [00:06<00:00,  6.16s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  35% 0.35067483076698774/1 [00:06<00:02,  4.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  25% 0.24647909007492871/1 [00:06<00:18, 24.53s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   0% 0.0001619872369599508/1 [00:06<11:55:36, 42943.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  25% 0.2506172051243064/1 [00:07<00:18, 25.06s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :   5% 0.04908213279886509/1 [00:07<01:36, 101.35s/it]       \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  44% 0.4406138981275069/1 [00:07<00:01,  3.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  25% 0.25465082231890185/1 [00:07<00:21, 28.75s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  48% 0.47923736622758384/1 [00:07<00:01,  3.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  26% 0.25825599830889/1 [00:07<00:23, 31.12s/it]   \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  52% 0.5151254612327545/1 [00:07<00:01,  3.47s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  26% 0.261579030090966/1 [00:07<00:24, 32.72s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  22% 0.21819680818505374/1 [00:07<00:09, 12.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  26% 0.26471396573443395/1 [00:07<00:24, 33.38s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  26% 0.26225733663816037/1 [00:07<00:06,  8.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  27% 0.2677548533085979/1 [00:07<00:24, 33.30s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  31% 0.3137692779914247/1 [00:07<00:04,  6.23s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  27% 0.2713495795131078/1 [00:07<00:23, 31.62s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  37% 0.365443206581649/1 [00:07<00:03,  4.76s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  27% 0.27455766365492335/1 [00:07<00:23, 32.17s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  41% 0.41241950530003474/1 [00:07<00:02,  3.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  28% 0.2778075469386518/1 [00:07<00:22, 31.78s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  46% 0.4629595232315394/1 [00:07<00:01,  3.34s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  28% 0.28098428172403267/1 [00:08<00:22, 31.75s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  51% 0.510583770897765/1 [00:08<00:01,  2.98s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  75% 0.7479604190711788/1 [00:08<00:00,  3.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  28% 0.2841505667239353/1 [00:08<00:22, 31.73s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   0% 0.00017172886155179142/1 [00:08<13:12:12, 47540.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  56% 0.5606378271183897/1 [00:08<00:01,  2.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  78% 0.7800189917434807/1 [00:08<00:00,  3.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   3% 0.03245675483328858/1 [00:08<02:53, 179.45s/it]        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  29% 0.2873168517238379/1 [00:08<00:25, 36.35s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  81% 0.8102175107112463/1 [00:08<00:00,  3.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :   7% 0.06920673120537195/1 [00:08<01:05, 70.18s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  29% 0.29016964315939375/1 [00:08<00:27, 38.97s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  11% 0.1083609116391804/1 [00:08<00:33, 37.39s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  84% 0.8384465610506793/1 [00:08<00:00,  3.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  29% 0.2928238886708633/1 [00:08<00:28, 40.60s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  14% 0.144080514841953/1 [00:08<00:20, 24.01s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  87% 0.8650343875331685/1 [00:08<00:00,  3.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | :  73% 0.7338021834285772/1 [00:08<00:00,  2.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  30% 0.29534228697111586/1 [00:08<00:29, 41.81s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  89% 0.890856309549084/1 [00:08<00:00,  4.00s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  22% 0.2167218232783608/1 [00:08<00:09, 11.78s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  30% 0.2977770869875426/1 [00:08<00:29, 42.60s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  92% 0.916021742022222/1 [00:08<00:00,  4.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  25% 0.25295661306578876/1 [00:08<00:06,  8.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  30% 0.3001491882911001/1 [00:08<00:31, 44.40s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  94% 0.9405306849525824/1 [00:08<00:00,  4.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  29% 0.2886762162685614/1 [00:08<00:04,  6.93s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  30% 0.30242724152535344/1 [00:09<00:31, 44.81s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  96% 0.9647113831115541/1 [00:09<00:00,  4.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  32% 0.32405236174823043/1 [00:09<00:03,  5.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  30% 0.30467394540317216/1 [00:09<00:31, 44.83s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | :  99% 0.9886732514229333/1 [00:09<00:00,  4.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  36% 0.3592567783663477/1 [00:09<00:03,  4.83s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  31% 0.3069415488519473/1 [00:09<00:30, 44.67s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  40% 0.40115862058498475/1 [00:09<00:02,  4.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  31% 0.30943904758124346/1 [00:09<00:29, 43.23s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | :  45% 0.44529293800379516/1 [00:09<00:01,  3.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  31% 0.3120096948088872/1 [00:09<00:28, 41.94s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  32% 0.3156148707988753/1 [00:09<00:24, 36.48s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  32% 0.3197738854192095/1 [00:09<00:21, 31.67s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  32% 0.3231596159141549/1 [00:09<00:20, 31.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  33% 0.326764791904143/1 [00:09<00:20, 29.96s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  33% 0.330223670897436/1 [00:09<00:19, 29.64s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  33% 0.3338183971019459/1 [00:10<00:19, 29.08s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  34% 0.3372668263097606/1 [00:10<00:19, 29.51s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  34% 0.34120639543505205/1 [00:10<00:18, 28.18s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  39% 0.3929850824796644/1 [00:11<00:09, 15.55s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | : 100% 1.0/1 [00:11<00:00,  2.67s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  40% 0.39942215033425194/1 [00:11<00:09, 15.76s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.6 MB   | :  13% 0.12590868879201783/1 [00:11<00:54, 62.45s/it]        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  41% 0.40577561990501365/1 [00:11<00:11, 18.97s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  41% 0.4113558053503866/1 [00:11<00:12, 20.76s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  42% 0.41643440109280466/1 [00:11<00:13, 22.64s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  42% 0.421063656059659/1 [00:11<00:14, 24.91s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.6 MB   | :  76% 0.763167985547161/1 [00:11<00:01,  4.42s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | : 100% 1.0/1 [00:11<00:00,  4.28s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | :   0% 0.00035504780175590466/1 [00:11<9:14:35, 33287.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  43% 0.42525402003642787/1 [00:11<00:15, 26.62s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | :   9% 0.08698671143019665/1 [00:11<01:27, 96.37s/it]        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  43% 0.4291308904488499/1 [00:12<00:16, 29.58s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | :  17% 0.1736183750586374/1 [00:12<00:33, 40.46s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | : 100% 1.0/1 [00:12<00:00,  1.82s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  43% 0.4327256166533598/1 [00:12<00:16, 29.18s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | :  28% 0.27906757218014105/1 [00:12<00:14, 20.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  44% 0.44030171112507405/1 [00:12<00:15, 27.90s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | :  44% 0.43512258167223067/1 [00:12<00:09, 16.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | :  37% 0.3728001918436999/1 [00:12<00:08, 13.55s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  44% 0.4439591360424533/1 [00:12<00:16, 30.11s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  45% 0.44735531632287695/1 [00:12<00:17, 31.53s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | :  83% 0.8313066368595884/1 [00:12<00:01,  6.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | :  56% 0.5560048575497467/1 [00:12<00:02,  6.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  45% 0.4505843000356489/1 [00:12<00:20, 36.87s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  45% 0.4539595807451161/1 [00:12<00:19, 34.81s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  46% 0.45753340737866954/1 [00:12<00:17, 32.77s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.6 MB   | : 100% 1.0/1 [00:12<00:00,  2.70s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  46% 0.46100273615744075/1 [00:13<00:17, 31.61s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | :  21% 0.2122499635150532/1 [00:13<00:34, 43.39s/it]        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  46% 0.46426306922664745/1 [00:13<00:17, 32.33s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-5.1.2         | 9.2 MB    | :   0% 0.0017028885600582624/1 [00:13<2:08:32, 7726.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  47% 0.4674293542265501/1 [00:13<00:17, 32.99s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-5.1.2         | 9.2 MB    | :  43% 0.4342365828148569/1 [00:13<00:12, 21.47s/it]       \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  47% 0.4705120409426269/1 [00:13<00:18, 34.70s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-5.1.2         | 9.2 MB    | :  87% 0.8650673885095973/1 [00:13<00:01,  9.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  48% 0.4762698727411297/1 [00:13<00:19, 37.18s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-5.1.2         | 9.2 MB    | : 100% 1.0/1 [00:13<00:00,  9.04s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  48% 0.47900771653642504/1 [00:13<00:19, 37.51s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  48% 0.48197545561224137/1 [00:13<00:18, 36.37s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | : 100% 1.0/1 [00:13<00:00,  6.16s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  49% 0.48805723076056917/1 [00:13<00:13, 27.06s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.16.1   | 8.3 MB    | :   0% 0.0018771719552068092/1 [00:13<2:03:23, 7417.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchaudio-2.1.1     | 6.2 MB    | :   0% 0.0025039540742056205/1 [00:13<1:32:37, 5571.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.3.4          | 9.0 MB    | : 100% 1.0/1 [00:13<00:00,  8.13s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  49% 0.4935433681366381/1 [00:14<00:12, 23.74s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "p11-kit-0.24.1       | 4.5 MB    | :   0% 0.0034841064226090947/1 [00:14<1:06:48, 4022.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.16.1   | 8.3 MB    | :  61% 0.6063265415317993/1 [00:14<00:06, 16.26s/it]       \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchaudio-2.1.1     | 6.2 MB    | :  64% 0.6385082889224332/1 [00:14<00:05, 15.47s/it]       \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  50% 0.49782778018271095/1 [00:14<00:13, 27.27s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "p11-kit-0.24.1       | 4.5 MB    | : 100% 1.0/1 [00:14<00:00, 12.83s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchaudio-2.1.1     | 6.2 MB    | : 100% 1.0/1 [00:14<00:00, 15.47s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.16.1   | 8.3 MB    | : 100% 1.0/1 [00:14<00:00, 16.26s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  51% 0.505623320149468/1 [00:14<00:10, 21.00s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "x265-3.5             | 3.2 MB    | :   0% 0.004880274801411181/1 [00:14<48:27, 2921.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-2.1.1        | 1.46 GB   | :  51% 0.5106496669644949/1 [00:14<00:11, 23.21s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "x265-3.5             | 3.2 MB    | : 100% 1.0/1 [00:14<00:00, 10.14s/it]                   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "x265-3.5             | 3.2 MB    | : 100% 1.0/1 [00:14<00:00, 10.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.14.0         | 4.4 MB    | : 100% 1.0/1 [00:14<00:00, 12.20s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.1        | 1.46 GB   | : 100% 1.0/1 [00:24<00:00,  9.01s/it]              \n",
            "\n",
            "\n",
            "\n",
            "libnpp-11.8.0.86     | 147.8 MB  | : 100% 1.0/1 [00:28<00:00,  3.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libcusparse-11.7.5.8 | 176.3 MB  | : 100% 1.0/1 [00:31<00:00,  3.73s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2022.1.0         | 199.6 MB  | : 100% 1.0/1 [00:44<00:00,  3.22s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcusolver-11.4.1.4 | 96.5 MB   | : 100% 1.0/1 [00:45<00:00,  2.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pillow-9.4.0         | 44.6 MB   | : 100% 1.0/1 [00:46<00:00,  2.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcufft-10.9.0.58   | 142.8 MB  | : 100% 1.0/1 [00:49<00:00,  4.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-5.1.2         | 9.2 MB    | : 100% 1.0/1 [00:49<00:00,  9.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-cupti-11.8.87   | 25.3 MB   | : 100% 1.0/1 [00:49<00:00,  6.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurand-10.3.10.19 | 44.0 MB   | : 100% 1.0/1 [00:50<00:00,  2.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.3.4          | 9.0 MB    | : 100% 1.0/1 [00:50<00:00,  8.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "p11-kit-0.24.1       | 4.5 MB    | : 100% 1.0/1 [00:51<00:00, 12.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchaudio-2.1.1     | 6.2 MB    | : 100% 1.0/1 [00:51<00:00, 15.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cuda-nvrtc-11.8.89   | 19.1 MB   | : 100% 1.0/1 [00:52<00:00,  6.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "x265-3.5             | 3.2 MB    | : 100% 1.0/1 [00:53<00:00, 10.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.16.1   | 8.3 MB    | : 100% 1.0/1 [00:53<00:00, 16.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sympy-1.14.0         | 4.4 MB    | : 100% 1.0/1 [00:53<00:00, 12.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "torchtriton-2.1.0    | 91.0 MB   | : 100% 1.0/1 [00:57<00:00,  1.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-2.1.1        | 1.46 GB   | : 100% 1.0/1 [03:55<00:00,  9.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n"
          ]
        }
      ],
      "source": [
        "!conda install pytorch==2.1.1 torchvision==0.16.1 torchaudio==2.1.1 \\\n",
        "  pytorch-cuda=11.8 -c pytorch -c nvidia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEg9TMhhNXR7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0430560-3a3d-4623-b466-ff4a366a3337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting OpenNMT-py==3.4.3\n",
            "  Downloading OpenNMT_py-3.4.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: torch<2.2,>=2.0.1 in /usr/local/lib/python3.11/site-packages (from OpenNMT-py==3.4.3) (2.1.1)\n",
            "Collecting configargparse (from OpenNMT-py==3.4.3)\n",
            "  Downloading configargparse-1.7.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ctranslate2<4,>=3.17 (from OpenNMT-py==3.4.3)\n",
            "  Downloading ctranslate2-3.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting tensorboard>=2.3 (from OpenNMT-py==3.4.3)\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting flask (from OpenNMT-py==3.4.3)\n",
            "  Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting waitress (from OpenNMT-py==3.4.3)\n",
            "  Downloading waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting pyonmttok<2,>=1.35 (from OpenNMT-py==3.4.3)\n",
            "  Downloading pyonmttok-1.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/site-packages (from OpenNMT-py==3.4.3) (6.0.3)\n",
            "Collecting sacrebleu (from OpenNMT-py==3.4.3)\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "Collecting rapidfuzz (from OpenNMT-py==3.4.3)\n",
            "  Downloading rapidfuzz-3.14.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Collecting pyahocorasick (from OpenNMT-py==3.4.3)\n",
            "  Downloading pyahocorasick-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting fasttext-wheel (from OpenNMT-py==3.4.3)\n",
            "  Downloading fasttext_wheel-0.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting spacy (from OpenNMT-py==3.4.3)\n",
            "  Downloading spacy-3.8.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Collecting six (from OpenNMT-py==3.4.3)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/site-packages (from ctranslate2<4,>=3.17->OpenNMT-py==3.4.3) (65.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from ctranslate2<4,>=3.17->OpenNMT-py==3.4.3) (2.3.4)\n",
            "Collecting absl-py>=0.4 (from tensorboard>=2.3->OpenNMT-py==3.4.3)\n",
            "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard>=2.3->OpenNMT-py==3.4.3)\n",
            "  Downloading grpcio-1.76.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard>=2.3->OpenNMT-py==3.4.3)\n",
            "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from tensorboard>=2.3->OpenNMT-py==3.4.3) (24.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/site-packages (from tensorboard>=2.3->OpenNMT-py==3.4.3) (9.4.0)\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard>=2.3->OpenNMT-py==3.4.3)\n",
            "  Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.3->OpenNMT-py==3.4.3)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard>=2.3->OpenNMT-py==3.4.3)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch<2.2,>=2.0.1->OpenNMT-py==3.4.3) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/site-packages (from torch<2.2,>=2.0.1->OpenNMT-py==3.4.3) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch<2.2,>=2.0.1->OpenNMT-py==3.4.3) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch<2.2,>=2.0.1->OpenNMT-py==3.4.3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch<2.2,>=2.0.1->OpenNMT-py==3.4.3) (3.1.6)\n",
            "Collecting fsspec (from torch<2.2,>=2.0.1->OpenNMT-py==3.4.3)\n",
            "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel->OpenNMT-py==3.4.3)\n",
            "  Downloading pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting blinker>=1.9.0 (from flask->OpenNMT-py==3.4.3)\n",
            "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting click>=8.1.3 (from flask->OpenNMT-py==3.4.3)\n",
            "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting itsdangerous>=2.2.0 (from flask->OpenNMT-py==3.4.3)\n",
            "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/site-packages (from flask->OpenNMT-py==3.4.3) (3.0.3)\n",
            "Collecting portalocker (from sacrebleu->OpenNMT-py==3.4.3)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting regex (from sacrebleu->OpenNMT-py==3.4.3)\n",
            "  Downloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting tabulate>=0.8.9 (from sacrebleu->OpenNMT-py==3.4.3)\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/site-packages (from sacrebleu->OpenNMT-py==3.4.3) (0.4.6)\n",
            "Collecting lxml (from sacrebleu->OpenNMT-py==3.4.3)\n",
            "  Downloading lxml-6.0.2-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading murmurhash-1.0.13-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2 (from spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
            "Collecting preshed<3.1.0,>=3.0.2 (from spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading preshed-3.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading thinc-8.3.8-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (15 kB)\n",
            "Collecting wasabi<1.2.0,>=0.9.1 (from spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3 (from spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6 (from spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting weasel<0.5.0,>=0.4.2 (from spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading weasel-0.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/site-packages (from spacy->OpenNMT-py==3.4.3) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/site-packages (from spacy->OpenNMT-py==3.4.3) (2.32.3)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py==3.4.3) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py==3.4.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py==3.4.3) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py==3.4.3) (2025.10.5)\n",
            "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading blis-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading smart_open-7.4.4-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy->torch<2.2,>=2.0.1->OpenNMT-py==3.4.3) (1.3.0)\n",
            "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy->OpenNMT-py==3.4.3)\n",
            "  Downloading wrapt-2.0.1-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
            "Downloading OpenNMT_py-3.4.3-py3-none-any.whl (257 kB)\n",
            "Downloading ctranslate2-3.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m37.0/37.0 MB\u001b[0m \u001b[31m150.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyonmttok-1.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m162.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m125.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading configargparse-1.7.1-py3-none-any.whl (25 kB)\n",
            "Downloading fasttext_wheel-0.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m168.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask-3.1.2-py3-none-any.whl (103 kB)\n",
            "Downloading pyahocorasick-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (113 kB)\n",
            "Downloading rapidfuzz-3.14.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m124.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading spacy-3.8.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m32.3/32.3 MB\u001b[0m \u001b[31m158.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading waitress-3.0.2-py3-none-any.whl (56 kB)\n",
            "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
            "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
            "Downloading cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (218 kB)\n",
            "Downloading grpcio-1.76.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m191.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading markdown-3.10-py3-none-any.whl (107 kB)\n",
            "Downloading murmurhash-1.0.13-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (123 kB)\n",
            "Downloading preshed-3.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (842 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m842.9/842.9 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
            "Downloading pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
            "Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
            "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
            "Downloading srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m132.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.8-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m140.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
            "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
            "Downloading weasel-0.4.2-py3-none-any.whl (50 kB)\n",
            "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
            "Downloading lxml-6.0.2-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m152.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m800.4/800.4 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading blis-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m183.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)\n",
            "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
            "Downloading smart_open-7.4.4-py3-none-any.whl (63 kB)\n",
            "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading wrapt-2.0.1-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (114 kB)\n",
            "Installing collected packages: cymem, wrapt, werkzeug, wasabi, waitress, typing-inspection, tensorboard-data-server, tabulate, spacy-loggers, spacy-legacy, six, regex, rapidfuzz, pyonmttok, pydantic-core, pybind11, pyahocorasick, protobuf, portalocker, murmurhash, markdown, lxml, itsdangerous, grpcio, fsspec, ctranslate2, configargparse, cloudpathlib, click, catalogue, blis, blinker, annotated-types, absl-py, typer-slim, tensorboard, srsly, smart-open, sacrebleu, pydantic, preshed, flask, fasttext-wheel, confection, weasel, thinc, spacy, OpenNMT-py\n",
            "Successfully installed OpenNMT-py-3.4.3 absl-py-2.3.1 annotated-types-0.7.0 blinker-1.9.0 blis-1.3.0 catalogue-2.0.10 click-8.3.0 cloudpathlib-0.23.0 confection-0.1.5 configargparse-1.7.1 ctranslate2-3.24.0 cymem-2.0.11 fasttext-wheel-0.9.2 flask-3.1.2 fsspec-2025.10.0 grpcio-1.76.0 itsdangerous-2.2.0 lxml-6.0.2 markdown-3.10 murmurhash-1.0.13 portalocker-3.2.0 preshed-3.0.10 protobuf-6.33.0 pyahocorasick-2.2.0 pybind11-3.0.1 pydantic-2.12.4 pydantic-core-2.41.5 pyonmttok-1.37.1 rapidfuzz-3.14.3 regex-2025.11.3 sacrebleu-2.5.1 six-1.17.0 smart-open-7.4.4 spacy-3.8.8 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 tabulate-0.9.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 thinc-8.3.8 typer-slim-0.20.0 typing-inspection-0.4.2 waitress-3.0.2 wasabi-1.1.3 weasel-0.4.2 werkzeug-3.1.3 wrapt-2.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "six"
                ]
              },
              "id": "7e1828c9f4ef4445be84ce7175a1e3ea"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install OpenNMT-py==3.4.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo-aY8v_GvcJ"
      },
      "source": [
        "Lastly, let us create the folders where we will be uploading our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFmxj14sGYgw"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MDVAtcXBlCV"
      },
      "source": [
        "## Data Upload"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTeyEJ4lCHMM"
      },
      "source": [
        "Next, we need to upload the necessary files to train our model.\n",
        "\n",
        "At this point, it is assumed that:\n",
        "1. You have cloned the GitHub repository https://github.com/qu1r0ra/philippine-machine-translation.\n",
        "2. You have gone through `00_setup.ipynb` and `01b_preprocessing_nmt.ipynb` in the repository.\n",
        "\n",
        "To prepare the data needed for this notebook, simply follow these instructions:\n",
        "1. Upload `config.yaml` from the repository to the Colab filesystem (`/content`). You know you are in the right path if you can also see the file `condacolab_install.log`.\n",
        "3. Upload `train.src`, `train.tgt`, `valid.src`, and `valid.tgt` from `data/processed/` in the repository to the `data/` folder in Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO4sVIN4FxwO"
      },
      "source": [
        "Let us check the first few lines of our training and validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4rIoNl9B4vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be8f093f-7339-4d69-c340-3142f13f0864"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "busa nanghagdaw siya didto sa uma hangtod sa pagkahapon ug iyang gigiok ang iyang hinagdaw ug kini mga usa ka epha sa sebada\r\n",
            "sukad sa mga adlaw sa among mga katigulangan hangtod niining adlawa kami hilabihan ka makasasala ug tungod sa among mga kalapasan kami ang among mga hari ug ang among mga pari gitugyan ngadto sa kamot sa mga hari sa kayutaan ngadto sa espada ngadto sa pagkabinihag ug sa pagkainilogan ug ngadto sa kaulawan hangtod niining adlawa\r\n",
            "unya ibutang nila sa ibabaw niini ang tanang mga kahimanan sa halaran nga gigamit sa pagalagad diha niini ang mga sanggaan sa baga ang mga tinidor ug ang mga pala ug ang mga planggana ang tanang mga galamiton sa halaran ug tabonan nila kini sa usa ka tabon nga panit sa kanding ug itaod ang mga yayongan niini\r\n",
            "sa diha nga mabuhat ang hustisya kalipay kini sa matarong apan kapukanan sa tigbuhat ug daotan\r\n",
            "ang mga anak nga lalaki ni ham si cus si ehipto si put ug si canaan\r\n"
          ]
        }
      ],
      "source": [
        "!head -n 5 data/gru-aug-cbk/train.src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITukDj3gH6In",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc328d41-02ce-4779-c79d-cd8d299dba8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "espigÃ³ pues en el campo hasta la noche y cuando desgranÃ³ lo que habÃ­a recogido era como un efa de cebada\r\n",
            "desde los dÃ­as de nuestros padres hasta este dÃ­a hemos vivido en gran pecado y por nuestras iniquidades nosotros nuestros reyes y nuestros sacerdotes hemos sido entregados en manos de los reyes de los paÃ­ses a la espada al cautiverio al robo y a la vergÃ¼enza que cubre nuestro rostro como todavÃ­a sucede\r\n",
            "pondrÃ¡n sobre Ã©l todos los instrumentos que se emplean en su servicio las paletas los garfios los braseros y los tazones todos los utensilios del altar extenderÃ¡n sobre Ã©l la cubierta de pieles de tejones y le pondrÃ¡n ademÃ¡s las varas\r\n",
            "alegrÃ­a es para el justo practicar la justicia pero un desastre para los que cometen iniquidad\r\n",
            "los hijos de cam cus mizraim fut y canaÃ¡n\r\n"
          ]
        }
      ],
      "source": [
        "!head -n 5 data/gru-aug-cbk/train.tgt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUEVZx-TIIT9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67835965-bc46-48f6-f520-57b7c6f629f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kining unom ka siyudad mahimong dalangpanan alang sa katawhan sa israel ug alang sa mga dumuduong ug alang sa mga langyaw aron nga si bisan kinsa nga makapatay ug tawo nga wala tuyoa makadangop didto\r\n",
            "ta ama gayot came con ustedes y hende lang el buen noticia ta dale came con ustedes pero ta otorga came dale masquin pa el di amon vida cay tiene gayot came grande amor para con ustedes\r\n",
            "ug si safan nga sekretaryo miadto sa hari ug gisuginlan pagusab ang hari gikuha sa imong mga sulugoon ang salapi nga nakita didto sa balay ug gihatag sa kamot sa mga mamumuo nga nagbantay sa balay sa ginoo\r\n",
            "ug sila makigharong kanimo uban ang pagdumot ug kuhaon ang tanang bunga sa imong paghago ug biyaan ikaw nga hubo ug walay bisti ug ang pagkahubo sa imong pagkamakihilawason madayag ang imong kalaway ug ang imong pagkamakihilawason\r\n",
            "unya gidala ni samuel si saul ug ang iyang sulugoon ngadto sa kananan ug gipalingkod sila sa kinaibabwan nga dapit uban kanila nga mga dinapit nga mga ka tawo\r\n"
          ]
        }
      ],
      "source": [
        "!head -n 5 data/gru-aug-cbk/valid.src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPckT9QdIOmt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973e2008-d238-4978-8ea7-67d73d064cb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "estas seis ciudades serÃ¡n de refugio para los hijos de israel para el extranjero y el que habite entre ellos para que huya allÃ¡ cualquiera que hiera de muerte a otro sin intenciÃ³n\r\n",
            "tan grande es nuestro afecto por vosotros que hubiÃ©ramos querido entregaros no solo el evangelio de dios sino tambiÃ©n nuestras propias vidas porque habÃ©is llegado a sernos muy queridos\r\n",
            "luego el escriba safÃ¡n se presentÃ³ ante el rey y le rindiÃ³ cuentas diciendo tus siervos han recogido el dinero que se hallÃ³ en el templo y se lo han entregado a los que hacen la obra los que tienen a su cargo el arreglo de la casa de jehovÃ¡\r\n",
            "los cuales procederÃ¡n contigo con odio y tomarÃ¡n todo el fruto de tu labor te dejarÃ¡n desnuda por completo y se descubrirÃ¡ la inmundicia de tus fornicaciones tu lujuria y tu prostituciÃ³n\r\n",
            "entonces samuel tomÃ³ a saÃºl y a su criado los introdujo a la sala y les dio un lugar a la cabecera de los convidados que eran unos treinta hombres\r\n"
          ]
        }
      ],
      "source": [
        "!head -n 5 data/gru-aug-cbk/valid.tgt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dk7HR9dIaFK"
      },
      "source": [
        "(will soon write stuff about the data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also need to install NumPy with version `<2.0` for `OpenNMT-py`."
      ],
      "metadata": {
        "id": "ck1NBcmsDU9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy<2.0\""
      ],
      "metadata": {
        "id": "6lncykHLiYW4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "650e9bf8-666c-4c24-ee2d-adf9da53d3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m197.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.3.4\n",
            "    Uninstalling numpy-2.3.4:\n",
            "      Successfully uninstalled numpy-2.3.4\n",
            "Successfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "9354f99248574353b18b5c9a2d6eb45c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpkO0JiZIfh0"
      },
      "source": [
        "## Training a Gated Recurrent Unit (GRU) with OpenNMT-py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXxAHGGTInNV"
      },
      "source": [
        "The advantage with using `OpenNMT-py` is that we only need to configure the parameters and hyperparameters of the model with a `config.yaml` file. After doing so, the training can be ran with one line.\n",
        "\n",
        "Normally, we would need to code the architecture and mechanisms of the model ourselves in deep learning frameworks like `PyTorch` and `TensorFlow`. As an aside, `OpenNMT` has implementations in both of these frameworks, but the authors chose the PyTorch implementation, thus named `OpenNMT-py`.\n",
        "\n",
        "P.S.:\n",
        "- In retrospect, the author shouldn't have went with this..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYRMOIlZIgSL"
      },
      "outputs": [],
      "source": [
        "!onmt_build_vocab -config config-gru-aug.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTKJZdmKKTzB"
      },
      "outputs": [],
      "source": [
        "!onmt_train -config config-gru-aug.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eRimllMKbyv"
      },
      "source": [
        "This is literally it. Now we just have to wait until the model finishes training.\n",
        "\n",
        "Do note that training even a small GRU like may take hours, depending on various factors such as:\n",
        "- the size of your dataset\n",
        "- the parameters you set in your `config.yaml`\n",
        "- the power of your GPU\n",
        "- etc."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Same Exact Model Architecture on Non-Augmented Data (i.e., no Noise Injection)"
      ],
      "metadata": {
        "id": "eCEBWemiO8oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt_build_vocab -config config-gru-base.yaml"
      ],
      "metadata": {
        "id": "JHlPHR0-PgSH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94c048b7-f7a5-4b50-d66a-16ac056e8c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2025-11-08 20:24:31,903 INFO] Counter vocab from 5000 samples.\n",
            "[2025-11-08 20:24:31,903 INFO] Build vocab on 5000 transformed examples/corpus.\n",
            "[2025-11-08 20:24:32,111 INFO] Counters src: 8180\n",
            "[2025-11-08 20:24:32,112 INFO] Counters tgt: 10994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt_train -config config-gru-base.yaml"
      ],
      "metadata": {
        "id": "2nL-9QZ8Pt7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc88390-e433-45e3-b2a5-9721bf084c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-11-08 20:24:45,510 INFO] Missing transforms field for corpus_1 data, set to default: [].\n",
            "[2025-11-08 20:24:45,510 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2025-11-08 20:24:45,510 INFO] Missing transforms field for valid data, set to default: [].\n",
            "[2025-11-08 20:24:45,510 INFO] Parsed 2 corpora from -data.\n",
            "[2025-11-08 20:24:45,510 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2025-11-08 20:24:45,539 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 'sa', 'ug', 'ang', 'nga', 'mga', 'iyang']\n",
            "[2025-11-08 20:24:45,539 INFO] The decoder start token is: <s>\n",
            "[2025-11-08 20:24:45,539 INFO] Building model...\n",
            "[2025-11-08 20:24:45,811 INFO] Switching model to float32 for amp/apex_amp\n",
            "[2025-11-08 20:24:45,812 INFO] Non quantized layer compute is fp32\n",
            "[2025-11-08 20:24:45,966 INFO] NMTModel(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(8184, 300, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (rnn): GRU(300, 500, num_layers=2, batch_first=True, dropout=0.2)\n",
            "    (bridge): ModuleList(\n",
            "      (0): Linear(in_features=1000, out_features=1000, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (decoder): InputFeedRNNDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(11000, 300, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "    (rnn): StackedGRU(\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (layers): ModuleList(\n",
            "        (0): GRUCell(800, 500)\n",
            "        (1): GRUCell(500, 500)\n",
            "      )\n",
            "    )\n",
            "    (attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=500, out_features=500, bias=False)\n",
            "      (linear_out): Linear(in_features=1000, out_features=500, bias=False)\n",
            "    )\n",
            "    (copy_attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=500, out_features=500, bias=False)\n",
            "      (linear_out): Linear(in_features=1000, out_features=500, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): CopyGenerator(\n",
            "    (linear): Linear(in_features=500, out_features=11000, bias=True)\n",
            "    (linear_copy): Linear(in_features=500, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "[2025-11-08 20:24:45,967 INFO] encoder: 6162200\n",
            "[2025-11-08 20:24:45,967 INFO] decoder: 13767501\n",
            "[2025-11-08 20:24:45,967 INFO] * number of parameters: 19929701\n",
            "[2025-11-08 20:24:45,967 INFO] Trainable parameters = {'torch.float32': 19929701, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2025-11-08 20:24:45,967 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2025-11-08 20:24:45,967 INFO]  * src vocab size = 8184\n",
            "[2025-11-08 20:24:45,967 INFO]  * tgt vocab size = 11000\n",
            "[2025-11-08 20:24:46,277 INFO] Starting training on GPU: [0]\n",
            "[2025-11-08 20:24:46,277 INFO] Start training loop and validate every 250 steps...\n",
            "[2025-11-08 20:24:46,277 INFO] Scoring with: TransformPipe()\n",
            "[2025-11-08 20:24:48,505 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2025-11-08 20:24:50,765 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2025-11-08 20:24:51,140 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2025-11-08 20:24:51,154 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2025-11-08 20:24:51,656 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2025-11-08 20:24:51,687 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2025-11-08 20:24:52,255 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2025-11-08 20:24:52,301 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2025-11-08 20:24:52,901 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2025-11-08 20:24:52,967 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2025-11-08 20:24:53,668 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2025-11-08 20:24:53,728 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2025-11-08 20:24:54,071 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 7\n",
            "[2025-11-08 20:24:54,128 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 7\n",
            "[2025-11-08 20:24:54,911 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 8\n",
            "[2025-11-08 20:24:54,995 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 8\n",
            "[2025-11-08 20:24:55,298 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 9\n",
            "[2025-11-08 20:24:55,405 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 9\n",
            "[2025-11-08 20:24:55,680 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 10\n",
            "[2025-11-08 20:24:55,799 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 10\n",
            "[2025-11-08 20:24:56,652 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 11\n",
            "[2025-11-08 20:24:56,804 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 11\n",
            "[2025-11-08 20:24:57,034 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 12\n",
            "[2025-11-08 20:24:57,207 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 12\n",
            "[2025-11-08 20:24:57,418 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 13\n",
            "[2025-11-08 20:24:57,604 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 13\n",
            "[2025-11-08 20:24:58,576 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 14\n",
            "[2025-11-08 20:24:58,785 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 14\n",
            "[2025-11-08 20:24:58,953 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 15\n",
            "[2025-11-08 20:24:59,186 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 15\n",
            "[2025-11-08 20:24:59,335 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 16\n",
            "[2025-11-08 20:24:59,583 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 16\n",
            "[2025-11-08 20:25:00,703 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 17\n",
            "[2025-11-08 20:25:00,971 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 17\n",
            "[2025-11-08 20:25:01,102 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 18\n",
            "[2025-11-08 20:25:01,373 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 18\n",
            "[2025-11-08 20:25:01,485 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 19\n",
            "[2025-11-08 20:25:01,764 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 19\n",
            "[2025-11-08 20:25:28,544 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 20\n",
            "[2025-11-08 20:25:28,929 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 21\n",
            "[2025-11-08 20:25:29,015 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 20\n",
            "[2025-11-08 20:25:29,309 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 22\n",
            "[2025-11-08 20:25:29,390 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 21\n",
            "[2025-11-08 20:25:29,688 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 23\n",
            "[2025-11-08 20:25:29,748 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 22\n",
            "[2025-11-08 20:25:30,100 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 24\n",
            "[2025-11-08 20:25:30,110 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 23\n",
            "[2025-11-08 20:25:30,477 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 24\n",
            "[2025-11-08 20:25:34,116 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 25\n",
            "[2025-11-08 20:25:34,230 INFO] Step 50/30000; acc: 4.9; ppl: 806.7; xent: 6.7; lr: 0.00100; sents:    6894; bsz: 3504/3077/138; 3654/3208 tok/s;     48 sec;\n",
            "[2025-11-08 20:25:34,486 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 25\n",
            "[2025-11-08 20:25:34,537 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 26\n",
            "[2025-11-08 20:25:34,870 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 26\n",
            "[2025-11-08 20:25:34,935 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 27\n",
            "[2025-11-08 20:25:35,257 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 27\n",
            "[2025-11-08 20:25:35,331 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 28\n",
            "[2025-11-08 20:25:35,639 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 28\n",
            "[2025-11-08 20:25:35,722 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 29\n",
            "[2025-11-08 20:25:36,036 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 29\n",
            "[2025-11-08 20:25:36,113 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 30\n",
            "[2025-11-08 20:25:36,430 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 30\n",
            "[2025-11-08 20:25:36,528 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 31\n",
            "[2025-11-08 20:25:36,821 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 31\n",
            "[2025-11-08 20:25:36,924 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 32\n",
            "[2025-11-08 20:25:37,240 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 32\n",
            "[2025-11-08 20:25:37,331 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 33\n",
            "[2025-11-08 20:25:37,623 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 33\n",
            "[2025-11-08 20:25:37,751 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 34\n",
            "[2025-11-08 20:25:38,021 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 34\n",
            "[2025-11-08 20:25:42,722 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 35\n",
            "[2025-11-08 20:25:42,927 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 35\n",
            "[2025-11-08 20:25:43,137 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 36\n",
            "[2025-11-08 20:25:43,349 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 36\n",
            "[2025-11-08 20:25:43,546 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 37\n",
            "[2025-11-08 20:25:43,749 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 37\n",
            "[2025-11-08 20:25:43,942 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 38\n",
            "[2025-11-08 20:25:44,107 INFO] Step 100/30000; acc: 5.9; ppl: 461.1; xent: 6.1; lr: 0.00100; sents:    5991; bsz: 3401/3008/120; 17218/15227 tok/s;     58 sec;\n",
            "[2025-11-08 20:25:44,149 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 38\n",
            "[2025-11-08 20:25:53,645 INFO] Step 150/30000; acc: 9.3; ppl: 330.5; xent: 5.8; lr: 0.00100; sents:    7188; bsz: 3364/3064/144; 17637/16061 tok/s;     67 sec;\n",
            "[2025-11-08 20:26:03,143 INFO] Step 200/30000; acc: 11.3; ppl: 232.8; xent: 5.5; lr: 0.00100; sents:    6281; bsz: 3393/2997/126; 17864/15781 tok/s;     77 sec;\n",
            "[2025-11-08 20:26:13,572 INFO] Step 250/30000; acc: 13.0; ppl: 164.1; xent: 5.1; lr: 0.00100; sents:    6119; bsz: 3332/2983/122; 15976/14300 tok/s;     87 sec;\n",
            "[2025-11-08 20:26:16,172 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 39\n",
            "[2025-11-08 20:26:16,272 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 39\n",
            "[2025-11-08 20:26:16,578 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 40\n",
            "[2025-11-08 20:26:16,696 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 40\n",
            "[2025-11-08 20:26:17,118 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 41\n",
            "[2025-11-08 20:26:17,158 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 41\n",
            "[2025-11-08 20:26:17,536 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 42\n",
            "[2025-11-08 20:26:17,585 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 42\n",
            "[2025-11-08 20:26:17,920 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 43\n",
            "[2025-11-08 20:26:18,063 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 43\n",
            "[2025-11-08 20:26:18,327 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 44\n",
            "[2025-11-08 20:26:18,487 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 44\n",
            "[2025-11-08 20:26:18,724 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 45\n",
            "[2025-11-08 20:26:18,853 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 45\n",
            "[2025-11-08 20:26:19,224 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 46\n",
            "[2025-11-08 20:26:19,379 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 46\n",
            "[2025-11-08 20:26:19,742 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 47\n",
            "[2025-11-08 20:26:19,860 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 47\n",
            "[2025-11-08 20:26:24,023 INFO] valid stats calculation\n",
            "                           took: 10.448749542236328 s.\n",
            "[2025-11-08 20:26:24,023 INFO] Train perplexity: 344.045\n",
            "[2025-11-08 20:26:24,023 INFO] Train accuracy: 8.86296\n",
            "[2025-11-08 20:26:24,023 INFO] Sentences processed: 32473\n",
            "[2025-11-08 20:26:24,023 INFO] Average bsz: 3399/3026/130\n",
            "[2025-11-08 20:26:24,024 INFO] Validation perplexity: 157.808\n",
            "[2025-11-08 20:26:24,024 INFO] Validation accuracy: 11.7052\n",
            "[2025-11-08 20:26:24,024 INFO] Model is improving ppl: inf --> 157.808.\n",
            "[2025-11-08 20:26:24,200 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 48\n",
            "[2025-11-08 20:26:24,306 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 48\n",
            "[2025-11-08 20:26:24,561 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 49\n",
            "[2025-11-08 20:26:24,686 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 49\n",
            "[2025-11-08 20:26:24,924 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 50\n",
            "[2025-11-08 20:26:25,046 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 50\n",
            "[2025-11-08 20:26:25,287 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 51\n",
            "[2025-11-08 20:26:25,432 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 51\n",
            "[2025-11-08 20:26:25,697 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 52\n",
            "[2025-11-08 20:26:25,802 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 52\n",
            "[2025-11-08 20:26:26,079 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 53\n",
            "[2025-11-08 20:26:26,173 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 53\n",
            "[2025-11-08 20:26:26,457 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 54\n",
            "[2025-11-08 20:26:26,542 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 54\n",
            "[2025-11-08 20:26:26,852 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 55\n",
            "[2025-11-08 20:26:26,904 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 55\n",
            "[2025-11-08 20:26:27,227 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 56\n",
            "[2025-11-08 20:26:27,298 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 56\n",
            "[2025-11-08 20:26:27,622 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 57\n",
            "[2025-11-08 20:26:27,662 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 57\n",
            "[2025-11-08 20:26:33,898 INFO] Step 300/30000; acc: 13.9; ppl: 134.4; xent: 4.9; lr: 0.00100; sents:    6963; bsz: 3436/3059/139; 8454/7525 tok/s;    108 sec;\n",
            "[2025-11-08 20:26:43,480 INFO] Step 350/30000; acc: 15.3; ppl: 111.6; xent: 4.7; lr: 0.00100; sents:    6465; bsz: 3334/3039/129; 17398/15859 tok/s;    117 sec;\n",
            "[2025-11-08 20:26:52,732 INFO] Step 400/30000; acc: 16.2; ppl: 100.2; xent: 4.6; lr: 0.00100; sents:    6802; bsz: 3223/2842/136; 17423/15362 tok/s;    126 sec;\n",
            "[2025-11-08 20:27:02,444 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 58\n",
            "[2025-11-08 20:27:02,694 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 58\n",
            "[2025-11-08 20:27:02,829 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 59\n",
            "[2025-11-08 20:27:03,081 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 59\n",
            "[2025-11-08 20:27:03,214 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 60\n",
            "[2025-11-08 20:27:03,450 INFO] Step 450/30000; acc: 18.6; ppl:  83.9; xent: 4.4; lr: 0.00100; sents:    5910; bsz: 3558/3116/118; 16598/14535 tok/s;    137 sec;\n",
            "[2025-11-08 20:27:03,486 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 60\n",
            "[2025-11-08 20:27:03,616 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 61\n",
            "[2025-11-08 20:27:03,874 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 61\n",
            "[2025-11-08 20:27:04,001 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 62\n",
            "[2025-11-08 20:27:04,244 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 62\n",
            "[2025-11-08 20:27:04,383 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 63\n",
            "[2025-11-08 20:27:04,630 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 63\n",
            "[2025-11-08 20:27:08,728 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 64\n",
            "[2025-11-08 20:27:09,039 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 64\n",
            "[2025-11-08 20:27:09,155 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 65\n",
            "[2025-11-08 20:27:09,489 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 65\n",
            "[2025-11-08 20:27:09,543 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 66\n",
            "[2025-11-08 20:27:09,865 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 66\n",
            "[2025-11-08 20:27:09,924 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 67\n",
            "[2025-11-08 20:27:10,254 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 67\n",
            "[2025-11-08 20:27:10,308 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 68\n",
            "[2025-11-08 20:27:10,629 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 68\n",
            "[2025-11-08 20:27:10,679 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 69\n",
            "[2025-11-08 20:27:11,033 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 69\n",
            "[2025-11-08 20:27:11,082 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 70\n",
            "[2025-11-08 20:27:11,391 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 70\n",
            "[2025-11-08 20:27:11,477 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 71\n",
            "[2025-11-08 20:27:11,746 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 71\n",
            "[2025-11-08 20:27:11,829 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 72\n",
            "[2025-11-08 20:27:12,109 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 72\n",
            "[2025-11-08 20:27:12,193 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 73\n",
            "[2025-11-08 20:27:12,480 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 73\n",
            "[2025-11-08 20:27:13,527 INFO] Step 500/30000; acc: 20.0; ppl:  67.4; xent: 4.2; lr: 0.00100; sents:    6045; bsz: 3382/3034/121; 16780/15054 tok/s;    147 sec;\n",
            "[2025-11-08 20:27:17,338 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 74\n",
            "[2025-11-08 20:27:17,589 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 74\n",
            "[2025-11-08 20:27:17,718 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 75\n",
            "[2025-11-08 20:27:17,943 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 75\n",
            "[2025-11-08 20:27:18,148 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 76\n",
            "[2025-11-08 20:27:18,413 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 76\n",
            "[2025-11-08 20:27:23,772 INFO] valid stats calculation\n",
            "                           took: 10.243544578552246 s.\n",
            "[2025-11-08 20:27:23,773 INFO] Train perplexity: 182.571\n",
            "[2025-11-08 20:27:23,773 INFO] Train accuracy: 12.8395\n",
            "[2025-11-08 20:27:23,773 INFO] Sentences processed: 64658\n",
            "[2025-11-08 20:27:23,773 INFO] Average bsz: 3393/3022/129\n",
            "[2025-11-08 20:27:23,773 INFO] Validation perplexity: 58.56\n",
            "[2025-11-08 20:27:23,773 INFO] Validation accuracy: 20.2813\n",
            "[2025-11-08 20:27:23,774 INFO] Model is improving ppl: 157.808 --> 58.56.\n",
            "[2025-11-08 20:27:23,777 INFO] Saving checkpoint outputs/gru-base/model_gru_base_step_500.pt\n",
            "[2025-11-08 20:27:34,199 INFO] Step 550/30000; acc: 20.1; ppl:  60.3; xent: 4.1; lr: 0.00100; sents:    5693; bsz: 3292/2879/114; 7963/6964 tok/s;    168 sec;\n",
            "[2025-11-08 20:27:44,090 INFO] Step 600/30000; acc: 22.9; ppl:  51.3; xent: 3.9; lr: 0.00100; sents:    6595; bsz: 3309/2979/132; 16727/15060 tok/s;    178 sec;\n",
            "[2025-11-08 20:27:48,674 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 77\n",
            "[2025-11-08 20:27:49,006 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 77\n",
            "[2025-11-08 20:27:49,048 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 78\n",
            "[2025-11-08 20:27:49,384 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 78\n",
            "Exception in thread Thread-2 (_pin_memory_loop):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/data/_utils/pin_memory.py\", line 54, in _pin_memory_loop\n",
            "    do_one_step()\n",
            "  File \"/usr/local/lib/python3.11/site-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in do_one_step\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/torch/multiprocessing/reductions.py\", line 355, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "         ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/multiprocessing/connection.py\", line 519, in Client\n",
            "    c = SocketClient(address)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/multiprocessing/connection.py\", line 647, in SocketClient\n",
            "    s.connect(address)\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt_train\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/onmt/bin/train.py\", line 67, in main\n",
            "    train(opt)\n",
            "  File \"/usr/local/lib/python3.11/site-packages/onmt/bin/train.py\", line 52, in train\n",
            "    train_process(opt, device_id=0)\n",
            "  File \"/usr/local/lib/python3.11/site-packages/onmt/train_single.py\", line 237, in main\n",
            "    trainer.train(\n",
            "  File \"/usr/local/lib/python3.11/site-packages/onmt/trainer.py\", line 308, in train\n",
            "    for i, (batches, normalization) in enumerate(self._accum_batches(train_iter)):\n",
            "  File \"/usr/local/lib/python3.11/site-packages/onmt/trainer.py\", line 238, in _accum_batches\n",
            "    for batch, bucket_idx in iterator:\n",
            "  File \"/usr/local/lib/python3.11/site-packages/onmt/inputters/dynamic_iterator.py\", line 370, in __iter__\n",
            "    tensor_batch[key] = tensor_batch[key].to(self.device)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Same Exact Model Architecture on Data Augmented with Chavacano-Spanish"
      ],
      "metadata": {
        "id": "gTGIhLJEmUq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt_build_vocab -config config-gru-aug-cbk.yaml"
      ],
      "metadata": {
        "id": "-fnUErAhmN8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf1dab5-291f-4e3e-b426-d78f775b3222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2025-11-08 15:40:37,574 INFO] Counter vocab from 5000 samples.\n",
            "[2025-11-08 15:40:37,574 INFO] Build vocab on 5000 transformed examples/corpus.\n",
            "[2025-11-08 15:40:37,768 INFO] Counters src: 8936\n",
            "[2025-11-08 15:40:37,768 INFO] Counters tgt: 10839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt_train -config config-gru-aug-cbk.yaml"
      ],
      "metadata": {
        "id": "oGbVyDIQnC4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d889ab94-afd2-40c8-a0e2-fec65e45c780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-11-08 15:40:49,645 INFO] Missing transforms field for corpus_1 data, set to default: [].\n",
            "[2025-11-08 15:40:49,645 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2025-11-08 15:40:49,645 INFO] Missing transforms field for valid data, set to default: [].\n",
            "[2025-11-08 15:40:49,645 INFO] Parsed 2 corpora from -data.\n",
            "[2025-11-08 15:40:49,645 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2025-11-08 15:40:49,673 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 'sa', 'ug', 'ang', 'nga', 'mga', 'si']\n",
            "[2025-11-08 15:40:49,673 INFO] The decoder start token is: <s>\n",
            "[2025-11-08 15:40:49,673 INFO] Building model...\n",
            "[2025-11-08 15:40:49,938 INFO] Switching model to float32 for amp/apex_amp\n",
            "[2025-11-08 15:40:49,938 INFO] Non quantized layer compute is fp32\n",
            "[2025-11-08 15:40:50,216 INFO] NMTModel(\n",
            "  (encoder): RNNEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(8944, 300, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (rnn): GRU(300, 500, num_layers=2, batch_first=True, dropout=0.2)\n",
            "    (bridge): ModuleList(\n",
            "      (0): Linear(in_features=1000, out_features=1000, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (decoder): InputFeedRNNDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(10848, 300, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "    (rnn): StackedGRU(\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "      (layers): ModuleList(\n",
            "        (0): GRUCell(800, 500)\n",
            "        (1): GRUCell(500, 500)\n",
            "      )\n",
            "    )\n",
            "    (attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=500, out_features=500, bias=False)\n",
            "      (linear_out): Linear(in_features=1000, out_features=500, bias=False)\n",
            "    )\n",
            "    (copy_attn): GlobalAttention(\n",
            "      (linear_in): Linear(in_features=500, out_features=500, bias=False)\n",
            "      (linear_out): Linear(in_features=1000, out_features=500, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (generator): CopyGenerator(\n",
            "    (linear): Linear(in_features=500, out_features=10848, bias=True)\n",
            "    (linear_copy): Linear(in_features=500, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "[2025-11-08 15:40:50,216 INFO] encoder: 6390200\n",
            "[2025-11-08 15:40:50,216 INFO] decoder: 13645749\n",
            "[2025-11-08 15:40:50,216 INFO] * number of parameters: 20035949\n",
            "[2025-11-08 15:40:50,216 INFO] Trainable parameters = {'torch.float32': 20035949, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2025-11-08 15:40:50,216 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2025-11-08 15:40:50,217 INFO]  * src vocab size = 8944\n",
            "[2025-11-08 15:40:50,217 INFO]  * tgt vocab size = 10848\n",
            "[2025-11-08 15:40:50,508 INFO] Starting training on GPU: [0]\n",
            "[2025-11-08 15:40:50,508 INFO] Start training loop and validate every 250 steps...\n",
            "[2025-11-08 15:40:50,508 INFO] Scoring with: TransformPipe()\n",
            "[2025-11-08 15:40:52,552 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2025-11-08 15:40:54,599 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2025-11-08 15:40:55,181 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2025-11-08 15:40:55,184 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2025-11-08 15:40:55,843 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2025-11-08 15:40:55,855 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2025-11-08 15:40:56,582 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2025-11-08 15:40:56,593 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2025-11-08 15:40:57,036 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2025-11-08 15:40:57,049 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2025-11-08 15:40:57,888 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2025-11-08 15:40:57,901 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2025-11-08 15:40:58,812 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 7\n",
            "[2025-11-08 15:40:58,826 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 7\n",
            "[2025-11-08 15:40:59,266 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 8\n",
            "[2025-11-08 15:40:59,286 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 8\n",
            "[2025-11-08 15:41:00,320 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 9\n",
            "[2025-11-08 15:41:00,350 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 9\n",
            "[2025-11-08 15:41:00,780 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 10\n",
            "[2025-11-08 15:41:00,811 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 10\n",
            "[2025-11-08 15:41:01,250 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 11\n",
            "[2025-11-08 15:41:01,283 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 11\n",
            "[2025-11-08 15:41:02,484 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 12\n",
            "[2025-11-08 15:41:02,514 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 12\n",
            "[2025-11-08 15:41:02,941 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 13\n",
            "[2025-11-08 15:41:02,968 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 13\n",
            "[2025-11-08 15:41:03,408 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 14\n",
            "[2025-11-08 15:41:03,435 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 14\n",
            "[2025-11-08 15:41:04,856 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 15\n",
            "[2025-11-08 15:41:04,864 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 15\n",
            "[2025-11-08 15:41:05,311 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 16\n",
            "[2025-11-08 15:41:05,315 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 16\n",
            "[2025-11-08 15:41:33,545 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 17\n",
            "[2025-11-08 15:41:33,622 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 17\n",
            "[2025-11-08 15:41:33,984 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 18\n",
            "[2025-11-08 15:41:34,089 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 18\n",
            "[2025-11-08 15:41:34,457 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 19\n",
            "[2025-11-08 15:41:34,559 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 19\n",
            "[2025-11-08 15:41:34,888 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 20\n",
            "[2025-11-08 15:41:35,013 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 20\n",
            "[2025-11-08 15:41:37,392 INFO] Step 50/30000; acc: 5.0; ppl: 689.4; xent: 6.5; lr: 0.00100; sents:    6880; bsz: 3508/2935/138; 3741/3130 tok/s;     47 sec;\n",
            "[2025-11-08 15:41:38,858 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 21\n",
            "[2025-11-08 15:41:39,000 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 21\n",
            "[2025-11-08 15:41:39,296 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 22\n",
            "[2025-11-08 15:41:39,438 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 22\n",
            "[2025-11-08 15:41:39,747 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 23\n",
            "[2025-11-08 15:41:39,877 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 23\n",
            "[2025-11-08 15:41:40,200 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 24\n",
            "[2025-11-08 15:41:40,340 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 24\n",
            "[2025-11-08 15:41:40,698 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 25\n",
            "[2025-11-08 15:41:40,851 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 25\n",
            "[2025-11-08 15:41:41,191 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 26\n",
            "[2025-11-08 15:41:41,328 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 26\n",
            "[2025-11-08 15:41:41,651 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 27\n",
            "[2025-11-08 15:41:41,813 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 27\n",
            "[2025-11-08 15:41:42,107 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 28\n",
            "[2025-11-08 15:41:42,283 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 28\n",
            "[2025-11-08 15:41:46,299 INFO] Step 100/30000; acc: 5.5; ppl: 460.3; xent: 6.1; lr: 0.00100; sents:    6750; bsz: 3312/2889/135; 18593/16217 tok/s;     56 sec;\n",
            "[2025-11-08 15:41:47,007 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 29\n",
            "[2025-11-08 15:41:47,205 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 29\n",
            "[2025-11-08 15:41:47,471 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 30\n",
            "[2025-11-08 15:41:47,678 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 30\n",
            "[2025-11-08 15:41:47,941 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 31\n",
            "[2025-11-08 15:41:48,156 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 31\n",
            "[2025-11-08 15:41:48,421 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 32\n",
            "[2025-11-08 15:41:48,638 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 32\n",
            "[2025-11-08 15:41:55,748 INFO] Step 150/30000; acc: 7.7; ppl: 357.7; xent: 5.9; lr: 0.00100; sents:    6059; bsz: 3793/3122/121; 20075/16525 tok/s;     65 sec;\n",
            "[2025-11-08 15:42:04,511 INFO] Step 200/30000; acc: 10.0; ppl: 250.0; xent: 5.5; lr: 0.00100; sents:    7029; bsz: 3419/2838/141; 19511/16193 tok/s;     74 sec;\n",
            "[2025-11-08 15:42:13,888 INFO] Step 250/30000; acc: 11.3; ppl: 190.5; xent: 5.2; lr: 0.00100; sents:    5467; bsz: 3440/2858/109; 18345/15242 tok/s;     83 sec;\n",
            "[2025-11-08 15:42:22,167 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 33\n",
            "[2025-11-08 15:42:22,327 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 33\n",
            "[2025-11-08 15:42:22,618 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 34\n",
            "[2025-11-08 15:42:22,795 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 34\n",
            "[2025-11-08 15:42:23,072 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 35\n",
            "[2025-11-08 15:42:23,244 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 35\n",
            "[2025-11-08 15:42:23,538 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 36\n",
            "[2025-11-08 15:42:23,694 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 36\n",
            "[2025-11-08 15:42:23,980 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 37\n",
            "[2025-11-08 15:42:24,130 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 37\n",
            "[2025-11-08 15:42:24,415 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 38\n",
            "[2025-11-08 15:42:24,560 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 38\n",
            "[2025-11-08 15:42:24,863 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 39\n",
            "[2025-11-08 15:42:24,988 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 39\n",
            "[2025-11-08 15:42:25,289 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 40\n",
            "[2025-11-08 15:42:25,454 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 40\n",
            "[2025-11-08 15:42:25,697 INFO] valid stats calculation\n",
            "                           took: 11.808371305465698 s.\n",
            "[2025-11-08 15:42:25,698 INFO] Train perplexity: 353.739\n",
            "[2025-11-08 15:42:25,698 INFO] Train accuracy: 7.88287\n",
            "[2025-11-08 15:42:25,698 INFO] Sentences processed: 32185\n",
            "[2025-11-08 15:42:25,698 INFO] Average bsz: 3494/2928/129\n",
            "[2025-11-08 15:42:25,698 INFO] Validation perplexity: 147.94\n",
            "[2025-11-08 15:42:25,699 INFO] Validation accuracy: 11.8966\n",
            "[2025-11-08 15:42:25,699 INFO] Model is improving ppl: inf --> 147.94.\n",
            "[2025-11-08 15:42:29,733 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 41\n",
            "[2025-11-08 15:42:29,909 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 41\n",
            "[2025-11-08 15:42:30,170 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 42\n",
            "[2025-11-08 15:42:30,338 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 42\n",
            "[2025-11-08 15:42:30,610 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 43\n",
            "[2025-11-08 15:42:30,812 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 43\n",
            "[2025-11-08 15:42:31,079 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 44\n",
            "[2025-11-08 15:42:31,273 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 44\n",
            "[2025-11-08 15:42:31,556 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 45\n",
            "[2025-11-08 15:42:31,803 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 45\n",
            "[2025-11-08 15:42:32,036 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 46\n",
            "[2025-11-08 15:42:32,318 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 46\n",
            "[2025-11-08 15:42:32,488 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 47\n",
            "[2025-11-08 15:42:32,755 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 47\n",
            "[2025-11-08 15:42:32,935 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 48\n",
            "[2025-11-08 15:42:33,209 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 48\n",
            "[2025-11-08 15:42:35,462 INFO] Step 300/30000; acc: 13.1; ppl: 148.3; xent: 5.0; lr: 0.00100; sents:    5867; bsz: 3530/2907/117; 8182/6738 tok/s;    105 sec;\n",
            "[2025-11-08 15:42:44,904 INFO] Step 350/30000; acc: 14.5; ppl: 119.1; xent: 4.8; lr: 0.00100; sents:    6113; bsz: 3566/2974/122; 18887/15751 tok/s;    114 sec;\n",
            "[2025-11-08 15:42:54,087 INFO] Step 400/30000; acc: 15.0; ppl: 115.9; xent: 4.8; lr: 0.00100; sents:    6276; bsz: 3714/3043/126; 20224/16568 tok/s;    124 sec;\n",
            "[2025-11-08 15:43:03,403 INFO] Step 450/30000; acc: 17.0; ppl:  90.4; xent: 4.5; lr: 0.00100; sents:    6178; bsz: 3466/2986/124; 18604/16027 tok/s;    133 sec;\n",
            "[2025-11-08 15:43:08,556 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 49\n",
            "[2025-11-08 15:43:09,001 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 50\n",
            "[2025-11-08 15:43:09,440 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 51\n",
            "[2025-11-08 15:43:09,652 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 49\n",
            "[2025-11-08 15:43:09,892 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 52\n",
            "[2025-11-08 15:43:10,094 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 50\n",
            "[2025-11-08 15:43:10,358 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 53\n",
            "[2025-11-08 15:43:10,529 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 51\n",
            "[2025-11-08 15:43:10,960 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 52\n",
            "[2025-11-08 15:43:11,392 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 53\n",
            "[2025-11-08 15:43:13,313 INFO] Step 500/30000; acc: 19.3; ppl:  76.6; xent: 4.3; lr: 0.00100; sents:    6632; bsz: 3610/3049/133; 18217/15384 tok/s;    143 sec;\n",
            "[2025-11-08 15:43:14,741 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 54\n",
            "[2025-11-08 15:43:15,196 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 55\n",
            "[2025-11-08 15:43:15,688 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 56\n",
            "[2025-11-08 15:43:15,837 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 54\n",
            "[2025-11-08 15:43:16,188 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 57\n",
            "[2025-11-08 15:43:16,337 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 55\n",
            "[2025-11-08 15:43:16,643 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 58\n",
            "[2025-11-08 15:43:16,790 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 56\n",
            "[2025-11-08 15:43:17,074 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 59\n",
            "[2025-11-08 15:43:17,231 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 57\n",
            "[2025-11-08 15:43:17,512 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 60\n",
            "[2025-11-08 15:43:17,698 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 58\n",
            "[2025-11-08 15:43:17,944 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 61\n",
            "[2025-11-08 15:43:18,179 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 59\n",
            "[2025-11-08 15:43:18,862 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 60\n",
            "[2025-11-08 15:43:19,405 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 61\n",
            "[2025-11-08 15:43:23,390 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 62\n",
            "[2025-11-08 15:43:23,903 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 63\n",
            "[2025-11-08 15:43:23,955 INFO] valid stats calculation\n",
            "                           took: 10.640912055969238 s.\n",
            "[2025-11-08 15:43:23,955 INFO] Train perplexity: 193.234\n",
            "[2025-11-08 15:43:23,955 INFO] Train accuracy: 11.8826\n",
            "[2025-11-08 15:43:23,955 INFO] Sentences processed: 63251\n",
            "[2025-11-08 15:43:23,955 INFO] Average bsz: 3536/2960/127\n",
            "[2025-11-08 15:43:23,956 INFO] Validation perplexity: 64.9647\n",
            "[2025-11-08 15:43:23,956 INFO] Validation accuracy: 17.9156\n",
            "[2025-11-08 15:43:23,956 INFO] Model is improving ppl: 147.94 --> 64.9647.\n",
            "[2025-11-08 15:43:23,959 INFO] Saving checkpoint outputs/gru-aug-cbk/model_gru_aug_cbk_step_500.pt\n",
            "[2025-11-08 15:43:24,685 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 62\n",
            "[2025-11-08 15:43:25,144 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 63\n",
            "[2025-11-08 15:43:33,505 INFO] Step 550/30000; acc: 18.6; ppl:  69.1; xent: 4.2; lr: 0.00100; sents:    6557; bsz: 3230/2573/131; 7998/6371 tok/s;    163 sec;\n",
            "[2025-11-08 15:43:42,858 INFO] Step 600/30000; acc: 21.4; ppl:  60.3; xent: 4.1; lr: 0.00100; sents:    6175; bsz: 3534/3043/124; 18892/16270 tok/s;    172 sec;\n",
            "[2025-11-08 15:43:52,803 INFO] Step 650/30000; acc: 21.9; ppl:  49.6; xent: 3.9; lr: 0.00100; sents:    6089; bsz: 3485/2869/122; 17523/14425 tok/s;    182 sec;\n",
            "[2025-11-08 15:44:02,377 INFO] Step 700/30000; acc: 23.5; ppl:  48.9; xent: 3.9; lr: 0.00100; sents:    6210; bsz: 3574/2954/124; 18668/15427 tok/s;    192 sec;\n",
            "[2025-11-08 15:44:11,856 INFO] Step 750/30000; acc: 23.1; ppl:  46.6; xent: 3.8; lr: 0.00100; sents:    5729; bsz: 3365/2821/115; 17752/14883 tok/s;    201 sec;\n",
            "[2025-11-08 15:44:21,695 INFO] valid stats calculation\n",
            "                           took: 9.838342428207397 s.\n",
            "[2025-11-08 15:44:21,696 INFO] Train perplexity: 127.726\n",
            "[2025-11-08 15:44:21,696 INFO] Train accuracy: 15.1029\n",
            "[2025-11-08 15:44:21,696 INFO] Sentences processed: 94011\n",
            "[2025-11-08 15:44:21,696 INFO] Average bsz: 3503/2924/125\n",
            "[2025-11-08 15:44:21,696 INFO] Validation perplexity: 43.4686\n",
            "[2025-11-08 15:44:21,696 INFO] Validation accuracy: 22.7538\n",
            "[2025-11-08 15:44:21,697 INFO] Model is improving ppl: 64.9647 --> 43.4686.\n",
            "[2025-11-08 15:44:23,624 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 64\n",
            "[2025-11-08 15:44:24,071 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 65\n",
            "[2025-11-08 15:44:25,228 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 64\n",
            "[2025-11-08 15:44:25,681 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 65\n",
            "[2025-11-08 15:44:28,176 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 66\n",
            "[2025-11-08 15:44:28,620 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 67\n",
            "[2025-11-08 15:44:29,057 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 68\n",
            "[2025-11-08 15:44:29,477 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 69\n",
            "[2025-11-08 15:44:29,842 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 66\n",
            "[2025-11-08 15:44:29,907 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 70\n",
            "[2025-11-08 15:44:30,274 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 67\n",
            "[2025-11-08 15:44:30,339 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 71\n",
            "[2025-11-08 15:44:30,699 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 68\n",
            "[2025-11-08 15:44:30,764 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 72\n",
            "[2025-11-08 15:44:30,855 INFO] Step 800/30000; acc: 24.7; ppl:  42.6; xent: 3.8; lr: 0.00100; sents:    6825; bsz: 3397/2944/136; 8941/7747 tok/s;    220 sec;\n",
            "[2025-11-08 15:44:31,129 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 69\n",
            "[2025-11-08 15:44:31,199 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 73\n",
            "[2025-11-08 15:44:31,550 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 70\n",
            "[2025-11-08 15:44:31,972 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 71\n",
            "[2025-11-08 15:44:32,390 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 72\n",
            "[2025-11-08 15:44:32,823 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 73\n",
            "[2025-11-08 15:44:36,119 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 74\n",
            "[2025-11-08 15:44:36,545 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 75\n",
            "[2025-11-08 15:44:36,959 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 76\n",
            "[2025-11-08 15:44:37,380 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 77\n",
            "[2025-11-08 15:44:37,734 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 74\n",
            "[2025-11-08 15:44:37,808 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 78\n",
            "[2025-11-08 15:44:38,157 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 75\n",
            "[2025-11-08 15:44:38,245 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 79\n",
            "[2025-11-08 15:44:38,587 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 76\n",
            "[2025-11-08 15:44:39,018 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 77\n",
            "[2025-11-08 15:44:39,461 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 78\n",
            "[2025-11-08 15:44:39,903 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 79\n",
            "[2025-11-08 15:44:40,342 INFO] Step 850/30000; acc: 26.0; ppl:  39.0; xent: 3.7; lr: 0.00100; sents:    6792; bsz: 3531/2880/136; 18610/15179 tok/s;    230 sec;\n",
            "[2025-11-08 15:44:49,655 INFO] Step 900/30000; acc: 27.3; ppl:  35.1; xent: 3.6; lr: 0.00100; sents:    6366; bsz: 3602/3021/127; 19342/16221 tok/s;    239 sec;\n",
            "[2025-11-08 15:44:58,914 INFO] Step 950/30000; acc: 28.1; ppl:  30.5; xent: 3.4; lr: 0.00100; sents:    6327; bsz: 3515/2901/127; 18984/15669 tok/s;    248 sec;\n",
            "[2025-11-08 15:45:08,381 INFO] Step 1000/30000; acc: 29.6; ppl:  29.0; xent: 3.4; lr: 0.00100; sents:    6405; bsz: 3535/2998/128; 18670/15837 tok/s;    258 sec;\n",
            "[2025-11-08 15:45:19,380 INFO] valid stats calculation\n",
            "                           took: 10.998121976852417 s.\n",
            "[2025-11-08 15:45:19,381 INFO] Train perplexity: 92.1197\n",
            "[2025-11-08 15:45:19,381 INFO] Train accuracy: 18.1317\n",
            "[2025-11-08 15:45:19,381 INFO] Sentences processed: 126726\n",
            "[2025-11-08 15:45:19,381 INFO] Average bsz: 3506/2930/127\n",
            "[2025-11-08 15:45:19,381 INFO] Validation perplexity: 30.5966\n",
            "[2025-11-08 15:45:19,381 INFO] Validation accuracy: 26.9088\n",
            "[2025-11-08 15:45:19,381 INFO] Model is improving ppl: 43.4686 --> 30.5966.\n",
            "[2025-11-08 15:45:19,384 INFO] Saving checkpoint outputs/gru-aug-cbk/model_gru_aug_cbk_step_1000.pt\n",
            "[2025-11-08 15:45:29,081 INFO] Step 1050/30000; acc: 29.7; ppl:  28.4; xent: 3.3; lr: 0.00100; sents:    6236; bsz: 3435/2944/125; 8298/7111 tok/s;    279 sec;\n",
            "[2025-11-08 15:45:29,370 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 80\n",
            "[2025-11-08 15:45:29,817 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 81\n",
            "[2025-11-08 15:45:30,269 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 82\n",
            "[2025-11-08 15:45:30,714 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 83\n",
            "[2025-11-08 15:45:31,154 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 84\n",
            "[2025-11-08 15:45:31,329 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 80\n",
            "[2025-11-08 15:45:31,594 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 85\n",
            "[2025-11-08 15:45:31,767 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 81\n",
            "[2025-11-08 15:45:32,027 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 86\n",
            "[2025-11-08 15:45:32,200 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 82\n",
            "[2025-11-08 15:45:32,471 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 87\n",
            "[2025-11-08 15:45:32,633 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 83\n",
            "[2025-11-08 15:45:32,915 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 88\n",
            "[2025-11-08 15:45:33,077 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 84\n",
            "[2025-11-08 15:45:33,528 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 85\n",
            "[2025-11-08 15:45:33,956 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 86\n",
            "[2025-11-08 15:45:34,382 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 87\n",
            "[2025-11-08 15:45:34,825 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 88\n",
            "[2025-11-08 15:45:35,264 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 89\n",
            "[2025-11-08 15:45:37,707 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 89\n",
            "[2025-11-08 15:45:38,136 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 90\n",
            "[2025-11-08 15:45:38,572 INFO] Step 1100/30000; acc: 29.0; ppl:  27.5; xent: 3.3; lr: 0.00100; sents:    6234; bsz: 3467/2859/125; 18262/15063 tok/s;    288 sec;\n",
            "[2025-11-08 15:45:38,595 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 91\n",
            "[2025-11-08 15:45:39,055 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 92\n",
            "[2025-11-08 15:45:39,479 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 93\n",
            "[2025-11-08 15:45:39,920 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 94\n",
            "[2025-11-08 15:45:40,118 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 90\n",
            "[2025-11-08 15:45:40,360 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 95\n",
            "[2025-11-08 15:45:40,548 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 91\n",
            "[2025-11-08 15:45:40,976 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 92\n",
            "[2025-11-08 15:45:41,403 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 93\n",
            "[2025-11-08 15:45:41,844 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 94\n",
            "[2025-11-08 15:45:42,278 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 95\n",
            "[2025-11-08 15:45:47,943 INFO] Step 1150/30000; acc: 29.6; ppl:  26.6; xent: 3.3; lr: 0.00100; sents:    6190; bsz: 3504/2874/124; 18697/15335 tok/s;    297 sec;\n",
            "[2025-11-08 15:45:57,760 INFO] Step 1200/30000; acc: 31.0; ppl:  24.1; xent: 3.2; lr: 0.00100; sents:    5749; bsz: 3633/2981/115; 18505/15185 tok/s;    307 sec;\n",
            "[2025-11-08 15:46:07,429 INFO] Step 1250/30000; acc: 31.6; ppl:  23.1; xent: 3.1; lr: 0.00100; sents:    6046; bsz: 3625/3015/121; 18748/15590 tok/s;    317 sec;\n",
            "[2025-11-08 15:46:19,050 INFO] valid stats calculation\n",
            "                           took: 11.620394229888916 s.\n",
            "[2025-11-08 15:46:19,051 INFO] Train perplexity: 71.4\n",
            "[2025-11-08 15:46:19,051 INFO] Train accuracy: 20.5476\n",
            "[2025-11-08 15:46:19,051 INFO] Sentences processed: 157181\n",
            "[2025-11-08 15:46:19,051 INFO] Average bsz: 3512/2931/126\n",
            "[2025-11-08 15:46:19,051 INFO] Validation perplexity: 25.048\n",
            "[2025-11-08 15:46:19,051 INFO] Validation accuracy: 29.5432\n",
            "[2025-11-08 15:46:19,052 INFO] Model is improving ppl: 30.5966 --> 25.048.\n",
            "[2025-11-08 15:46:28,076 INFO] Step 1300/30000; acc: 32.9; ppl:  20.1; xent: 3.0; lr: 0.00100; sents:    6892; bsz: 3352/2858/138; 8117/6922 tok/s;    338 sec;\n",
            "[2025-11-08 15:46:35,841 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 96\n",
            "[2025-11-08 15:46:36,293 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 97\n",
            "[2025-11-08 15:46:36,735 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 98\n",
            "[2025-11-08 15:46:37,184 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 99\n",
            "[2025-11-08 15:46:37,338 INFO] Step 1350/30000; acc: 33.5; ppl:  21.0; xent: 3.0; lr: 0.00100; sents:    6755; bsz: 3537/2993/135; 19095/16157 tok/s;    347 sec;\n",
            "[2025-11-08 15:46:37,637 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 100\n",
            "[2025-11-08 15:46:38,071 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 101\n",
            "[2025-11-08 15:46:38,298 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 96\n",
            "[2025-11-08 15:46:38,522 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 102\n",
            "[2025-11-08 15:46:38,762 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 97\n",
            "[2025-11-08 15:46:39,222 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 98\n",
            "[2025-11-08 15:46:39,678 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 99\n",
            "[2025-11-08 15:46:40,133 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 100\n",
            "[2025-11-08 15:46:40,587 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 101\n",
            "[2025-11-08 15:46:41,034 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 102\n",
            "[2025-11-08 15:46:41,484 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 103\n",
            "[2025-11-08 15:46:43,247 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 103\n",
            "[2025-11-08 15:46:43,680 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 104\n",
            "[2025-11-08 15:46:44,108 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 105\n",
            "[2025-11-08 15:46:44,560 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 106\n",
            "[2025-11-08 15:46:44,991 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 107\n",
            "[2025-11-08 15:46:45,424 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 108\n",
            "[2025-11-08 15:46:45,863 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 109\n",
            "[2025-11-08 15:46:46,307 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 110\n",
            "[2025-11-08 15:46:46,329 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 104\n",
            "[2025-11-08 15:46:46,781 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 105\n",
            "[2025-11-08 15:46:46,897 INFO] Step 1400/30000; acc: 30.7; ppl:  21.7; xent: 3.1; lr: 0.00100; sents:    5978; bsz: 3384/2792/120; 17705/14606 tok/s;    356 sec;\n",
            "[2025-11-08 15:46:47,232 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 106\n",
            "[2025-11-08 15:46:47,700 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 107\n",
            "[2025-11-08 15:46:48,151 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 108\n",
            "[2025-11-08 15:46:48,618 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 109\n",
            "[2025-11-08 15:46:49,130 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 110\n",
            "[2025-11-08 15:46:56,341 INFO] Step 1450/30000; acc: 34.2; ppl:  19.9; xent: 3.0; lr: 0.00100; sents:    6930; bsz: 3560/3013/139; 18847/15952 tok/s;    366 sec;\n",
            "[2025-11-08 15:47:05,488 INFO] Step 1500/30000; acc: 36.5; ppl:  16.7; xent: 2.8; lr: 0.00100; sents:    6907; bsz: 3573/3043/138; 19532/16635 tok/s;    375 sec;\n",
            "[2025-11-08 15:47:15,963 INFO] valid stats calculation\n",
            "                           took: 10.472939252853394 s.\n",
            "[2025-11-08 15:47:15,963 INFO] Train perplexity: 57.6042\n",
            "[2025-11-08 15:47:15,963 INFO] Train accuracy: 22.7313\n",
            "[2025-11-08 15:47:15,963 INFO] Sentences processed: 190643\n",
            "[2025-11-08 15:47:15,964 INFO] Average bsz: 3507/2933/127\n",
            "[2025-11-08 15:47:15,964 INFO] Validation perplexity: 22.3644\n",
            "[2025-11-08 15:47:15,964 INFO] Validation accuracy: 30.8197\n",
            "[2025-11-08 15:47:15,964 INFO] Model is improving ppl: 25.048 --> 22.3644.\n",
            "[2025-11-08 15:47:15,968 INFO] Saving checkpoint outputs/gru-aug-cbk/model_gru_aug_cbk_step_1500.pt\n",
            "[2025-11-08 15:47:26,662 INFO] Step 1550/30000; acc: 35.7; ppl:  17.1; xent: 2.8; lr: 0.00100; sents:    6008; bsz: 3666/3104/120; 8658/7331 tok/s;    396 sec;\n",
            "[2025-11-08 15:47:36,051 INFO] Step 1600/30000; acc: 35.0; ppl:  17.1; xent: 2.8; lr: 0.00100; sents:    6234; bsz: 3583/2972/125; 19086/15830 tok/s;    406 sec;\n",
            "[2025-11-08 15:47:41,960 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 111\n",
            "[2025-11-08 15:47:42,468 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 112\n",
            "[2025-11-08 15:47:42,968 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 113\n",
            "[2025-11-08 15:47:43,426 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 114\n",
            "[2025-11-08 15:47:44,724 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 111\n",
            "[2025-11-08 15:47:45,201 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 112\n",
            "[2025-11-08 15:47:45,573 INFO] Step 1650/30000; acc: 34.9; ppl:  16.5; xent: 2.8; lr: 0.00100; sents:    6605; bsz: 3525/2941/132; 18512/15446 tok/s;    415 sec;\n",
            "[2025-11-08 15:47:45,636 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 113\n",
            "[2025-11-08 15:47:46,081 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 114\n",
            "[2025-11-08 15:47:46,592 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 115\n",
            "[2025-11-08 15:47:47,106 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 116\n",
            "[2025-11-08 15:47:47,623 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 117\n",
            "[2025-11-08 15:47:47,907 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 115\n",
            "[2025-11-08 15:47:48,346 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 116\n",
            "[2025-11-08 15:47:48,797 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 117\n",
            "[2025-11-08 15:47:49,241 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 118\n",
            "[2025-11-08 15:47:49,693 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 119\n",
            "[2025-11-08 15:47:50,127 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 120\n",
            "[2025-11-08 15:47:50,571 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 121\n",
            "[2025-11-08 15:47:51,006 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 122\n",
            "[2025-11-08 15:47:51,449 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 123\n",
            "[2025-11-08 15:47:52,340 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 118\n",
            "[2025-11-08 15:47:52,781 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 119\n",
            "[2025-11-08 15:47:53,230 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 120\n",
            "[2025-11-08 15:47:53,673 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 121\n",
            "[2025-11-08 15:47:54,111 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 122\n",
            "[2025-11-08 15:47:54,554 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 123\n",
            "[2025-11-08 15:47:54,999 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 124\n",
            "[2025-11-08 15:47:55,146 INFO] Step 1700/30000; acc: 34.4; ppl:  17.0; xent: 2.8; lr: 0.00100; sents:    6282; bsz: 3383/2817/126; 17669/14715 tok/s;    425 sec;\n",
            "[2025-11-08 15:47:55,437 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 125\n",
            "[2025-11-08 15:47:55,886 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 126\n",
            "[2025-11-08 15:47:56,712 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 124\n",
            "[2025-11-08 15:47:57,150 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 125\n",
            "[2025-11-08 15:47:57,588 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 126\n",
            "[2025-11-08 15:48:04,701 INFO] Step 1750/30000; acc: 31.9; ppl:  17.1; xent: 2.8; lr: 0.00100; sents:    5817; bsz: 3226/2638/116; 16884/13808 tok/s;    434 sec;\n",
            "[2025-11-08 15:48:15,075 INFO] valid stats calculation\n",
            "                           took: 10.373028039932251 s.\n",
            "[2025-11-08 15:48:15,076 INFO] Train perplexity: 48.4533\n",
            "[2025-11-08 15:48:15,076 INFO] Train accuracy: 24.3869\n",
            "[2025-11-08 15:48:15,076 INFO] Sentences processed: 221589\n",
            "[2025-11-08 15:48:15,076 INFO] Average bsz: 3502/2927/127\n",
            "[2025-11-08 15:48:15,076 INFO] Validation perplexity: 20.5409\n",
            "[2025-11-08 15:48:15,076 INFO] Validation accuracy: 31.4921\n",
            "[2025-11-08 15:48:15,077 INFO] Model is improving ppl: 22.3644 --> 20.5409.\n",
            "[2025-11-08 15:48:24,548 INFO] Step 1800/30000; acc: 38.6; ppl:  14.0; xent: 2.6; lr: 0.00100; sents:    6473; bsz: 3694/3018/129; 9306/7603 tok/s;    454 sec;\n",
            "[2025-11-08 15:48:34,424 INFO] Step 1850/30000; acc: 37.1; ppl:  13.5; xent: 2.6; lr: 0.00100; sents:    6546; bsz: 3443/2852/131; 17434/14443 tok/s;    464 sec;\n",
            "[2025-11-08 15:48:44,035 INFO] Step 1900/30000; acc: 35.9; ppl:  14.0; xent: 2.6; lr: 0.00100; sents:    6467; bsz: 3394/2824/129; 17658/14692 tok/s;    474 sec;\n",
            "[2025-11-08 15:48:48,426 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 127\n",
            "[2025-11-08 15:48:48,891 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 128\n",
            "[2025-11-08 15:48:49,342 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 129\n",
            "[2025-11-08 15:48:49,794 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 130\n",
            "[2025-11-08 15:48:50,246 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 131\n",
            "[2025-11-08 15:48:50,694 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 132\n",
            "[2025-11-08 15:48:51,137 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 133\n",
            "[2025-11-08 15:48:51,587 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 134\n",
            "[2025-11-08 15:48:51,798 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 127\n",
            "[2025-11-08 15:48:52,255 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 128\n",
            "[2025-11-08 15:48:52,707 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 129\n",
            "[2025-11-08 15:48:53,161 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 130\n",
            "[2025-11-08 15:48:54,008 INFO] Step 1950/30000; acc: 34.8; ppl:  15.1; xent: 2.7; lr: 0.00100; sents:    5454; bsz: 3510/2822/109; 17600/14149 tok/s;    484 sec;\n",
            "[2025-11-08 15:48:56,361 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 135\n",
            "[2025-11-08 15:48:56,803 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 136\n",
            "[2025-11-08 15:48:57,255 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 137\n",
            "[2025-11-08 15:48:57,731 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 131\n",
            "[2025-11-08 15:48:57,737 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 138\n",
            "[2025-11-08 15:48:58,169 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 139\n",
            "[2025-11-08 15:48:58,170 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 132\n",
            "[2025-11-08 15:48:58,611 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 140\n",
            "[2025-11-08 15:48:58,613 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 133\n",
            "[2025-11-08 15:48:59,056 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 134\n",
            "[2025-11-08 15:48:59,064 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 141\n",
            "[2025-11-08 15:48:59,507 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 135\n",
            "[2025-11-08 15:48:59,518 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 142\n",
            "[2025-11-08 15:48:59,947 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 136\n",
            "[2025-11-08 15:49:00,388 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 137\n",
            "[2025-11-08 15:49:00,819 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 138\n",
            "[2025-11-08 15:49:03,477 INFO] Step 2000/30000; acc: 37.6; ppl:  13.8; xent: 2.6; lr: 0.00100; sents:    6719; bsz: 3494/3000/134; 18451/15845 tok/s;    493 sec;\n",
            "[2025-11-08 15:49:06,057 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 139\n",
            "[2025-11-08 15:49:06,534 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 140\n",
            "[2025-11-08 15:49:06,982 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 141\n",
            "[2025-11-08 15:49:07,420 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 142\n",
            "[2025-11-08 15:49:14,011 INFO] valid stats calculation\n",
            "                           took: 10.532938480377197 s.\n",
            "[2025-11-08 15:49:14,011 INFO] Train perplexity: 41.5574\n",
            "[2025-11-08 15:49:14,011 INFO] Train accuracy: 25.9303\n",
            "[2025-11-08 15:49:14,011 INFO] Sentences processed: 253248\n",
            "[2025-11-08 15:49:14,012 INFO] Average bsz: 3503/2924/127\n",
            "[2025-11-08 15:49:14,012 INFO] Validation perplexity: 19.0444\n",
            "[2025-11-08 15:49:14,012 INFO] Validation accuracy: 32.4005\n",
            "[2025-11-08 15:49:14,013 INFO] Model is improving ppl: 20.5409 --> 19.0444.\n",
            "[2025-11-08 15:49:14,016 INFO] Saving checkpoint outputs/gru-aug-cbk/model_gru_aug_cbk_step_2000.pt\n",
            "[2025-11-08 15:49:23,852 INFO] Step 2050/30000; acc: 37.3; ppl:  13.9; xent: 2.6; lr: 0.00100; sents:    6401; bsz: 3523/3023/128; 8646/7419 tok/s;    513 sec;\n",
            "[2025-11-08 15:49:33,754 INFO] Step 2100/30000; acc: 38.1; ppl:  12.1; xent: 2.5; lr: 0.00100; sents:    6117; bsz: 3439/2895/122; 17367/14616 tok/s;    523 sec;\n",
            "[2025-11-08 15:49:43,355 INFO] Step 2150/30000; acc: 40.4; ppl:  11.4; xent: 2.4; lr: 0.00100; sents:    6741; bsz: 3457/2941/135; 18009/15316 tok/s;    533 sec;\n",
            "[2025-11-08 15:49:52,896 INFO] Step 2200/30000; acc: 39.3; ppl:  12.0; xent: 2.5; lr: 0.00100; sents:    6456; bsz: 3663/2987/129; 19197/15654 tok/s;    542 sec;\n",
            "[2025-11-08 15:49:55,167 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 143\n",
            "[2025-11-08 15:49:55,628 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 144\n",
            "[2025-11-08 15:49:56,070 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 145\n",
            "[2025-11-08 15:49:56,583 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 146\n",
            "[2025-11-08 15:49:57,036 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 147\n",
            "[2025-11-08 15:49:58,871 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 143\n",
            "[2025-11-08 15:49:59,316 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 144\n",
            "[2025-11-08 15:49:59,758 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 145\n",
            "[2025-11-08 15:50:00,205 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 146\n",
            "[2025-11-08 15:50:00,645 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 147\n",
            "[2025-11-08 15:50:01,085 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 148\n",
            "[2025-11-08 15:50:01,543 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 149\n",
            "[2025-11-08 15:50:01,576 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 148\n",
            "[2025-11-08 15:50:01,995 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 150\n",
            "[2025-11-08 15:50:02,037 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 149\n",
            "[2025-11-08 15:50:02,483 INFO] Step 2250/30000; acc: 38.4; ppl:  12.4; xent: 2.5; lr: 0.00100; sents:    6100; bsz: 3529/2939/122; 18406/15331 tok/s;    552 sec;\n",
            "[2025-11-08 15:50:02,483 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 150\n",
            "[2025-11-08 15:50:02,932 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 151\n",
            "[2025-11-08 15:50:03,440 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 152\n",
            "[2025-11-08 15:50:03,877 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 153\n",
            "[2025-11-08 15:50:04,317 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 154\n",
            "[2025-11-08 15:50:04,759 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 155\n",
            "[2025-11-08 15:50:06,847 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 151\n",
            "[2025-11-08 15:50:07,456 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 152\n",
            "[2025-11-08 15:50:08,054 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 153\n",
            "[2025-11-08 15:50:08,619 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 154\n",
            "[2025-11-08 15:50:09,085 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 155\n",
            "[2025-11-08 15:50:09,528 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 156\n",
            "[2025-11-08 15:50:09,989 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 157\n",
            "[2025-11-08 15:50:10,356 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 156\n",
            "[2025-11-08 15:50:10,442 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 158\n",
            "[2025-11-08 15:50:10,806 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 157\n",
            "[2025-11-08 15:50:11,251 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 158\n",
            "[2025-11-08 15:50:12,920 INFO] valid stats calculation\n",
            "                           took: 10.436150312423706 s.\n",
            "[2025-11-08 15:50:12,921 INFO] Train perplexity: 36.2701\n",
            "[2025-11-08 15:50:12,921 INFO] Train accuracy: 27.3619\n",
            "[2025-11-08 15:50:12,921 INFO] Sentences processed: 285063\n",
            "[2025-11-08 15:50:12,921 INFO] Average bsz: 3505/2928/127\n",
            "[2025-11-08 15:50:12,921 INFO] Validation perplexity: 18.4571\n",
            "[2025-11-08 15:50:12,921 INFO] Validation accuracy: 32.9951\n",
            "[2025-11-08 15:50:12,921 INFO] Model is improving ppl: 19.0444 --> 18.4571.\n",
            "[2025-11-08 15:50:22,428 INFO] Step 2300/30000; acc: 38.8; ppl:  12.1; xent: 2.5; lr: 0.00100; sents:    6245; bsz: 3443/2936/125; 8633/7362 tok/s;    572 sec;\n",
            "[2025-11-08 15:50:31,545 INFO] Step 2350/30000; acc: 41.0; ppl:  11.0; xent: 2.4; lr: 0.00100; sents:    6764; bsz: 3570/2918/135; 19578/16005 tok/s;    581 sec;\n",
            "[2025-11-08 15:50:40,979 INFO] Step 2400/30000; acc: 43.3; ppl:   9.8; xent: 2.3; lr: 0.00100; sents:    6909; bsz: 3663/3046/138; 19417/16144 tok/s;    590 sec;\n",
            "[2025-11-08 15:50:51,025 INFO] Step 2450/30000; acc: 38.1; ppl:  10.9; xent: 2.4; lr: 0.00100; sents:    5553; bsz: 3402/2794/111; 16931/13906 tok/s;    601 sec;\n",
            "[2025-11-08 15:51:00,294 INFO] Step 2500/30000; acc: 41.5; ppl:  10.3; xent: 2.3; lr: 0.00100; sents:    6939; bsz: 3456/3024/139; 18644/16313 tok/s;    610 sec;\n",
            "[2025-11-08 15:51:10,078 INFO] valid stats calculation\n",
            "                           took: 9.783263444900513 s.\n",
            "[2025-11-08 15:51:10,079 INFO] Train perplexity: 32.108\n",
            "[2025-11-08 15:51:10,079 INFO] Train accuracy: 28.69\n",
            "[2025-11-08 15:51:10,079 INFO] Sentences processed: 317473\n",
            "[2025-11-08 15:51:10,079 INFO] Average bsz: 3505/2929/127\n",
            "[2025-11-08 15:51:10,079 INFO] Validation perplexity: 17.6174\n",
            "[2025-11-08 15:51:10,080 INFO] Validation accuracy: 33.5543\n",
            "[2025-11-08 15:51:10,080 INFO] Model is improving ppl: 18.4571 --> 17.6174.\n",
            "[2025-11-08 15:51:10,082 INFO] Saving checkpoint outputs/gru-aug-cbk/model_gru_aug_cbk_step_2500.pt\n",
            "[2025-11-08 15:51:10,821 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 159\n",
            "[2025-11-08 15:51:14,780 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 159\n",
            "[2025-11-08 15:51:14,931 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 160\n",
            "[2025-11-08 15:51:15,223 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 160\n",
            "[2025-11-08 15:51:15,360 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 161\n",
            "[2025-11-08 15:51:15,668 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 161\n",
            "[2025-11-08 15:51:15,802 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 162\n",
            "[2025-11-08 15:51:16,114 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 162\n",
            "[2025-11-08 15:51:16,242 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 163\n",
            "[2025-11-08 15:51:16,559 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 163\n",
            "[2025-11-08 15:51:16,680 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 164\n",
            "[2025-11-08 15:51:17,114 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 165\n",
            "[2025-11-08 15:51:17,570 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 166\n",
            "[2025-11-08 15:51:18,023 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 167\n",
            "[2025-11-08 15:51:19,928 INFO] Step 2550/30000; acc: 40.1; ppl:  11.0; xent: 2.4; lr: 0.00100; sents:    6165; bsz: 3561/2954/123; 9068/7522 tok/s;    629 sec;\n",
            "[2025-11-08 15:51:21,146 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 164\n",
            "[2025-11-08 15:51:21,604 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 165\n",
            "[2025-11-08 15:51:22,038 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 166\n",
            "[2025-11-08 15:51:22,473 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 167\n",
            "[2025-11-08 15:51:22,905 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 168\n",
            "[2025-11-08 15:51:23,039 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 168\n",
            "[2025-11-08 15:51:23,370 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 169\n",
            "[2025-11-08 15:51:23,479 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 169\n",
            "[2025-11-08 15:51:23,804 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 170\n",
            "[2025-11-08 15:51:23,919 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 170\n",
            "[2025-11-08 15:51:24,241 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 171\n",
            "[2025-11-08 15:51:24,355 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 171\n",
            "[2025-11-08 15:51:24,798 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 172\n",
            "[2025-11-08 15:51:25,238 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 173\n",
            "[2025-11-08 15:51:29,611 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 172\n",
            "[2025-11-08 15:51:29,621 INFO] Step 2600/30000; acc: 37.2; ppl:  11.8; xent: 2.5; lr: 0.00100; sents:    5795; bsz: 3392/2790/116; 17499/14393 tok/s;    639 sec;\n",
            "[2025-11-08 15:51:30,069 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 173\n",
            "[2025-11-08 15:51:39,052 INFO] Step 2650/30000; acc: 41.2; ppl:   9.8; xent: 2.3; lr: 0.00100; sents:    6286; bsz: 3463/2937/126; 18362/15574 tok/s;    649 sec;\n",
            "[2025-11-08 15:51:48,496 INFO] Step 2700/30000; acc: 43.1; ppl:   9.0; xent: 2.2; lr: 0.00100; sents:    6377; bsz: 3506/3041/128; 18564/16103 tok/s;    658 sec;\n",
            "[2025-11-08 15:51:58,100 INFO] Step 2750/30000; acc: 43.8; ppl:   9.4; xent: 2.2; lr: 0.00100; sents:    6715; bsz: 3511/3051/134; 18282/15887 tok/s;    668 sec;\n",
            "[2025-11-08 15:52:08,298 INFO] valid stats calculation\n",
            "                           took: 10.197455167770386 s.\n",
            "[2025-11-08 15:52:08,299 INFO] Train perplexity: 28.8919\n",
            "[2025-11-08 15:52:08,299 INFO] Train accuracy: 29.8315\n",
            "[2025-11-08 15:52:08,299 INFO] Sentences processed: 348811\n",
            "[2025-11-08 15:52:08,299 INFO] Average bsz: 3504/2932/127\n",
            "[2025-11-08 15:52:08,299 INFO] Validation perplexity: 17.3239\n",
            "[2025-11-08 15:52:08,299 INFO] Validation accuracy: 34.0085\n",
            "[2025-11-08 15:52:08,300 INFO] Model is improving ppl: 17.6174 --> 17.3239.\n",
            "[2025-11-08 15:52:15,924 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 174\n",
            "[2025-11-08 15:52:16,398 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 175\n",
            "[2025-11-08 15:52:16,869 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 176\n",
            "[2025-11-08 15:52:17,338 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 177\n",
            "[2025-11-08 15:52:17,631 INFO] Step 2800/30000; acc: 41.2; ppl:   9.6; xent: 2.3; lr: 0.00100; sents:    6460; bsz: 3458/2848/129; 8854/7291 tok/s;    687 sec;\n",
            "[2025-11-08 15:52:17,795 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 178\n",
            "[2025-11-08 15:52:18,253 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 179\n",
            "[2025-11-08 15:52:18,698 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 180\n",
            "[2025-11-08 15:52:19,143 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 181\n",
            "[2025-11-08 15:52:20,219 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 174\n",
            "[2025-11-08 15:52:20,684 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 175\n",
            "[2025-11-08 15:52:23,956 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 182\n",
            "[2025-11-08 15:52:24,405 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 183\n",
            "[2025-11-08 15:52:24,855 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 184\n",
            "[2025-11-08 15:52:24,941 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 176\n",
            "[2025-11-08 15:52:25,309 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 185\n",
            "[2025-11-08 15:52:25,383 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 177\n",
            "[2025-11-08 15:52:25,757 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 186\n",
            "[2025-11-08 15:52:25,824 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 178\n",
            "[2025-11-08 15:52:26,206 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 187\n",
            "[2025-11-08 15:52:26,259 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 179\n",
            "[2025-11-08 15:52:26,666 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 188\n",
            "[2025-11-08 15:52:26,700 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 180\n",
            "[2025-11-08 15:52:27,040 INFO] Step 2850/30000; acc: 39.3; ppl:  10.2; xent: 2.3; lr: 0.00100; sents:    5855; bsz: 3472/2824/117; 18454/15008 tok/s;    697 sec;\n",
            "[2025-11-08 15:52:27,130 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 189\n",
            "[2025-11-08 15:52:27,152 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 181\n",
            "[2025-11-08 15:52:27,623 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 182\n",
            "[2025-11-08 15:52:28,076 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 183\n",
            "[2025-11-08 15:52:33,189 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 184\n",
            "[2025-11-08 15:52:33,641 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 185\n",
            "[2025-11-08 15:52:34,083 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 186\n",
            "[2025-11-08 15:52:34,525 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 187\n",
            "[2025-11-08 15:52:34,976 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 188\n",
            "[2025-11-08 15:52:35,427 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 189\n",
            "[2025-11-08 15:52:36,627 INFO] Step 2900/30000; acc: 41.0; ppl:  10.0; xent: 2.3; lr: 0.00100; sents:    6291; bsz: 3590/2888/126; 18724/15066 tok/s;    706 sec;\n",
            "[2025-11-08 15:52:46,519 INFO] Step 2950/30000; acc: 41.8; ppl:   9.0; xent: 2.2; lr: 0.00100; sents:    5890; bsz: 3563/2899/118; 18011/14657 tok/s;    716 sec;\n",
            "[2025-11-08 15:52:55,939 INFO] Step 3000/30000; acc: 43.4; ppl:   8.6; xent: 2.1; lr: 0.00100; sents:    6225; bsz: 3470/2994/124; 18416/15894 tok/s;    725 sec;\n",
            "[2025-11-08 15:53:06,543 INFO] valid stats calculation\n",
            "                           took: 10.602257251739502 s.\n",
            "[2025-11-08 15:53:06,543 INFO] Train perplexity: 26.3476\n",
            "[2025-11-08 15:53:06,543 INFO] Train accuracy: 30.7802\n",
            "[2025-11-08 15:53:06,543 INFO] Sentences processed: 379532\n",
            "[2025-11-08 15:53:06,543 INFO] Average bsz: 3504/2928/127\n",
            "[2025-11-08 15:53:06,544 INFO] Validation perplexity: 16.8679\n",
            "[2025-11-08 15:53:06,544 INFO] Validation accuracy: 34.3117\n",
            "[2025-11-08 15:53:06,544 INFO] Model is improving ppl: 17.3239 --> 16.8679.\n",
            "[2025-11-08 15:53:06,546 INFO] Saving checkpoint outputs/gru-aug-cbk/model_gru_aug_cbk_step_3000.pt\n",
            "[2025-11-08 15:53:16,427 INFO] Step 3050/30000; acc: 42.5; ppl:   8.7; xent: 2.2; lr: 0.00100; sents:    6359; bsz: 3472/2942/127; 8475/7180 tok/s;    746 sec;\n",
            "[2025-11-08 15:53:22,154 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 190\n",
            "[2025-11-08 15:53:22,606 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 191\n",
            "[2025-11-08 15:53:23,045 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 192\n",
            "[2025-11-08 15:53:23,485 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 193\n",
            "[2025-11-08 15:53:23,922 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 194\n",
            "[2025-11-08 15:53:24,374 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 195\n",
            "[2025-11-08 15:53:25,744 INFO] Step 3100/30000; acc: 43.5; ppl:   8.8; xent: 2.2; lr: 0.00100; sents:    6584; bsz: 3591/2948/132; 19273/15820 tok/s;    755 sec;\n",
            "[2025-11-08 15:53:27,007 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 190\n",
            "[2025-11-08 15:53:27,458 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 191\n",
            "[2025-11-08 15:53:27,906 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 192\n",
            "[2025-11-08 15:53:28,359 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 193\n",
            "[2025-11-08 15:53:28,812 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 194\n",
            "[2025-11-08 15:53:28,926 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 196\n",
            "[2025-11-08 15:53:29,267 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 195\n",
            "[2025-11-08 15:53:29,364 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 197\n",
            "[2025-11-08 15:53:29,722 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 196\n",
            "[2025-11-08 15:53:29,805 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 198\n",
            "[2025-11-08 15:53:30,183 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 197\n",
            "[2025-11-08 15:53:30,254 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 199\n",
            "[2025-11-08 15:53:30,638 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 198\n",
            "[2025-11-08 15:53:30,695 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 200\n",
            "[2025-11-08 15:53:31,125 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 201\n",
            "[2025-11-08 15:53:31,577 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 202\n",
            "[2025-11-08 15:53:32,023 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 203\n",
            "[2025-11-08 15:53:35,207 INFO] Step 3150/30000; acc: 41.3; ppl:   9.0; xent: 2.2; lr: 0.00100; sents:    6212; bsz: 3408/2846/124; 18011/15041 tok/s;    765 sec;\n",
            "[2025-11-08 15:53:35,522 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 199\n",
            "[2025-11-08 15:53:35,992 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 200\n",
            "[2025-11-08 15:53:36,442 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 201\n",
            "[2025-11-08 15:53:36,903 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 202\n",
            "[2025-11-08 15:53:37,343 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 203\n",
            "[2025-11-08 15:53:37,516 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 204\n",
            "[2025-11-08 15:53:37,809 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 204\n",
            "[2025-11-08 15:53:38,005 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 205\n",
            "[2025-11-08 15:53:38,277 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 205\n",
            "[2025-11-08 15:53:44,515 INFO] Step 3200/30000; acc: 43.4; ppl:   8.6; xent: 2.1; lr: 0.00100; sents:    6532; bsz: 3504/2870/131; 18822/15416 tok/s;    774 sec;\n",
            "[2025-11-08 15:53:54,085 INFO] Step 3250/30000; acc: 43.3; ppl:   8.0; xent: 2.1; lr: 0.00100; sents:    6302; bsz: 3512/2936/126; 18352/15340 tok/s;    784 sec;\n",
            "[2025-11-08 15:54:04,500 INFO] valid stats calculation\n",
            "                           took: 10.413958549499512 s.\n",
            "[2025-11-08 15:54:04,501 INFO] Train perplexity: 24.1884\n",
            "[2025-11-08 15:54:04,501 INFO] Train accuracy: 31.6987\n",
            "[2025-11-08 15:54:04,501 INFO] Sentences processed: 411521\n",
            "[2025-11-08 15:54:04,501 INFO] Average bsz: 3504/2927/127\n",
            "[2025-11-08 15:54:04,501 INFO] Validation perplexity: 16.9044\n",
            "[2025-11-08 15:54:04,502 INFO] Validation accuracy: 34.4061\n",
            "[2025-11-08 15:54:04,502 INFO] Decreasing patience: 4/5\n",
            "[2025-11-08 15:54:14,253 INFO] Step 3300/30000; acc: 46.7; ppl:   7.8; xent: 2.1; lr: 0.00100; sents:    6646; bsz: 3616/3152/133; 8966/7815 tok/s;    804 sec;\n",
            "[2025-11-08 15:54:24,114 INFO] Step 3350/30000; acc: 44.0; ppl:   8.1; xent: 2.1; lr: 0.00100; sents:    6092; bsz: 3580/2948/122; 18155/14947 tok/s;    814 sec;\n",
            "[2025-11-08 15:54:28,516 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 206\n",
            "[2025-11-08 15:54:28,961 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 207\n",
            "[2025-11-08 15:54:33,176 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 208\n",
            "[2025-11-08 15:54:33,586 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 206\n",
            "[2025-11-08 15:54:33,625 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 209\n",
            "[2025-11-08 15:54:33,696 INFO] Step 3400/30000; acc: 43.5; ppl:   8.2; xent: 2.1; lr: 0.00100; sents:    6299; bsz: 3475/2953/126; 18137/15410 tok/s;    823 sec;\n",
            "[2025-11-08 15:54:34,031 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 207\n",
            "[2025-11-08 15:54:34,069 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 210\n",
            "[2025-11-08 15:54:34,493 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 208\n",
            "[2025-11-08 15:54:34,524 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 211\n",
            "[2025-11-08 15:54:34,971 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 209\n",
            "[2025-11-08 15:54:35,007 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 212\n",
            "[2025-11-08 15:54:35,425 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 210\n",
            "[2025-11-08 15:54:35,467 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 213\n",
            "[2025-11-08 15:54:35,888 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 211\n",
            "[2025-11-08 15:54:35,938 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 214\n",
            "[2025-11-08 15:54:36,381 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 212\n",
            "[2025-11-08 15:54:36,439 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 215\n",
            "[2025-11-08 15:54:41,185 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 213\n",
            "[2025-11-08 15:54:41,628 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 214\n",
            "[2025-11-08 15:54:41,652 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 216\n",
            "[2025-11-08 15:54:42,072 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 215\n",
            "[2025-11-08 15:54:42,098 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 217\n",
            "[2025-11-08 15:54:42,542 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 216\n",
            "[2025-11-08 15:54:42,551 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 218\n",
            "[2025-11-08 15:54:42,980 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 217\n",
            "[2025-11-08 15:54:42,996 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 219\n",
            "[2025-11-08 15:54:43,104 INFO] Step 3450/30000; acc: 41.5; ppl:   8.6; xent: 2.1; lr: 0.00100; sents:    6045; bsz: 3450/2752/121; 18337/14627 tok/s;    833 sec;\n",
            "[2025-11-08 15:54:43,420 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 218\n",
            "[2025-11-08 15:54:43,453 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 220\n",
            "[2025-11-08 15:54:43,856 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 219\n",
            "[2025-11-08 15:54:44,310 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 220\n",
            "[2025-11-08 15:54:52,301 INFO] Step 3500/30000; acc: 44.1; ppl:   7.6; xent: 2.0; lr: 0.00100; sents:    6561; bsz: 3331/2807/131; 18109/15259 tok/s;    842 sec;\n",
            "[2025-11-08 15:55:02,625 INFO] valid stats calculation\n",
            "                           took: 10.322750329971313 s.\n",
            "[2025-11-08 15:55:02,626 INFO] Train perplexity: 22.3584\n",
            "[2025-11-08 15:55:02,626 INFO] Train accuracy: 32.5782\n",
            "[2025-11-08 15:55:02,626 INFO] Sentences processed: 443164\n",
            "[2025-11-08 15:55:02,626 INFO] Average bsz: 3503/2926/127\n",
            "[2025-11-08 15:55:02,626 INFO] Validation perplexity: 17.1835\n",
            "[2025-11-08 15:55:02,626 INFO] Validation accuracy: 34.2362\n",
            "[2025-11-08 15:55:02,627 INFO] Decreasing patience: 3/5\n",
            "[2025-11-08 15:55:02,630 INFO] Saving checkpoint outputs/gru-aug-cbk/model_gru_aug_cbk_step_3500.pt\n",
            "[2025-11-08 15:55:12,404 INFO] Step 3550/30000; acc: 44.8; ppl:   7.3; xent: 2.0; lr: 0.00100; sents:    6192; bsz: 3399/2928/124; 8455/7282 tok/s;    862 sec;\n",
            "[2025-11-08 15:55:22,732 INFO] Step 3600/30000; acc: 43.8; ppl:   7.7; xent: 2.0; lr: 0.00100; sents:    5773; bsz: 3582/2914/115; 17345/14108 tok/s;    872 sec;\n",
            "[2025-11-08 15:55:32,633 INFO] Step 3650/30000; acc: 43.7; ppl:   7.8; xent: 2.0; lr: 0.00100; sents:    5598; bsz: 3506/2918/112; 17708/14738 tok/s;    882 sec;\n",
            "[2025-11-08 15:55:34,687 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 221\n",
            "[2025-11-08 15:55:35,153 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 222\n",
            "[2025-11-08 15:55:35,596 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 223\n",
            "[2025-11-08 15:55:36,035 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 224\n",
            "[2025-11-08 15:55:36,473 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 225\n",
            "[2025-11-08 15:55:36,908 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 226\n",
            "[2025-11-08 15:55:37,339 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 227\n",
            "[2025-11-08 15:55:37,779 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 228\n",
            "[2025-11-08 15:55:38,223 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 229\n",
            "[2025-11-08 15:55:38,666 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 230\n",
            "[2025-11-08 15:55:39,099 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 231\n",
            "[2025-11-08 15:55:40,180 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 221\n",
            "[2025-11-08 15:55:40,675 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 222\n",
            "[2025-11-08 15:55:41,147 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 223\n",
            "[2025-11-08 15:55:41,606 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 224\n",
            "[2025-11-08 15:55:42,066 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 225\n",
            "[2025-11-08 15:55:42,181 INFO] Step 3700/30000; acc: 44.8; ppl:   7.5; xent: 2.0; lr: 0.00100; sents:    6811; bsz: 3590/2929/136; 18801/15339 tok/s;    892 sec;\n",
            "[2025-11-08 15:55:44,116 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 232\n",
            "[2025-11-08 15:55:44,604 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 233\n",
            "[2025-11-08 15:55:45,125 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 234\n",
            "[2025-11-08 15:55:45,617 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 235\n",
            "[2025-11-08 15:55:46,103 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 236\n",
            "[2025-11-08 15:55:46,669 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 226\n",
            "[2025-11-08 15:55:47,117 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 227\n",
            "[2025-11-08 15:55:47,564 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 228\n",
            "[2025-11-08 15:55:48,014 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 229\n",
            "[2025-11-08 15:55:48,459 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 230\n",
            "[2025-11-08 15:55:48,900 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 231\n",
            "[2025-11-08 15:55:49,349 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 232\n",
            "[2025-11-08 15:55:49,792 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 233\n",
            "[2025-11-08 15:55:51,229 INFO] Step 3750/30000; acc: 46.0; ppl:   7.3; xent: 2.0; lr: 0.00100; sents:    7050; bsz: 3400/2918/141; 18787/16125 tok/s;    901 sec;\n",
            "[2025-11-08 15:55:55,162 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 234\n",
            "[2025-11-08 15:55:55,613 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 235\n",
            "[2025-11-08 15:55:56,193 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 236\n",
            "[2025-11-08 15:56:01,532 INFO] valid stats calculation\n",
            "                           took: 10.302212715148926 s.\n",
            "[2025-11-08 15:56:01,533 INFO] Train perplexity: 20.7945\n",
            "[2025-11-08 15:56:01,533 INFO] Train accuracy: 33.378\n",
            "[2025-11-08 15:56:01,533 INFO] Sentences processed: 474588\n",
            "[2025-11-08 15:56:01,533 INFO] Average bsz: 3502/2926/127\n",
            "[2025-11-08 15:56:01,533 INFO] Validation perplexity: 16.8465\n",
            "[2025-11-08 15:56:01,534 INFO] Validation accuracy: 34.6456\n",
            "[2025-11-08 15:56:01,534 INFO] Model is improving ppl: 16.8679 --> 16.8465.\n",
            "[2025-11-08 15:56:10,746 INFO] Step 3800/30000; acc: 45.7; ppl:   7.1; xent: 2.0; lr: 0.00100; sents:    6523; bsz: 3479/2926/130; 8912/7496 tok/s;    920 sec;\n",
            "[2025-11-08 15:56:20,374 INFO] Step 3850/30000; acc: 44.5; ppl:   6.6; xent: 1.9; lr: 0.00100; sents:    6243; bsz: 3237/2752/125; 16811/14293 tok/s;    930 sec;\n",
            "[2025-11-08 15:56:30,159 INFO] Step 3900/30000; acc: 47.3; ppl:   7.0; xent: 1.9; lr: 0.00100; sents:    6261; bsz: 3594/3070/125; 18367/15691 tok/s;    940 sec;\n",
            "[2025-11-08 15:56:39,765 INFO] Step 3950/30000; acc: 45.7; ppl:   7.2; xent: 2.0; lr: 0.00100; sents:    6371; bsz: 3643/2988/127; 18965/15555 tok/s;    949 sec;\n",
            "[2025-11-08 15:56:39,991 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 237\n",
            "[2025-11-08 15:56:40,451 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 238\n",
            "[2025-11-08 15:56:40,900 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 239\n",
            "[2025-11-08 15:56:41,343 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 240\n",
            "[2025-11-08 15:56:41,799 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 241\n",
            "[2025-11-08 15:56:42,249 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 242\n",
            "[2025-11-08 15:56:42,699 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 243\n",
            "[2025-11-08 15:56:43,214 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 244\n",
            "[2025-11-08 15:56:43,671 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 245\n",
            "[2025-11-08 15:56:44,153 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 246\n",
            "[2025-11-08 15:56:44,624 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 247\n",
            "[2025-11-08 15:56:46,057 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 237\n",
            "[2025-11-08 15:56:49,481 INFO] Step 4000/30000; acc: 45.3; ppl:   7.2; xent: 2.0; lr: 0.00100; sents:    6340; bsz: 3565/2894/127; 18345/14894 tok/s;    959 sec;\n",
            "[2025-11-08 15:56:49,638 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 248\n",
            "[2025-11-08 15:56:50,110 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 249\n",
            "[2025-11-08 15:56:50,283 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 238\n",
            "[2025-11-08 15:56:50,567 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 250\n",
            "[2025-11-08 15:56:50,731 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 239\n",
            "[2025-11-08 15:56:51,010 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 251\n",
            "[2025-11-08 15:56:51,172 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 240\n",
            "[2025-11-08 15:56:51,461 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 252\n",
            "[2025-11-08 15:56:51,619 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 241\n",
            "[2025-11-08 15:56:52,064 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 242\n",
            "[2025-11-08 15:56:52,561 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 243\n",
            "[2025-11-08 15:56:53,002 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 244\n",
            "[2025-11-08 15:56:58,081 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 245\n",
            "[2025-11-08 15:56:58,525 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 246\n",
            "[2025-11-08 15:56:58,964 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 247\n",
            "[2025-11-08 15:56:59,410 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 248\n",
            "[2025-11-08 15:56:59,861 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 249\n",
            "[2025-11-08 15:56:59,910 INFO] valid stats calculation\n",
            "                           took: 10.427593231201172 s.\n",
            "[2025-11-08 15:56:59,910 INFO] Train perplexity: 19.4318\n",
            "[2025-11-08 15:56:59,910 INFO] Train accuracy: 34.1497\n",
            "[2025-11-08 15:56:59,910 INFO] Sentences processed: 506326\n",
            "[2025-11-08 15:56:59,911 INFO] Average bsz: 3502/2926/127\n",
            "[2025-11-08 15:56:59,911 INFO] Validation perplexity: 16.9424\n",
            "[2025-11-08 15:56:59,911 INFO] Validation accuracy: 34.576\n",
            "[2025-11-08 15:56:59,911 INFO] Decreasing patience: 4/5\n",
            "[2025-11-08 15:56:59,914 INFO] Saving checkpoint outputs/gru-aug-cbk/model_gru_aug_cbk_step_4000.pt\n",
            "[2025-11-08 15:57:00,328 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 250\n",
            "[2025-11-08 15:57:00,786 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 251\n",
            "[2025-11-08 15:57:01,231 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 252\n",
            "[2025-11-08 15:57:09,554 INFO] Step 4050/30000; acc: 47.6; ppl:   7.0; xent: 1.9; lr: 0.00100; sents:    6850; bsz: 3595/3073/137; 8956/7655 tok/s;    979 sec;\n",
            "[2025-11-08 15:57:18,988 INFO] Step 4100/30000; acc: 48.0; ppl:   6.7; xent: 1.9; lr: 0.00100; sents:    6211; bsz: 3573/2974/124; 18941/15763 tok/s;    988 sec;\n",
            "[2025-11-08 15:57:28,770 INFO] Step 4150/30000; acc: 48.1; ppl:   6.2; xent: 1.8; lr: 0.00100; sents:    6482; bsz: 3608/2957/130; 18446/15118 tok/s;    998 sec;\n",
            "[2025-11-08 15:57:38,534 INFO] Step 4200/30000; acc: 47.0; ppl:   6.3; xent: 1.8; lr: 0.00100; sents:    6346; bsz: 3507/2920/127; 17960/14954 tok/s;   1008 sec;\n",
            "[2025-11-08 15:57:46,567 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 253\n",
            "[2025-11-08 15:57:47,020 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 254\n",
            "[2025-11-08 15:57:47,474 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 255\n",
            "[2025-11-08 15:57:47,970 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 256\n",
            "[2025-11-08 15:57:48,253 INFO] Step 4250/30000; acc: 45.5; ppl:   7.0; xent: 1.9; lr: 0.00100; sents:    5799; bsz: 3461/2924/116; 17807/15046 tok/s;   1018 sec;\n",
            "[2025-11-08 15:57:48,483 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 257\n",
            "[2025-11-08 15:57:53,085 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 258\n",
            "[2025-11-08 15:57:53,647 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 259\n",
            "[2025-11-08 15:57:54,206 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 260\n",
            "[2025-11-08 15:57:54,647 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 261\n",
            "[2025-11-08 15:57:55,081 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 262\n",
            "[2025-11-08 15:57:55,545 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 263\n",
            "[2025-11-08 15:57:55,976 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 264\n",
            "[2025-11-08 15:57:56,410 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 265\n",
            "[2025-11-08 15:57:58,466 INFO] valid stats calculation\n",
            "                           took: 10.211345195770264 s.\n",
            "[2025-11-08 15:57:58,467 INFO] Train perplexity: 18.2233\n",
            "[2025-11-08 15:57:58,467 INFO] Train accuracy: 34.9316\n",
            "[2025-11-08 15:57:58,467 INFO] Sentences processed: 538014\n",
            "[2025-11-08 15:57:58,467 INFO] Average bsz: 3505/2929/127\n",
            "[2025-11-08 15:57:58,467 INFO] Validation perplexity: 16.9073\n",
            "[2025-11-08 15:57:58,467 INFO] Validation accuracy: 34.8603\n",
            "[2025-11-08 15:57:58,467 INFO] Decreasing patience: 3/5\n",
            "[2025-11-08 15:58:01,837 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 266\n",
            "[2025-11-08 15:58:02,346 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 267\n",
            "[2025-11-08 15:58:02,805 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 268\n",
            "[2025-11-08 15:58:03,587 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 253\n",
            "[2025-11-08 15:58:04,047 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 254\n",
            "[2025-11-08 15:58:04,585 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 255\n",
            "[2025-11-08 15:58:05,078 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 256\n",
            "[2025-11-08 15:58:05,556 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 257\n",
            "[2025-11-08 15:58:06,094 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 258\n",
            "[2025-11-08 15:58:08,517 INFO] Step 4300/30000; acc: 44.0; ppl:   7.3; xent: 2.0; lr: 0.00100; sents:    5777; bsz: 3537/2886/116; 8729/7121 tok/s;   1038 sec;\n",
            "[2025-11-08 15:58:10,706 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 259\n",
            "[2025-11-08 15:58:11,154 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 260\n",
            "[2025-11-08 15:58:11,608 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 261\n",
            "[2025-11-08 15:58:12,062 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 262\n",
            "[2025-11-08 15:58:12,516 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 263\n",
            "[2025-11-08 15:58:12,963 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 264\n",
            "[2025-11-08 15:58:13,420 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 265\n",
            "[2025-11-08 15:58:13,872 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 266\n",
            "[2025-11-08 15:58:17,783 INFO] Step 4350/30000; acc: 48.0; ppl:   6.1; xent: 1.8; lr: 0.00100; sents:    6946; bsz: 3397/2905/139; 18332/15676 tok/s;   1047 sec;\n",
            "[2025-11-08 15:58:19,404 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 267\n",
            "[2025-11-08 15:58:19,844 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 268\n",
            "[2025-11-08 15:58:27,373 INFO] Step 4400/30000; acc: 46.0; ppl:   6.4; xent: 1.9; lr: 0.00100; sents:    5962; bsz: 3477/2855/119; 18128/14886 tok/s;   1057 sec;\n",
            "[2025-11-08 15:58:37,267 INFO] Step 4450/30000; acc: 48.1; ppl:   5.7; xent: 1.7; lr: 0.00100; sents:    6361; bsz: 3396/2871/127; 17164/14510 tok/s;   1067 sec;\n",
            "[2025-11-08 15:58:46,740 INFO] Step 4500/30000; acc: 49.5; ppl:   6.0; xent: 1.8; lr: 0.00100; sents:    6499; bsz: 3585/3047/130; 18926/16084 tok/s;   1076 sec;\n",
            "[2025-11-08 15:58:57,106 INFO] valid stats calculation\n",
            "                           took: 10.365248203277588 s.\n",
            "[2025-11-08 15:58:57,107 INFO] Train perplexity: 17.1812\n",
            "[2025-11-08 15:58:57,107 INFO] Train accuracy: 35.6085\n",
            "[2025-11-08 15:58:57,107 INFO] Sentences processed: 569559\n",
            "[2025-11-08 15:58:57,107 INFO] Average bsz: 3504/2928/127\n",
            "[2025-11-08 15:58:57,107 INFO] Validation perplexity: 16.7002\n",
            "[2025-11-08 15:58:57,107 INFO] Validation accuracy: 35.324\n",
            "[2025-11-08 15:58:57,108 INFO] Model is improving ppl: 16.8465 --> 16.7002.\n",
            "[2025-11-08 15:58:57,110 INFO] Saving checkpoint outputs/gru-aug-cbk/model_gru_aug_cbk_step_4500.pt\n",
            "[2025-11-08 15:59:03,521 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 269\n",
            "[2025-11-08 15:59:06,661 INFO] Step 4550/30000; acc: 49.5; ppl:   5.8; xent: 1.8; lr: 0.00100; sents:    6696; bsz: 3473/2942/134; 8717/7386 tok/s;   1096 sec;\n",
            "[2025-11-08 15:59:07,712 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 270\n",
            "[2025-11-08 15:59:08,162 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 271\n",
            "[2025-11-08 15:59:08,610 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 272\n",
            "[2025-11-08 15:59:09,066 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 273\n",
            "[2025-11-08 15:59:09,524 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 274\n",
            "[2025-11-08 15:59:09,985 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 275\n",
            "[2025-11-08 15:59:09,986 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 269\n",
            "[2025-11-08 15:59:10,434 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 276\n",
            "[2025-11-08 15:59:10,437 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 270\n",
            "[2025-11-08 15:59:10,883 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 271\n",
            "[2025-11-08 15:59:15,276 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 272\n",
            "[2025-11-08 15:59:15,506 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 277\n",
            "[2025-11-08 15:59:15,756 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 273\n",
            "[2025-11-08 15:59:15,960 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 278\n",
            "[2025-11-08 15:59:16,065 INFO] Step 4600/30000; acc: 48.6; ppl:   5.9; xent: 1.8; lr: 0.00100; sents:    6880; bsz: 3515/2930/138; 18692/15582 tok/s;   1106 sec;\n",
            "[2025-11-08 15:59:16,205 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 274\n",
            "[2025-11-08 15:59:16,413 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 279\n",
            "[2025-11-08 15:59:16,655 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 275\n",
            "[2025-11-08 15:59:16,867 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 280\n",
            "[2025-11-08 15:59:17,102 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 276\n",
            "[2025-11-08 15:59:17,320 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 281\n",
            "[2025-11-08 15:59:17,555 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 277\n",
            "[2025-11-08 15:59:17,770 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 282\n",
            "[2025-11-08 15:59:18,003 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 278\n",
            "[2025-11-08 15:59:18,226 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 283\n",
            "[2025-11-08 15:59:18,449 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 279\n",
            "[2025-11-08 15:59:23,563 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 280\n",
            "[2025-11-08 15:59:23,997 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 281\n",
            "[2025-11-08 15:59:24,444 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 282\n",
            "[2025-11-08 15:59:24,886 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 283\n",
            "[2025-11-08 15:59:25,844 INFO] Step 4650/30000; acc: 44.7; ppl:   7.0; xent: 1.9; lr: 0.00100; sents:    5911; bsz: 3528/2891/118; 18040/14785 tok/s;   1115 sec;\n",
            "[2025-11-08 15:59:35,172 INFO] Step 4700/30000; acc: 48.5; ppl:   5.7; xent: 1.7; lr: 0.00100; sents:    6633; bsz: 3477/2860/133; 18642/15333 tok/s;   1125 sec;\n",
            "[2025-11-08 15:59:44,785 INFO] Step 4750/30000; acc: 48.0; ppl:   5.8; xent: 1.8; lr: 0.00100; sents:    5867; bsz: 3535/2889/117; 18389/15027 tok/s;   1134 sec;\n",
            "[2025-11-08 15:59:56,497 INFO] valid stats calculation\n",
            "                           took: 11.711134195327759 s.\n",
            "[2025-11-08 15:59:56,497 INFO] Train perplexity: 16.2662\n",
            "[2025-11-08 15:59:56,497 INFO] Train accuracy: 36.2479\n",
            "[2025-11-08 15:59:56,497 INFO] Sentences processed: 601546\n",
            "[2025-11-08 15:59:56,497 INFO] Average bsz: 3504/2926/127\n",
            "[2025-11-08 15:59:56,498 INFO] Validation perplexity: 17.0567\n",
            "[2025-11-08 15:59:56,498 INFO] Validation accuracy: 34.8816\n",
            "[2025-11-08 15:59:56,498 INFO] Decreasing patience: 4/5\n",
            "[2025-11-08 16:00:06,450 INFO] Step 4800/30000; acc: 48.6; ppl:   6.0; xent: 1.8; lr: 0.00100; sents:    6100; bsz: 3618/3001/122; 8351/6927 tok/s;   1156 sec;\n",
            "[2025-11-08 16:00:10,506 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 284\n",
            "[2025-11-08 16:00:10,982 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 285\n",
            "[2025-11-08 16:00:11,433 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 286\n",
            "[2025-11-08 16:00:11,879 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 287\n",
            "[2025-11-08 16:00:12,328 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 288\n",
            "[2025-11-08 16:00:12,788 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 289\n",
            "[2025-11-08 16:00:13,243 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 290\n",
            "[2025-11-08 16:00:16,175 INFO] Step 4850/30000; acc: 47.3; ppl:   6.3; xent: 1.8; lr: 0.00100; sents:    5824; bsz: 3554/2950/116; 18275/15171 tok/s;   1166 sec;\n",
            "[2025-11-08 16:00:17,664 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 284\n",
            "[2025-11-08 16:00:18,000 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 291\n",
            "[2025-11-08 16:00:18,150 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 285\n",
            "[2025-11-08 16:00:18,458 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 292\n",
            "[2025-11-08 16:00:18,615 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 286\n",
            "[2025-11-08 16:00:18,912 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 293\n",
            "[2025-11-08 16:00:19,069 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 287\n",
            "[2025-11-08 16:00:19,388 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 294\n",
            "[2025-11-08 16:00:19,554 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 288\n",
            "[2025-11-08 16:00:19,854 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 295\n",
            "[2025-11-08 16:00:20,011 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 289\n",
            "[2025-11-08 16:00:20,312 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 296\n",
            "[2025-11-08 16:00:20,784 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 297\n",
            "[2025-11-08 16:00:21,238 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 298\n",
            "[2025-11-08 16:00:21,689 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 299\n",
            "[2025-11-08 16:00:24,680 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 290\n",
            "[2025-11-08 16:00:25,206 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 291\n",
            "[2025-11-08 16:00:25,710 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 292\n",
            "[2025-11-08 16:00:25,741 INFO] Step 4900/30000; acc: 49.2; ppl:   5.6; xent: 1.7; lr: 0.00100; sents:    6694; bsz: 3374/2907/134; 17635/15194 tok/s;   1175 sec;\n",
            "[2025-11-08 16:00:26,158 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 293\n",
            "[2025-11-08 16:00:26,616 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 294\n",
            "[2025-11-08 16:00:27,107 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 295\n",
            "[2025-11-08 16:00:27,558 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 296\n",
            "[2025-11-08 16:00:28,000 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 297\n",
            "[2025-11-08 16:00:33,457 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 298\n",
            "[2025-11-08 16:00:33,905 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 299\n",
            "[2025-11-08 16:00:34,946 INFO] Step 4950/30000; acc: 50.2; ppl:   5.8; xent: 1.8; lr: 0.00100; sents:    6683; bsz: 3505/3006/134; 19038/16331 tok/s;   1184 sec;\n",
            "[2025-11-08 16:00:44,233 INFO] Step 5000/30000; acc: 48.5; ppl:   5.3; xent: 1.7; lr: 0.00100; sents:    6449; bsz: 3400/2859/129; 18309/15393 tok/s;   1194 sec;\n",
            "[2025-11-08 16:00:55,351 INFO] valid stats calculation\n",
            "                           took: 11.116530179977417 s.\n",
            "[2025-11-08 16:00:55,352 INFO] Train perplexity: 15.44\n",
            "[2025-11-08 16:00:55,352 INFO] Train accuracy: 36.8773\n",
            "[2025-11-08 16:00:55,354 INFO] Sentences processed: 633296\n",
            "[2025-11-08 16:00:55,354 INFO] Average bsz: 3503/2927/127\n",
            "[2025-11-08 16:00:55,354 INFO] Validation perplexity: 17.2085\n",
            "[2025-11-08 16:00:55,354 INFO] Validation accuracy: 35.2402\n",
            "[2025-11-08 16:00:55,355 INFO] Decreasing patience: 3/5\n",
            "[2025-11-08 16:00:55,358 INFO] Saving checkpoint outputs/gru-aug-cbk/model_gru_aug_cbk_step_5000.pt\n",
            "[2025-11-08 16:01:05,550 INFO] Step 5050/30000; acc: 49.8; ppl:   5.4; xent: 1.7; lr: 0.00100; sents:    6372; bsz: 3453/2912/127; 8100/6830 tok/s;   1215 sec;\n",
            "[2025-11-08 16:01:15,267 INFO] Step 5100/30000; acc: 48.8; ppl:   5.6; xent: 1.7; lr: 0.00100; sents:    5927; bsz: 3399/2846/119; 17494/14645 tok/s;   1225 sec;\n",
            "[2025-11-08 16:01:17,371 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 300\n",
            "[2025-11-08 16:01:17,819 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 301\n",
            "[2025-11-08 16:01:18,266 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 302\n",
            "[2025-11-08 16:01:18,712 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 303\n",
            "[2025-11-08 16:01:23,159 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 304\n",
            "[2025-11-08 16:01:23,618 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 305\n",
            "[2025-11-08 16:01:24,060 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 306\n",
            "[2025-11-08 16:01:24,507 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 307\n",
            "[2025-11-08 16:01:24,507 INFO] Step 5150/30000; acc: 49.6; ppl:   5.6; xent: 1.7; lr: 0.00100; sents:    6272; bsz: 3472/2983/125; 18789/16142 tok/s;   1234 sec;\n",
            "[2025-11-08 16:01:24,637 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 300\n",
            "[2025-11-08 16:01:24,949 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 308\n",
            "[2025-11-08 16:01:25,099 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 301\n",
            "[2025-11-08 16:01:25,390 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 309\n",
            "[2025-11-08 16:01:25,826 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 310\n",
            "[2025-11-08 16:01:26,270 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 311\n",
            "[2025-11-08 16:01:29,465 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 302\n",
            "[2025-11-08 16:01:29,915 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 303\n",
            "[2025-11-08 16:01:30,370 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 304\n",
            "[2025-11-08 16:01:30,826 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 305\n",
            "[2025-11-08 16:01:31,289 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 306\n",
            "[2025-11-08 16:01:31,574 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 312\n",
            "[2025-11-08 16:01:31,752 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 307\n",
            "[2025-11-08 16:01:32,017 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 313\n",
            "[2025-11-08 16:01:32,212 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 308\n",
            "[2025-11-08 16:01:32,474 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 314\n",
            "[2025-11-08 16:01:32,663 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 309\n",
            "[2025-11-08 16:01:32,910 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 315\n",
            "[2025-11-08 16:01:34,272 INFO] Step 5200/30000; acc: 48.8; ppl:   5.8; xent: 1.8; lr: 0.00100; sents:    6634; bsz: 3585/2920/133; 18356/14952 tok/s;   1244 sec;\n",
            "[2025-11-08 16:01:37,843 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 310\n",
            "[2025-11-08 16:01:38,286 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 311\n",
            "[2025-11-08 16:01:38,740 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 312\n",
            "[2025-11-08 16:01:39,190 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 313\n",
            "[2025-11-08 16:01:39,656 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 314\n",
            "[2025-11-08 16:01:40,145 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 315\n",
            "[2025-11-08 16:01:43,747 INFO] Step 5250/30000; acc: 50.0; ppl:   5.7; xent: 1.7; lr: 0.00100; sents:    6637; bsz: 3694/3022/133; 19495/15949 tok/s;   1253 sec;\n",
            "[2025-11-08 16:01:54,063 INFO] valid stats calculation\n",
            "                           took: 10.315807580947876 s.\n",
            "[2025-11-08 16:01:54,064 INFO] Train perplexity: 14.7091\n",
            "[2025-11-08 16:01:54,064 INFO] Train accuracy: 37.4756\n",
            "[2025-11-08 16:01:54,064 INFO] Sentences processed: 665138\n",
            "[2025-11-08 16:01:54,064 INFO] Average bsz: 3504/2928/127\n",
            "[2025-11-08 16:01:54,064 INFO] Validation perplexity: 16.888\n",
            "[2025-11-08 16:01:54,064 INFO] Validation accuracy: 35.2402\n",
            "[2025-11-08 16:01:54,064 INFO] Decreasing patience: 2/5\n",
            "[2025-11-08 16:02:04,029 INFO] Step 5300/30000; acc: 49.9; ppl:   5.2; xent: 1.6; lr: 0.00100; sents:    6136; bsz: 3524/2892/123; 8689/7131 tok/s;   1274 sec;\n",
            "[2025-11-08 16:02:13,124 INFO] Step 5350/30000; acc: 53.2; ppl:   4.9; xent: 1.6; lr: 0.00100; sents:    7053; bsz: 3471/3000/141; 19082/16491 tok/s;   1283 sec;\n",
            "[2025-11-08 16:02:22,753 INFO] Step 5400/30000; acc: 47.9; ppl:   5.3; xent: 1.7; lr: 0.00100; sents:    6313; bsz: 3345/2880/126; 17370/14954 tok/s;   1292 sec;\n",
            "[2025-11-08 16:02:23,189 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 316\n",
            "[2025-11-08 16:02:23,636 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 317\n",
            "[2025-11-08 16:02:24,076 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 318\n",
            "[2025-11-08 16:02:24,520 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 319\n",
            "[2025-11-08 16:02:24,961 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 320\n",
            "[2025-11-08 16:02:25,405 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 321\n",
            "[2025-11-08 16:02:25,850 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 322\n",
            "[2025-11-08 16:02:26,292 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 323\n",
            "[2025-11-08 16:02:31,049 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 324\n",
            "[2025-11-08 16:02:31,190 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 316\n",
            "[2025-11-08 16:02:31,506 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 325\n",
            "[2025-11-08 16:02:31,656 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 317\n",
            "[2025-11-08 16:02:31,976 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 326\n",
            "[2025-11-08 16:02:32,144 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 318\n",
            "[2025-11-08 16:02:32,438 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 327\n",
            "[2025-11-08 16:02:32,522 INFO] Step 5450/30000; acc: 48.1; ppl:   5.7; xent: 1.7; lr: 0.00100; sents:    5940; bsz: 3595/2922/119; 18399/14957 tok/s;   1302 sec;\n",
            "[2025-11-08 16:02:32,609 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 319\n",
            "[2025-11-08 16:02:32,903 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 328\n",
            "[2025-11-08 16:02:33,101 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 320\n",
            "[2025-11-08 16:02:33,371 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 329\n",
            "[2025-11-08 16:02:33,561 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 321\n",
            "[2025-11-08 16:02:33,837 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 330\n",
            "[2025-11-08 16:02:34,017 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 322\n",
            "[2025-11-08 16:02:34,467 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 323\n",
            "[2025-11-08 16:02:34,920 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 324\n",
            "[2025-11-08 16:02:35,364 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 325\n",
            "[2025-11-08 16:02:40,395 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 326\n",
            "[2025-11-08 16:02:40,848 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 327\n",
            "[2025-11-08 16:02:41,291 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 328\n",
            "[2025-11-08 16:02:41,731 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 329\n",
            "[2025-11-08 16:02:42,161 INFO] Step 5500/30000; acc: 49.7; ppl:   5.4; xent: 1.7; lr: 0.00100; sents:    6114; bsz: 3524/2892/122; 18282/15005 tok/s;   1312 sec;\n",
            "[2025-11-08 16:02:42,174 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 330\n",
            "[2025-11-08 16:02:52,378 INFO] valid stats calculation\n",
            "                           took: 10.216334342956543 s.\n",
            "[2025-11-08 16:02:52,379 INFO] Train perplexity: 14.0439\n",
            "[2025-11-08 16:02:52,379 INFO] Train accuracy: 38.0325\n",
            "[2025-11-08 16:02:52,379 INFO] Sentences processed: 696694\n",
            "[2025-11-08 16:02:52,379 INFO] Average bsz: 3503/2927/127\n",
            "[2025-11-08 16:02:52,379 INFO] Validation perplexity: 17.3017\n",
            "[2025-11-08 16:02:52,379 INFO] Validation accuracy: 35.1305\n",
            "[2025-11-08 16:02:52,380 INFO] Decreasing patience: 1/5\n",
            "[2025-11-08 16:02:52,384 INFO] Saving checkpoint outputs/gru-aug-cbk/model_gru_aug_cbk_step_5500.pt\n",
            "[2025-11-08 16:03:02,028 INFO] Step 5550/30000; acc: 49.1; ppl:   5.4; xent: 1.7; lr: 0.00100; sents:    6113; bsz: 3527/2866/122; 8876/7214 tok/s;   1332 sec;\n",
            "[2025-11-08 16:03:11,717 INFO] Step 5600/30000; acc: 51.1; ppl:   4.7; xent: 1.6; lr: 0.00100; sents:    6226; bsz: 3423/2860/125; 17669/14761 tok/s;   1341 sec;\n",
            "[2025-11-08 16:03:21,782 INFO] Step 5650/30000; acc: 49.5; ppl:   5.1; xent: 1.6; lr: 0.00100; sents:    6304; bsz: 3545/2878/126; 17611/14301 tok/s;   1351 sec;\n",
            "[2025-11-08 16:03:29,323 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 331\n",
            "[2025-11-08 16:03:29,792 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 332\n",
            "[2025-11-08 16:03:30,255 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 333\n",
            "[2025-11-08 16:03:30,708 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 334\n",
            "[2025-11-08 16:03:31,163 INFO] Step 5700/30000; acc: 51.2; ppl:   4.9; xent: 1.6; lr: 0.00100; sents:    6589; bsz: 3463/2953/132; 18457/15740 tok/s;   1361 sec;\n",
            "[2025-11-08 16:03:31,208 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 335\n",
            "[2025-11-08 16:03:31,675 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 336\n",
            "[2025-11-08 16:03:32,126 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 337\n",
            "[2025-11-08 16:03:36,786 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 338\n",
            "[2025-11-08 16:03:37,225 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 339\n",
            "[2025-11-08 16:03:37,656 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 331\n",
            "[2025-11-08 16:03:37,668 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 340\n",
            "[2025-11-08 16:03:38,109 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 341\n",
            "[2025-11-08 16:03:38,123 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 332\n",
            "[2025-11-08 16:03:38,554 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 342\n",
            "[2025-11-08 16:03:38,579 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 333\n",
            "[2025-11-08 16:03:38,999 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 343\n",
            "[2025-11-08 16:03:39,030 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 334\n",
            "[2025-11-08 16:03:39,451 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 344\n",
            "[2025-11-08 16:03:39,482 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 335\n",
            "[2025-11-08 16:03:39,899 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 345\n",
            "[2025-11-08 16:03:39,936 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 336\n",
            "[2025-11-08 16:03:40,389 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 337\n",
            "[2025-11-08 16:03:40,843 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 338\n",
            "[2025-11-08 16:03:40,898 INFO] Step 5750/30000; acc: 49.2; ppl:   5.6; xent: 1.7; lr: 0.00100; sents:    6250; bsz: 3510/2975/125; 18028/15279 tok/s;   1370 sec;\n",
            "[2025-11-08 16:03:41,300 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 339\n",
            "[2025-11-08 16:03:41,834 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 340\n",
            "[2025-11-08 16:03:45,707 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 346\n",
            "[2025-11-08 16:03:47,002 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 341\n",
            "[2025-11-08 16:03:47,450 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 342\n",
            "[2025-11-08 16:03:47,903 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 343\n",
            "[2025-11-08 16:03:48,343 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 344\n",
            "[2025-11-08 16:03:48,793 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 345\n",
            "[2025-11-08 16:03:49,232 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 346\n",
            "[2025-11-08 16:03:51,209 INFO] valid stats calculation\n",
            "                           took: 10.31016206741333 s.\n",
            "[2025-11-08 16:03:51,210 INFO] Train perplexity: 13.4461\n",
            "[2025-11-08 16:03:51,210 INFO] Train accuracy: 38.5505\n",
            "[2025-11-08 16:03:51,210 INFO] Sentences processed: 728176\n",
            "[2025-11-08 16:03:51,210 INFO] Average bsz: 3503/2926/127\n",
            "[2025-11-08 16:03:51,210 INFO] Validation perplexity: 17.3854\n",
            "[2025-11-08 16:03:51,210 INFO] Validation accuracy: 35.5198\n",
            "[2025-11-08 16:03:51,211 INFO] Decreasing patience: 0/5\n",
            "[2025-11-08 16:03:51,211 INFO] Training finished after not improving. Early Stop!\n",
            "[2025-11-08 16:03:51,211 INFO] Best model found at step 4500\n",
            "[2025-11-08 16:03:51,211 INFO] earlystopper has_stopped!\n",
            "[2025-11-08 16:04:01,403 INFO] Saving checkpoint outputs/gru-aug-cbk/model_gru_aug_cbk_step_5750.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation"
      ],
      "metadata": {
        "id": "DyF3sXYMuYaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's perform translation here too since it needs `OpenNMT-py`.\n",
        "\n",
        "Make sure you have the ff. uploaded:\n",
        "- testing data (i.e., `test.src`) in `data/`\n",
        "- models in `outputs/`"
      ],
      "metadata": {
        "id": "ypiDZsfauirH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Common paths\n",
        "SRC = \"data/test.src\"\n",
        "\n",
        "# Config files\n",
        "CONFIG_BASE = \"config-gru-base.yaml\"\n",
        "CONFIG_AUG = \"config-gru-aug.yaml\"\n",
        "CONFIG_AUG_CBK = \"config-gru-aug-cbk.yaml\"\n",
        "CONFIG_TRANSLATE = \"translate.yaml\"\n",
        "\n",
        "# Model checkpoints\n",
        "MODEL_BASE = \"/content/drive/MyDrive/opennmt_models/gru-base/model_gru_base_step_4000.pt\"\n",
        "MODEL_AUG = \"/content/drive/MyDrive/opennmt_models/gru-aug/model_gru_aug_step_28500.pt\"\n",
        "MODEL_AUG_CBK = \"/content/drive/MyDrive/opennmt_models/gru-aug-cbk/model_gru_aug_cbk_step_5750.pt\"\n",
        "\n",
        "# Translation outputs\n",
        "OUT_BASE=\"outputs/trans-base.txt\"\n",
        "OUT_AUG=\"outputs/trans-aug.txt\"\n",
        "OUT_AUG_CBK=\"outputs/trans-aug-cbk.txt\""
      ],
      "metadata": {
        "id": "JXZIxLW5uhTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translate with the base model\n",
        "!onmt_translate \\\n",
        "    -model $MODEL_BASE \\\n",
        "    -src $SRC \\\n",
        "    -output $OUT_BASE \\\n",
        "    -gpu 0 \\\n",
        "    -batch_size 64 \\\n",
        "    -beam_size 5\n",
        "\n",
        "# # Translate with the augmented model\n",
        "# !onmt_translate \\\n",
        "#     -model $MODEL_AUG \\\n",
        "#     -src $SRC \\\n",
        "#     -output $OUT_AUG \\\n",
        "#     -gpu 0 \\\n",
        "#     -batch_size 64 \\\n",
        "#     -beam_size 5\n",
        "\n",
        "# # Translate with the CBK-augmented model\n",
        "# !onmt_translate \\\n",
        "#     -model $MODEL_AUG_CBK \\\n",
        "#     -src $SRC \\\n",
        "#     -output $OUT_AUG_CBK \\\n",
        "#     -gpu 0 \\\n",
        "#     -batch_size 64 \\\n",
        "#     -beam_size 5"
      ],
      "metadata": {
        "id": "wIefQyHKwCSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2215a144-2f18-4983-fd45-3ab2fbfde4d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-11-08 20:47:29,999 INFO] Loading checkpoint from /content/drive/MyDrive/opennmt_models/gru-base/model_gru_base_step_4000.pt\n",
            "[2025-11-08 20:47:30,387 INFO] Loading data into the model\n",
            "WARNING: missing checkpoint key, skipping: generator.linear.weight\n",
            "WARNING: missing checkpoint key, skipping: generator.linear.bias\n",
            "WARNING: missing checkpoint key, skipping: generator.linear_copy.weight\n",
            "WARNING: missing checkpoint key, skipping: generator.linear_copy.bias\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt_translate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/onmt/bin/translate.py\", line 67, in main\n",
            "    translate(opt)\n",
            "  File \"/usr/local/lib/python3.11/site-packages/onmt/bin/translate.py\", line 37, in translate\n",
            "    _, _ = translator._translate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/onmt/translate/translator.py\", line 510, in _translate\n",
            "    translations = xlation_builder.from_batch(batch_data)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/onmt/translate/translation.py\", line 98, in from_batch\n",
            "    pred_sents = [\n",
            "                 ^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/onmt/translate/translation.py\", line 99, in <listcomp>\n",
            "    self._build_target_tokens(\n",
            "  File \"/usr/local/lib/python3.11/site-packages/onmt/translate/translation.py\", line 39, in _build_target_tokens\n",
            "    tokens = [\n",
            "             ^\n",
            "  File \"/usr/local/lib/python3.11/site-packages/onmt/translate/translation.py\", line 42, in <listcomp>\n",
            "    else dyn_voc.ids_to_tokens[tok - len(self.vocabs[\"src\"].ids_to_tokens)]\n",
            "         ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "IndexError: list index out of range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The author doesn't know why, but he's experiencing several problems trying to get this to run. After two hours of no progress, he chose to implement the architecture through `PyTorch`.\n",
        "\n",
        "It's painful, but that's life."
      ],
      "metadata": {
        "id": "4-9OSt229_WX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, mount your Google Drive and save the models you trained along with their translations.\n",
        "\n",
        "P.S.:\n",
        "- No need for this unless you want to keep the models you ended up training."
      ],
      "metadata": {
        "id": "ipWeQzOgcN-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZXC7VIzQ-cjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0424167-07bd-4d7a-e27d-10c1a2444a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/opennmt_models\n",
        "!cp -r outputs /content/drive/MyDrive/opennmt_models/"
      ],
      "metadata": {
        "id": "iyxasloY-d8x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "mount_file_id": "19kTuF8gFb8AhHNY-vsK9aIpzzz_6gZGr",
      "authorship_tag": "ABX9TyMdX0LFfIqKUw0qS7z+vUzo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}